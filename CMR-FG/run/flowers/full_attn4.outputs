64 10.0
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
current #steps=0, #epochs=0
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 8.303570 
iteration = 5 | loss = 8.388580 
iteration = 10 | loss = 8.376787 
iteration = 15 | loss = 8.324783 
iteration = 20 | loss = 8.302128 
iteration = 25 | loss = 8.313665 
iteration = 30 | loss = 8.246544 
iteration = 35 | loss = 8.276205 
iteration = 40 | loss = 8.130131 
iteration = 45 | loss = 8.043472 
iteration = 50 | loss = 7.913300 
iteration = 55 | loss = 7.655349 
iteration = 60 | loss = 7.662729 
iteration = 65 | loss = 7.629513 
iteration = 70 | loss = 7.276901 
iteration = 75 | loss = 7.230910 
iteration = 80 | loss = 7.283598 
iteration = 85 | loss = 7.242348 
iteration = 90 | loss = 7.329327 
iteration = 95 | loss = 7.383775 
iteration = 100 | loss = 6.851562 
iteration = 105 | loss = 6.673143 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 6.729568 
iteration = 5 | loss = 6.638702 
iteration = 10 | loss = 6.828753 
iteration = 15 | loss = 6.583222 
iteration = 20 | loss = 6.485435 
iteration = 25 | loss = 6.642041 
iteration = 30 | loss = 6.470737 
iteration = 35 | loss = 6.454876 
iteration = 40 | loss = 6.265308 
iteration = 45 | loss = 6.312121 
iteration = 50 | loss = 6.171919 
iteration = 55 | loss = 6.422845 
iteration = 60 | loss = 6.520650 
iteration = 65 | loss = 6.571999 
iteration = 70 | loss = 6.306971 
iteration = 75 | loss = 6.574196 
iteration = 80 | loss = 6.544116 
iteration = 85 | loss = 6.156874 
iteration = 90 | loss = 6.481921 
iteration = 95 | loss = 5.601473 
iteration = 100 | loss = 6.011361 
iteration = 105 | loss = 5.857092 
iteration = 0 | loss = 5.784544 
iteration = 5 | loss = 5.552561 
iteration = 10 | loss = 5.482106 
iteration = 15 | loss = 6.157293 
iteration = 20 | loss = 6.159322 
iteration = 25 | loss = 5.703152 
iteration = 30 | loss = 5.767825 
iteration = 35 | loss = 5.506085 
iteration = 40 | loss = 6.001059 
iteration = 45 | loss = 5.891760 
iteration = 50 | loss = 5.445093 
iteration = 55 | loss = 5.514121 
iteration = 60 | loss = 5.648661 
iteration = 65 | loss = 5.516341 
iteration = 70 | loss = 5.800816 
iteration = 75 | loss = 5.580686 
iteration = 80 | loss = 5.675392 
iteration = 85 | loss = 6.059393 
iteration = 90 | loss = 5.456352 
iteration = 95 | loss = 5.465805 
iteration = 100 | loss = 5.446118 
iteration = 105 | loss = 5.290823 
iteration = 0 | loss = 5.098950 
iteration = 5 | loss = 5.459927 
iteration = 10 | loss = 5.320459 
iteration = 15 | loss = 5.262874 
iteration = 20 | loss = 5.801072 
iteration = 25 | loss = 5.081341 
iteration = 30 | loss = 5.238261 
iteration = 35 | loss = 5.128026 
iteration = 40 | loss = 5.680927 
iteration = 45 | loss = 5.371871 
iteration = 50 | loss = 5.209261 
iteration = 55 | loss = 5.414905 
iteration = 60 | loss = 5.397892 
iteration = 65 | loss = 5.185602 
iteration = 70 | loss = 5.308156 
iteration = 75 | loss = 5.394205 
iteration = 80 | loss = 5.454325 
iteration = 85 | loss = 5.113027 
iteration = 90 | loss = 5.643813 
iteration = 95 | loss = 5.525880 
iteration = 100 | loss = 5.476418 
iteration = 105 | loss = 5.632564 
iteration = 0 | loss = 4.950017 
iteration = 5 | loss = 5.245022 
iteration = 10 | loss = 4.821887 
iteration = 15 | loss = 5.233574 
iteration = 20 | loss = 5.689616 
iteration = 25 | loss = 4.767834 
iteration = 30 | loss = 5.488528 
iteration = 35 | loss = 4.605597 
iteration = 40 | loss = 5.108544 
iteration = 45 | loss = 5.297426 
iteration = 50 | loss = 5.268177 
iteration = 55 | loss = 5.221686 
iteration = 60 | loss = 5.347165 
iteration = 65 | loss = 4.878506 
iteration = 70 | loss = 4.836807 
iteration = 75 | loss = 5.062908 
iteration = 80 | loss = 4.915504 
iteration = 85 | loss = 5.258611 
iteration = 90 | loss = 4.576630 
iteration = 95 | loss = 4.499760 
iteration = 100 | loss = 4.862381 
iteration = 105 | loss = 4.548057 
 Epoch: [5] Loss: 4.8634  R1_I2A: 0.4918 R1_A2I: 0.3330 
                 
iteration = 0 | loss = 4.378230 
iteration = 5 | loss = 4.413567 
iteration = 10 | loss = 4.803181 
iteration = 15 | loss = 4.945513 
iteration = 20 | loss = 4.946514 
iteration = 25 | loss = 4.971449 
iteration = 30 | loss = 4.877597 
iteration = 35 | loss = 5.055708 
iteration = 40 | loss = 5.016888 
iteration = 45 | loss = 4.473718 
iteration = 50 | loss = 4.597126 
iteration = 55 | loss = 4.472759 
iteration = 60 | loss = 5.126163 
iteration = 65 | loss = 4.633042 
iteration = 70 | loss = 4.922014 
iteration = 75 | loss = 5.336395 
iteration = 80 | loss = 4.526328 
iteration = 85 | loss = 4.865997 
iteration = 90 | loss = 4.637746 
iteration = 95 | loss = 5.300998 
iteration = 100 | loss = 5.354532 
iteration = 105 | loss = 5.024996 
iteration = 0 | loss = 4.321168 
iteration = 5 | loss = 4.723082 
iteration = 10 | loss = 5.074244 
iteration = 15 | loss = 4.914715 
iteration = 20 | loss = 5.015732 
iteration = 25 | loss = 4.846762 
iteration = 30 | loss = 5.369637 
iteration = 35 | loss = 4.639990 
iteration = 40 | loss = 4.457510 
iteration = 45 | loss = 5.081153 
iteration = 50 | loss = 4.667476 
iteration = 55 | loss = 4.496614 
iteration = 60 | loss = 4.856139 
iteration = 65 | loss = 4.250260 
iteration = 70 | loss = 4.836142 
iteration = 75 | loss = 4.690343 
iteration = 80 | loss = 4.873730 
iteration = 85 | loss = 4.046287 
iteration = 90 | loss = 4.349938 
iteration = 95 | loss = 4.933192 
iteration = 100 | loss = 4.008583 
iteration = 105 | loss = 5.029305 
iteration = 0 | loss = 4.728661 
iteration = 5 | loss = 5.313457 
iteration = 10 | loss = 4.844405 
iteration = 15 | loss = 4.418130 
iteration = 20 | loss = 4.433871 
iteration = 25 | loss = 5.232949 
iteration = 30 | loss = 4.736042 
iteration = 35 | loss = 4.658588 
iteration = 40 | loss = 4.686418 
iteration = 45 | loss = 4.626763 
iteration = 50 | loss = 4.255226 
iteration = 55 | loss = 4.828677 
iteration = 60 | loss = 4.646871 
iteration = 65 | loss = 4.537089 
iteration = 70 | loss = 4.879881 
iteration = 75 | loss = 4.757895 
iteration = 80 | loss = 4.649040 
iteration = 85 | loss = 4.764915 
iteration = 90 | loss = 4.227613 
iteration = 95 | loss = 4.727252 
iteration = 100 | loss = 4.669018 
iteration = 105 | loss = 3.989125 
iteration = 0 | loss = 4.377337 
iteration = 5 | loss = 3.586658 
iteration = 10 | loss = 4.349222 
iteration = 15 | loss = 4.526088 
iteration = 20 | loss = 4.234622 
iteration = 25 | loss = 4.199034 
iteration = 30 | loss = 4.589113 
iteration = 35 | loss = 4.387967 
iteration = 40 | loss = 4.445985 
iteration = 45 | loss = 4.508541 
iteration = 50 | loss = 4.582917 
iteration = 55 | loss = 3.945596 
iteration = 60 | loss = 4.399240 
iteration = 65 | loss = 4.385813 
iteration = 70 | loss = 4.111834 
iteration = 75 | loss = 4.240524 
iteration = 80 | loss = 3.800408 
iteration = 85 | loss = 3.533541 
iteration = 90 | loss = 4.857170 
iteration = 95 | loss = 4.226829 
iteration = 100 | loss = 4.106930 
iteration = 105 | loss = 4.280117 
iteration = 0 | loss = 4.107768 
iteration = 5 | loss = 4.309036 
iteration = 10 | loss = 4.027756 
iteration = 15 | loss = 4.340236 
iteration = 20 | loss = 4.520874 
iteration = 25 | loss = 4.598247 
iteration = 30 | loss = 4.434972 
iteration = 35 | loss = 3.838053 
iteration = 40 | loss = 3.898006 
iteration = 45 | loss = 4.198493 
iteration = 50 | loss = 4.864158 
iteration = 55 | loss = 4.761028 
iteration = 60 | loss = 4.441431 
iteration = 65 | loss = 4.363059 
iteration = 70 | loss = 4.334889 
iteration = 75 | loss = 4.625538 
iteration = 80 | loss = 4.072667 
iteration = 85 | loss = 4.840692 
iteration = 90 | loss = 4.053549 
iteration = 95 | loss = 4.849422 
iteration = 100 | loss = 4.122085 
iteration = 105 | loss = 4.148579 
 Epoch: [10] Loss: 4.1626  R1_I2A: 0.5498 R1_A2I: 0.3687 
                 
iteration = 0 | loss = 4.212753 
iteration = 5 | loss = 3.952006 
iteration = 10 | loss = 3.986562 
iteration = 15 | loss = 3.808986 
iteration = 20 | loss = 3.952817 
iteration = 25 | loss = 3.847164 
iteration = 30 | loss = 4.213552 
iteration = 35 | loss = 4.178980 
iteration = 40 | loss = 3.839700 
iteration = 45 | loss = 4.434844 
iteration = 50 | loss = 4.130236 
iteration = 55 | loss = 3.153025 
iteration = 60 | loss = 4.093683 
iteration = 65 | loss = 4.054236 
iteration = 70 | loss = 4.303239 
iteration = 75 | loss = 4.235400 
iteration = 80 | loss = 4.133343 
iteration = 85 | loss = 4.388934 
iteration = 90 | loss = 4.338176 
iteration = 95 | loss = 4.119763 
iteration = 100 | loss = 4.024050 
iteration = 105 | loss = 4.180216 
iteration = 0 | loss = 4.159728 
iteration = 5 | loss = 3.704678 
iteration = 10 | loss = 3.843886 
iteration = 15 | loss = 4.449157 
iteration = 20 | loss = 4.345415 
iteration = 25 | loss = 4.142115 
iteration = 30 | loss = 4.027558 
iteration = 35 | loss = 3.898174 
iteration = 40 | loss = 4.003789 
iteration = 45 | loss = 4.369382 
iteration = 50 | loss = 3.772755 
iteration = 55 | loss = 4.022606 
iteration = 60 | loss = 3.627125 
iteration = 65 | loss = 3.907692 
iteration = 70 | loss = 3.401359 
iteration = 75 | loss = 3.980150 
iteration = 80 | loss = 3.986263 
iteration = 85 | loss = 4.064417 
iteration = 90 | loss = 4.420877 
iteration = 95 | loss = 3.946372 
iteration = 100 | loss = 3.912221 
iteration = 105 | loss = 4.576929 
iteration = 0 | loss = 3.919984 
iteration = 5 | loss = 4.025243 
iteration = 10 | loss = 3.489713 
iteration = 15 | loss = 4.285883 
iteration = 20 | loss = 4.051620 
iteration = 25 | loss = 4.130748 
iteration = 30 | loss = 3.382442 
iteration = 35 | loss = 3.793781 
iteration = 40 | loss = 4.379065 
iteration = 45 | loss = 4.332602 
iteration = 50 | loss = 4.559336 
iteration = 55 | loss = 3.736519 
iteration = 60 | loss = 4.313589 
iteration = 65 | loss = 4.395951 
iteration = 70 | loss = 3.908590 
iteration = 75 | loss = 3.504346 
iteration = 80 | loss = 3.414382 
iteration = 85 | loss = 3.556907 
iteration = 90 | loss = 4.160521 
iteration = 95 | loss = 4.388173 
iteration = 100 | loss = 4.216683 
iteration = 105 | loss = 4.017942 
iteration = 0 | loss = 4.075423 
iteration = 5 | loss = 4.446689 
iteration = 10 | loss = 3.898638 
iteration = 15 | loss = 3.523898 
iteration = 20 | loss = 4.128359 
iteration = 25 | loss = 3.826955 
iteration = 30 | loss = 3.969212 
iteration = 35 | loss = 3.844811 
iteration = 40 | loss = 3.674785 
iteration = 45 | loss = 4.039798 
iteration = 50 | loss = 3.820309 
iteration = 55 | loss = 4.020555 
iteration = 60 | loss = 4.010610 
iteration = 65 | loss = 4.301509 
iteration = 70 | loss = 4.174863 
iteration = 75 | loss = 3.921061 
iteration = 80 | loss = 3.706398 
iteration = 85 | loss = 3.464157 
iteration = 90 | loss = 4.110892 
iteration = 95 | loss = 3.387250 
iteration = 100 | loss = 4.217595 
iteration = 105 | loss = 3.687091 
iteration = 0 | loss = 3.702473 
iteration = 5 | loss = 3.990386 
iteration = 10 | loss = 3.634784 
iteration = 15 | loss = 3.892462 
iteration = 20 | loss = 4.029243 
iteration = 25 | loss = 4.359491 
iteration = 30 | loss = 4.640821 
iteration = 35 | loss = 4.239060 
iteration = 40 | loss = 3.842021 
iteration = 45 | loss = 4.409227 
iteration = 50 | loss = 3.817648 
iteration = 55 | loss = 3.586261 
iteration = 60 | loss = 3.798176 
iteration = 65 | loss = 3.650738 
iteration = 70 | loss = 3.684112 
iteration = 75 | loss = 3.438128 
iteration = 80 | loss = 3.570099 
iteration = 85 | loss = 4.145914 
iteration = 90 | loss = 4.079052 
iteration = 95 | loss = 3.763216 
iteration = 100 | loss = 3.462101 
iteration = 105 | loss = 3.749700 
 Epoch: [15] Loss: 3.5966  R1_I2A: 0.5680 R1_A2I: 0.4300 
                 
iteration = 0 | loss = 3.662488 
iteration = 5 | loss = 3.646429 
iteration = 10 | loss = 3.607691 
iteration = 15 | loss = 3.746089 
iteration = 20 | loss = 3.634088 
iteration = 25 | loss = 3.565299 
iteration = 30 | loss = 4.000246 
iteration = 35 | loss = 3.703482 
iteration = 40 | loss = 3.945364 
iteration = 45 | loss = 3.710000 
iteration = 50 | loss = 3.652902 
iteration = 55 | loss = 3.680997 
iteration = 60 | loss = 3.252158 
iteration = 65 | loss = 3.917744 
iteration = 70 | loss = 3.396873 
iteration = 75 | loss = 3.408687 
iteration = 80 | loss = 4.011736 
iteration = 85 | loss = 3.050898 
iteration = 90 | loss = 4.606648 
iteration = 95 | loss = 3.680071 
iteration = 100 | loss = 4.034994 
iteration = 105 | loss = 3.340632 
iteration = 0 | loss = 3.415797 
iteration = 5 | loss = 3.569255 
iteration = 10 | loss = 3.982991 
iteration = 15 | loss = 3.343284 
iteration = 20 | loss = 3.637030 
iteration = 25 | loss = 3.648679 
iteration = 30 | loss = 3.825326 
iteration = 35 | loss = 3.745454 
iteration = 40 | loss = 3.870354 
iteration = 45 | loss = 3.210879 
iteration = 50 | loss = 3.488922 
iteration = 55 | loss = 3.545205 
iteration = 60 | loss = 3.421960 
iteration = 65 | loss = 3.762447 
iteration = 70 | loss = 3.670272 
iteration = 75 | loss = 3.822668 
iteration = 80 | loss = 3.475794 
iteration = 85 | loss = 3.910728 
iteration = 90 | loss = 3.777383 
iteration = 95 | loss = 3.572842 
iteration = 100 | loss = 3.786635 
iteration = 105 | loss = 3.605786 
iteration = 0 | loss = 3.324931 
iteration = 5 | loss = 3.841080 
iteration = 10 | loss = 3.798420 
iteration = 15 | loss = 3.639903 
iteration = 20 | loss = 3.560809 
iteration = 25 | loss = 4.000031 
iteration = 30 | loss = 3.839503 
iteration = 35 | loss = 3.691137 
iteration = 40 | loss = 3.050839 
iteration = 45 | loss = 3.482976 
iteration = 50 | loss = 3.447308 
iteration = 55 | loss = 3.758789 
iteration = 60 | loss = 3.352925 
iteration = 65 | loss = 3.431026 
iteration = 70 | loss = 3.451805 
iteration = 75 | loss = 3.229730 
iteration = 80 | loss = 3.558143 
iteration = 85 | loss = 3.766387 
iteration = 90 | loss = 3.483421 
iteration = 95 | loss = 3.572578 
iteration = 100 | loss = 3.779360 
iteration = 105 | loss = 4.005849 
iteration = 0 | loss = 3.410691 
iteration = 5 | loss = 3.623610 
iteration = 10 | loss = 3.406142 
iteration = 15 | loss = 3.356619 
iteration = 20 | loss = 3.539114 
iteration = 25 | loss = 3.933927 
iteration = 30 | loss = 3.789524 
iteration = 35 | loss = 3.520646 
iteration = 40 | loss = 3.982195 
iteration = 45 | loss = 3.673913 
iteration = 50 | loss = 4.133242 
iteration = 55 | loss = 3.489604 
iteration = 60 | loss = 3.499650 
iteration = 65 | loss = 3.335900 
iteration = 70 | loss = 4.037545 
iteration = 75 | loss = 3.753506 
iteration = 80 | loss = 3.556422 
iteration = 85 | loss = 3.621202 
iteration = 90 | loss = 3.524384 
iteration = 95 | loss = 3.703008 
iteration = 100 | loss = 3.535833 
iteration = 105 | loss = 3.171595 
iteration = 0 | loss = 3.509519 
iteration = 5 | loss = 2.977035 
iteration = 10 | loss = 3.437962 
iteration = 15 | loss = 3.085327 
iteration = 20 | loss = 3.451483 
iteration = 25 | loss = 3.043865 
iteration = 30 | loss = 3.235765 
iteration = 35 | loss = 3.283010 
iteration = 40 | loss = 3.384331 
iteration = 45 | loss = 4.345365 
iteration = 50 | loss = 3.715420 
iteration = 55 | loss = 3.630614 
iteration = 60 | loss = 3.517439 
iteration = 65 | loss = 3.400904 
iteration = 70 | loss = 3.304543 
iteration = 75 | loss = 3.340278 
iteration = 80 | loss = 3.756824 
iteration = 85 | loss = 3.182953 
iteration = 90 | loss = 2.811099 
iteration = 95 | loss = 3.446623 
iteration = 100 | loss = 3.327487 
iteration = 105 | loss = 3.600539 
 Epoch: [20] Loss: 3.9929  R1_I2A: 0.5429 R1_A2I: 0.4616 
                 
iteration = 0 | loss = 3.081471 
iteration = 5 | loss = 3.991764 
iteration = 10 | loss = 3.515543 
iteration = 15 | loss = 3.961393 
iteration = 20 | loss = 3.560167 
iteration = 25 | loss = 3.289583 
iteration = 30 | loss = 3.407124 
iteration = 35 | loss = 3.859993 
iteration = 40 | loss = 3.672371 
iteration = 45 | loss = 3.990832 
iteration = 50 | loss = 3.617969 
iteration = 55 | loss = 3.533110 
iteration = 60 | loss = 3.469934 
iteration = 65 | loss = 3.759687 
iteration = 70 | loss = 3.491544 
iteration = 75 | loss = 3.073366 
iteration = 80 | loss = 4.087150 
iteration = 85 | loss = 3.540120 
iteration = 90 | loss = 3.649759 
iteration = 95 | loss = 3.470185 
iteration = 100 | loss = 3.741619 
iteration = 105 | loss = 3.858770 
iteration = 0 | loss = 3.080987 
iteration = 5 | loss = 3.189286 
iteration = 10 | loss = 3.767452 
iteration = 15 | loss = 3.384104 
iteration = 20 | loss = 2.956191 
iteration = 25 | loss = 3.446878 
iteration = 30 | loss = 3.351506 
iteration = 35 | loss = 3.303230 
iteration = 40 | loss = 3.186493 
iteration = 45 | loss = 3.702088 
iteration = 50 | loss = 3.767670 
iteration = 55 | loss = 3.590400 
iteration = 60 | loss = 3.371313 
iteration = 65 | loss = 3.257737 
iteration = 70 | loss = 3.948614 
iteration = 75 | loss = 2.978914 
iteration = 80 | loss = 3.125039 
iteration = 85 | loss = 3.146481 
iteration = 90 | loss = 3.164495 
iteration = 95 | loss = 3.483432 
iteration = 100 | loss = 3.797377 
iteration = 105 | loss = 3.408374 
iteration = 0 | loss = 3.505884 
iteration = 5 | loss = 3.422831 
iteration = 10 | loss = 3.227598 
iteration = 15 | loss = 3.269742 
iteration = 20 | loss = 3.355918 
iteration = 25 | loss = 3.422304 
iteration = 30 | loss = 3.530762 
iteration = 35 | loss = 3.597199 
iteration = 40 | loss = 3.466966 
iteration = 45 | loss = 3.602074 
iteration = 50 | loss = 3.450256 
iteration = 55 | loss = 3.409573 
iteration = 60 | loss = 3.025743 
iteration = 65 | loss = 2.738736 
iteration = 70 | loss = 3.542675 
iteration = 75 | loss = 3.527193 
iteration = 80 | loss = 3.439358 
iteration = 85 | loss = 3.646353 
iteration = 90 | loss = 3.844774 
iteration = 95 | loss = 3.238245 
iteration = 100 | loss = 3.653935 
iteration = 105 | loss = 3.060775 
iteration = 0 | loss = 3.201441 
iteration = 5 | loss = 3.839527 
iteration = 10 | loss = 3.400493 
iteration = 15 | loss = 3.330100 
iteration = 20 | loss = 3.312191 
iteration = 25 | loss = 3.583917 
iteration = 30 | loss = 3.156010 
iteration = 35 | loss = 3.528343 
iteration = 40 | loss = 3.063922 
iteration = 45 | loss = 4.030146 
iteration = 50 | loss = 3.733062 
iteration = 55 | loss = 3.451858 
iteration = 60 | loss = 3.043923 
iteration = 65 | loss = 3.093002 
iteration = 70 | loss = 3.343080 
iteration = 75 | loss = 3.309255 
iteration = 80 | loss = 3.222390 
iteration = 85 | loss = 3.102544 
iteration = 90 | loss = 3.253039 
iteration = 95 | loss = 3.603181 
iteration = 100 | loss = 3.392478 
iteration = 105 | loss = 2.645607 
iteration = 0 | loss = 3.877369 
iteration = 5 | loss = 3.302969 
iteration = 10 | loss = 3.242953 
iteration = 15 | loss = 3.325558 
iteration = 20 | loss = 3.547915 
iteration = 25 | loss = 3.365031 
iteration = 30 | loss = 3.481643 
iteration = 35 | loss = 3.294776 
iteration = 40 | loss = 3.844991 
iteration = 45 | loss = 3.331401 
iteration = 50 | loss = 2.813778 
iteration = 55 | loss = 3.764493 
iteration = 60 | loss = 3.125081 
iteration = 65 | loss = 3.536318 
iteration = 70 | loss = 3.232889 
iteration = 75 | loss = 3.162603 
iteration = 80 | loss = 3.264211 
iteration = 85 | loss = 3.534364 
iteration = 90 | loss = 3.209486 
iteration = 95 | loss = 2.741462 
iteration = 100 | loss = 3.058096 
iteration = 105 | loss = 3.734228 
 Epoch: [25] Loss: 3.1603  R1_I2A: 0.5602 R1_A2I: 0.4546 
                 
 Epoch: [25] Loss: 3.1603  R1_I2A: 0.5620 mAP_I2A: 0.4956  R1_A2I: 0.4546 mAP_A2I: 0.4038 
                     
iteration = 0 | loss = 3.147220 
iteration = 5 | loss = 3.466440 
iteration = 10 | loss = 3.717682 
iteration = 15 | loss = 3.228851 
iteration = 20 | loss = 2.746893 
iteration = 25 | loss = 3.670943 
iteration = 30 | loss = 3.729810 
iteration = 35 | loss = 3.325354 
iteration = 40 | loss = 2.527915 
iteration = 45 | loss = 3.521833 
iteration = 50 | loss = 3.287632 
iteration = 55 | loss = 3.272997 
iteration = 60 | loss = 3.361677 
iteration = 65 | loss = 3.514550 
iteration = 70 | loss = 3.443355 
iteration = 75 | loss = 3.476079 
iteration = 80 | loss = 3.553228 
iteration = 85 | loss = 3.343120 
iteration = 90 | loss = 3.089255 
iteration = 95 | loss = 3.760239 
iteration = 100 | loss = 2.922171 
iteration = 105 | loss = 2.929341 
iteration = 0 | loss = 3.032127 
iteration = 5 | loss = 3.219750 
iteration = 10 | loss = 3.269155 
iteration = 15 | loss = 3.000310 
iteration = 20 | loss = 3.283252 
iteration = 25 | loss = 2.986971 
iteration = 30 | loss = 3.062947 
iteration = 35 | loss = 3.355223 
iteration = 40 | loss = 3.036968 
iteration = 45 | loss = 2.773112 
iteration = 50 | loss = 3.048281 
iteration = 55 | loss = 3.391144 
iteration = 60 | loss = 3.319556 
iteration = 65 | loss = 2.594561 
iteration = 70 | loss = 2.950167 
iteration = 75 | loss = 3.548380 
iteration = 80 | loss = 3.318211 
iteration = 85 | loss = 2.854044 
iteration = 90 | loss = 3.824087 
iteration = 95 | loss = 3.166292 
iteration = 100 | loss = 2.742324 
iteration = 105 | loss = 3.616686 
iteration = 0 | loss = 3.205578 
iteration = 5 | loss = 3.813652 
iteration = 10 | loss = 2.805920 
iteration = 15 | loss = 3.226727 
iteration = 20 | loss = 3.601267 
iteration = 25 | loss = 2.932956 
iteration = 30 | loss = 3.252149 
iteration = 35 | loss = 3.951762 
iteration = 40 | loss = 3.536655 
iteration = 45 | loss = 3.459242 
iteration = 50 | loss = 3.444732 
iteration = 55 | loss = 3.132186 
iteration = 60 | loss = 3.122289 
iteration = 65 | loss = 3.000685 
iteration = 70 | loss = 3.126471 
iteration = 75 | loss = 3.118176 
iteration = 80 | loss = 3.059996 
iteration = 85 | loss = 3.228184 
iteration = 90 | loss = 2.963653 
iteration = 95 | loss = 3.263264 
iteration = 100 | loss = 3.239811 
iteration = 105 | loss = 3.798229 
iteration = 0 | loss = 2.955041 
iteration = 5 | loss = 3.282977 
iteration = 10 | loss = 2.697269 
iteration = 15 | loss = 3.092137 
iteration = 20 | loss = 3.014907 
iteration = 25 | loss = 3.006380 
iteration = 30 | loss = 2.687057 
iteration = 35 | loss = 3.337761 
iteration = 40 | loss = 3.087271 
iteration = 45 | loss = 3.492173 
iteration = 50 | loss = 2.967433 
iteration = 55 | loss = 3.223614 
iteration = 60 | loss = 3.331063 
iteration = 65 | loss = 3.262443 
iteration = 70 | loss = 3.325202 
iteration = 75 | loss = 3.038653 
iteration = 80 | loss = 2.517674 
iteration = 85 | loss = 3.494184 
iteration = 90 | loss = 2.841727 
iteration = 95 | loss = 3.445991 
iteration = 100 | loss = 2.714458 
iteration = 105 | loss = 3.037209 
iteration = 0 | loss = 2.754819 
iteration = 5 | loss = 3.299259 
iteration = 10 | loss = 3.096422 
iteration = 15 | loss = 2.887431 
iteration = 20 | loss = 3.222134 
iteration = 25 | loss = 2.927088 
iteration = 30 | loss = 2.740343 
iteration = 35 | loss = 3.421715 
iteration = 40 | loss = 2.772579 
iteration = 45 | loss = 2.809604 
iteration = 50 | loss = 2.824475 
iteration = 55 | loss = 3.552958 
iteration = 60 | loss = 3.324612 
iteration = 65 | loss = 3.301597 
iteration = 70 | loss = 3.260522 
iteration = 75 | loss = 2.869901 
iteration = 80 | loss = 2.812144 
iteration = 85 | loss = 3.295265 
iteration = 90 | loss = 2.981754 
iteration = 95 | loss = 3.095493 
iteration = 100 | loss = 3.160808 
iteration = 105 | loss = 3.079169 
 Epoch: [30] Loss: 3.4018  R1_I2A: 0.5576 R1_A2I: 0.4541 
                 
iteration = 0 | loss = 2.696822 
iteration = 5 | loss = 3.270917 
iteration = 10 | loss = 2.720424 
iteration = 15 | loss = 3.180664 
iteration = 20 | loss = 3.420896 
iteration = 25 | loss = 2.759191 
iteration = 30 | loss = 2.967708 
iteration = 35 | loss = 3.214422 
iteration = 40 | loss = 3.244928 
iteration = 45 | loss = 2.891111 
iteration = 50 | loss = 3.030984 
iteration = 55 | loss = 3.248325 
iteration = 60 | loss = 3.425362 
iteration = 65 | loss = 3.118010 
iteration = 70 | loss = 2.762863 
iteration = 75 | loss = 3.578814 
iteration = 80 | loss = 3.131345 
iteration = 85 | loss = 3.257397 
iteration = 90 | loss = 3.320170 
iteration = 95 | loss = 2.784301 
iteration = 100 | loss = 3.430421 
iteration = 105 | loss = 2.913984 
iteration = 0 | loss = 3.328869 
iteration = 5 | loss = 3.211148 
iteration = 10 | loss = 2.804118 
iteration = 15 | loss = 3.089817 
iteration = 20 | loss = 3.076936 
iteration = 25 | loss = 3.330779 
iteration = 30 | loss = 3.241222 
iteration = 35 | loss = 3.055843 
iteration = 40 | loss = 3.362184 
iteration = 45 | loss = 3.140243 
iteration = 50 | loss = 2.806877 
iteration = 55 | loss = 2.726049 
iteration = 60 | loss = 3.070918 
iteration = 65 | loss = 2.510973 
iteration = 70 | loss = 2.758403 
iteration = 75 | loss = 3.049186 
iteration = 80 | loss = 2.996674 
iteration = 85 | loss = 3.066433 
iteration = 90 | loss = 3.527545 
iteration = 95 | loss = 3.273762 
iteration = 100 | loss = 2.949522 
iteration = 105 | loss = 3.528614 
iteration = 0 | loss = 3.238459 
iteration = 5 | loss = 3.230686 
iteration = 10 | loss = 2.959143 
iteration = 15 | loss = 3.390295 
iteration = 20 | loss = 2.599721 
iteration = 25 | loss = 2.711363 
iteration = 30 | loss = 3.167225 
iteration = 35 | loss = 2.641275 
iteration = 40 | loss = 2.916128 
iteration = 45 | loss = 3.064989 
iteration = 50 | loss = 3.010627 
iteration = 55 | loss = 2.976950 
iteration = 60 | loss = 2.492085 
iteration = 65 | loss = 3.009809 
iteration = 70 | loss = 3.632267 
iteration = 75 | loss = 3.350706 
iteration = 80 | loss = 2.967624 
iteration = 85 | loss = 2.945062 
iteration = 90 | loss = 2.963663 
iteration = 95 | loss = 3.081906 
iteration = 100 | loss = 3.228106 
iteration = 105 | loss = 2.848251 
iteration = 0 | loss = 2.949487 
iteration = 5 | loss = 2.745121 
iteration = 10 | loss = 3.355845 
iteration = 15 | loss = 3.329172 
iteration = 20 | loss = 3.129470 
iteration = 25 | loss = 3.086958 
iteration = 30 | loss = 2.574450 
iteration = 35 | loss = 3.157738 
iteration = 40 | loss = 3.144457 
iteration = 45 | loss = 2.899700 
iteration = 50 | loss = 3.082124 
iteration = 55 | loss = 2.416033 
iteration = 60 | loss = 2.863804 
iteration = 65 | loss = 2.860187 
iteration = 70 | loss = 2.395023 
iteration = 75 | loss = 2.445912 
iteration = 80 | loss = 3.291789 
iteration = 85 | loss = 2.695364 
iteration = 90 | loss = 3.022734 
iteration = 95 | loss = 3.199090 
iteration = 100 | loss = 2.727288 
iteration = 105 | loss = 3.290708 
iteration = 0 | loss = 3.034509 
iteration = 5 | loss = 2.847706 
iteration = 10 | loss = 3.126340 
iteration = 15 | loss = 3.114871 
iteration = 20 | loss = 3.380215 
iteration = 25 | loss = 2.732856 
iteration = 30 | loss = 3.098709 
iteration = 35 | loss = 2.833230 
iteration = 40 | loss = 2.757058 
iteration = 45 | loss = 2.982927 
iteration = 50 | loss = 3.059417 
iteration = 55 | loss = 3.215085 
iteration = 60 | loss = 2.921105 
iteration = 65 | loss = 3.184344 
iteration = 70 | loss = 3.277547 
iteration = 75 | loss = 3.115858 
iteration = 80 | loss = 2.727291 
iteration = 85 | loss = 2.697586 
iteration = 90 | loss = 3.061630 
iteration = 95 | loss = 4.149409 
iteration = 100 | loss = 2.856055 
iteration = 105 | loss = 3.061647 
 Epoch: [35] Loss: 2.8590  R1_I2A: 0.5706 R1_A2I: 0.4610 
                 
 Epoch: [35] Loss: 2.8590  R1_I2A: 0.5735 mAP_I2A: 0.5033  R1_A2I: 0.4610 mAP_A2I: 0.4016 
                     
iteration = 0 | loss = 3.243262 
iteration = 5 | loss = 3.090836 
iteration = 10 | loss = 2.887666 
iteration = 15 | loss = 2.775950 
iteration = 20 | loss = 2.797385 
iteration = 25 | loss = 3.013190 
iteration = 30 | loss = 2.861458 
iteration = 35 | loss = 3.062369 
iteration = 40 | loss = 2.686666 
iteration = 45 | loss = 2.875914 
iteration = 50 | loss = 2.525879 
iteration = 55 | loss = 2.669510 
iteration = 60 | loss = 2.846091 
iteration = 65 | loss = 2.783755 
iteration = 70 | loss = 3.114999 
iteration = 75 | loss = 2.964415 
iteration = 80 | loss = 3.105410 
iteration = 85 | loss = 2.653152 
iteration = 90 | loss = 2.983481 
iteration = 95 | loss = 3.136450 
iteration = 100 | loss = 2.855965 
iteration = 105 | loss = 2.811542 
iteration = 0 | loss = 2.753637 
iteration = 5 | loss = 2.775666 
iteration = 10 | loss = 3.036292 
iteration = 15 | loss = 3.038683 
iteration = 20 | loss = 2.541821 
iteration = 25 | loss = 3.157034 
iteration = 30 | loss = 2.894798 
iteration = 35 | loss = 2.848373 
iteration = 40 | loss = 2.812841 
iteration = 45 | loss = 3.019255 
iteration = 50 | loss = 3.244567 
iteration = 55 | loss = 3.339988 
iteration = 60 | loss = 2.555800 
iteration = 65 | loss = 2.951322 
iteration = 70 | loss = 2.380330 
iteration = 75 | loss = 2.383707 
iteration = 80 | loss = 2.829107 
iteration = 85 | loss = 2.865472 
iteration = 90 | loss = 2.483591 
iteration = 95 | loss = 3.052660 
iteration = 100 | loss = 3.254653 
iteration = 105 | loss = 2.844225 
iteration = 0 | loss = 2.195682 
iteration = 5 | loss = 2.880606 
iteration = 10 | loss = 3.077621 
iteration = 15 | loss = 3.077894 
iteration = 20 | loss = 2.916159 
iteration = 25 | loss = 2.992126 
iteration = 30 | loss = 2.473867 
iteration = 35 | loss = 3.131965 
iteration = 40 | loss = 2.927585 
iteration = 45 | loss = 2.849333 
iteration = 50 | loss = 2.864231 
iteration = 55 | loss = 2.786085 
iteration = 60 | loss = 2.706669 
iteration = 65 | loss = 2.465390 
iteration = 70 | loss = 2.616687 
iteration = 75 | loss = 2.736070 
iteration = 80 | loss = 2.964845 
iteration = 85 | loss = 2.905169 
iteration = 90 | loss = 2.717847 
iteration = 95 | loss = 3.229707 
iteration = 100 | loss = 2.958376 
iteration = 105 | loss = 2.663656 
iteration = 0 | loss = 3.009542 
iteration = 5 | loss = 2.427033 
iteration = 10 | loss = 2.951620 
iteration = 15 | loss = 3.109920 
iteration = 20 | loss = 2.685217 
iteration = 25 | loss = 3.072357 
iteration = 30 | loss = 2.951186 
iteration = 35 | loss = 3.436834 
iteration = 40 | loss = 3.567837 
iteration = 45 | loss = 3.310931 
iteration = 50 | loss = 3.043549 
iteration = 55 | loss = 2.417044 
iteration = 60 | loss = 2.443918 
iteration = 65 | loss = 2.828464 
iteration = 70 | loss = 2.842527 
iteration = 75 | loss = 2.906408 
iteration = 80 | loss = 2.855462 
iteration = 85 | loss = 2.804877 
iteration = 90 | loss = 2.865844 
iteration = 95 | loss = 2.902313 
iteration = 100 | loss = 3.340375 
iteration = 105 | loss = 2.544696 
iteration = 0 | loss = 3.045191 
iteration = 5 | loss = 2.988202 
iteration = 10 | loss = 3.406271 
iteration = 15 | loss = 2.555405 
iteration = 20 | loss = 3.055163 
iteration = 25 | loss = 2.713555 
iteration = 30 | loss = 2.901585 
iteration = 35 | loss = 2.692873 
iteration = 40 | loss = 3.100968 
iteration = 45 | loss = 2.616665 
iteration = 50 | loss = 2.801574 
iteration = 55 | loss = 2.249645 
iteration = 60 | loss = 3.220199 
iteration = 65 | loss = 3.190702 
iteration = 70 | loss = 2.858995 
iteration = 75 | loss = 3.052205 
iteration = 80 | loss = 2.842401 
iteration = 85 | loss = 2.227313 
iteration = 90 | loss = 3.137341 
iteration = 95 | loss = 2.942427 
iteration = 100 | loss = 3.032991 
iteration = 105 | loss = 3.113022 
 Epoch: [40] Loss: 2.7975  R1_I2A: 0.5887 R1_A2I: 0.4718 
                 
 Epoch: [40] Loss: 2.7975  R1_I2A: 0.5843 mAP_I2A: 0.5068  R1_A2I: 0.4718 mAP_A2I: 0.4100 
                     
iteration = 0 | loss = 3.311128 
iteration = 5 | loss = 2.883436 
iteration = 10 | loss = 2.652319 
iteration = 15 | loss = 3.274222 
iteration = 20 | loss = 2.704156 
iteration = 25 | loss = 2.971728 
iteration = 30 | loss = 2.653578 
iteration = 35 | loss = 2.582734 
iteration = 40 | loss = 2.491841 
iteration = 45 | loss = 2.997148 
iteration = 50 | loss = 2.403328 
iteration = 55 | loss = 2.906291 
iteration = 60 | loss = 2.588446 
iteration = 65 | loss = 2.874036 
iteration = 70 | loss = 2.653738 
iteration = 75 | loss = 2.706444 
iteration = 80 | loss = 2.463717 
iteration = 85 | loss = 2.977604 
iteration = 90 | loss = 2.542526 
iteration = 95 | loss = 2.607169 
iteration = 100 | loss = 2.903114 
iteration = 105 | loss = 2.705750 

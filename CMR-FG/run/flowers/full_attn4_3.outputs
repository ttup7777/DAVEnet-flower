64 10.0
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
loaded parameters from epoch 80
current #steps=0, #epochs=80
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 1.247221 
iteration = 5 | loss = 1.901189 
iteration = 10 | loss = 1.548138 
iteration = 15 | loss = 1.717146 
iteration = 20 | loss = 1.598970 
iteration = 25 | loss = 1.984651 
iteration = 30 | loss = 1.662452 
iteration = 35 | loss = 2.168667 
iteration = 40 | loss = 1.661933 
iteration = 45 | loss = 1.865695 
iteration = 50 | loss = 1.506135 
iteration = 55 | loss = 2.002036 
iteration = 60 | loss = 1.637846 
iteration = 65 | loss = 1.753436 
iteration = 70 | loss = 1.938605 
iteration = 75 | loss = 1.671944 
iteration = 80 | loss = 1.796559 
iteration = 85 | loss = 1.477318 
iteration = 90 | loss = 1.425383 
iteration = 95 | loss = 1.794885 
iteration = 100 | loss = 1.624188 
iteration = 105 | loss = 1.448896 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 1.416017 
iteration = 5 | loss = 1.720379 
iteration = 10 | loss = 1.462001 
iteration = 15 | loss = 1.563355 
iteration = 20 | loss = 1.635468 
iteration = 25 | loss = 1.876745 
iteration = 30 | loss = 1.381193 
iteration = 35 | loss = 1.684048 
iteration = 40 | loss = 1.713671 
iteration = 45 | loss = 1.693481 
iteration = 50 | loss = 1.583164 
iteration = 55 | loss = 1.449346 
iteration = 60 | loss = 1.411198 
iteration = 65 | loss = 1.714023 
iteration = 70 | loss = 1.372170 
iteration = 75 | loss = 2.090167 
iteration = 80 | loss = 1.718963 
iteration = 85 | loss = 1.203718 
iteration = 90 | loss = 1.767526 
iteration = 95 | loss = 1.535807 
iteration = 100 | loss = 1.666673 
iteration = 105 | loss = 2.050932 
iteration = 0 | loss = 1.567621 
iteration = 5 | loss = 1.513219 
iteration = 10 | loss = 1.296810 
iteration = 15 | loss = 1.846287 
iteration = 20 | loss = 1.352471 
iteration = 25 | loss = 1.455750 
iteration = 30 | loss = 1.418159 
iteration = 35 | loss = 1.354265 
iteration = 40 | loss = 2.282874 
iteration = 45 | loss = 1.814996 
iteration = 50 | loss = 1.520937 
iteration = 55 | loss = 1.577362 
iteration = 60 | loss = 1.536377 
iteration = 65 | loss = 1.242955 
iteration = 70 | loss = 1.863491 
iteration = 75 | loss = 1.599219 
iteration = 80 | loss = 1.605568 
iteration = 85 | loss = 2.015092 
iteration = 90 | loss = 1.587099 
iteration = 95 | loss = 1.585455 
iteration = 100 | loss = 1.769168 
iteration = 105 | loss = 1.767959 
iteration = 0 | loss = 1.277107 
iteration = 5 | loss = 1.615123 
iteration = 10 | loss = 1.669077 
iteration = 15 | loss = 1.424148 
iteration = 20 | loss = 1.553216 
iteration = 25 | loss = 1.228723 
iteration = 30 | loss = 1.420423 
iteration = 35 | loss = 1.371583 
iteration = 40 | loss = 1.387300 
iteration = 45 | loss = 1.886408 
iteration = 50 | loss = 1.559363 
iteration = 55 | loss = 1.411998 
iteration = 60 | loss = 1.788634 
iteration = 65 | loss = 1.447371 
iteration = 70 | loss = 1.776605 
iteration = 75 | loss = 1.592295 
iteration = 80 | loss = 1.879401 
iteration = 85 | loss = 1.379882 
iteration = 90 | loss = 1.999071 
iteration = 95 | loss = 1.854085 
iteration = 100 | loss = 1.789415 
iteration = 105 | loss = 1.646624 
iteration = 0 | loss = 1.679330 
iteration = 5 | loss = 1.634749 
iteration = 10 | loss = 1.290982 
iteration = 15 | loss = 1.475962 
iteration = 20 | loss = 1.762920 
iteration = 25 | loss = 1.468816 
iteration = 30 | loss = 1.804957 
iteration = 35 | loss = 1.522231 
iteration = 40 | loss = 1.728870 
iteration = 45 | loss = 1.610279 
iteration = 50 | loss = 1.660682 
iteration = 55 | loss = 1.382595 
iteration = 60 | loss = 1.725201 
iteration = 65 | loss = 1.356262 
iteration = 70 | loss = 1.397978 
iteration = 75 | loss = 1.521310 
iteration = 80 | loss = 1.863963 
iteration = 85 | loss = 1.458234 
iteration = 90 | loss = 1.371660 
iteration = 95 | loss = 1.582694 
iteration = 100 | loss = 1.342029 
iteration = 105 | loss = 1.316589 
 Epoch: [85] Loss: 1.4669  R1_I2A: 0.5723 R1_A2I: 0.4558 
                 
 Epoch: [85] Loss: 1.4669  R1_I2A: 0.5704 mAP_I2A: 0.5067  R1_A2I: 0.4558 mAP_A2I: 0.4045 
                     
iteration = 0 | loss = 1.503268 
iteration = 5 | loss = 1.759932 
iteration = 10 | loss = 1.688720 
iteration = 15 | loss = 1.178415 
iteration = 20 | loss = 1.286671 
iteration = 25 | loss = 1.469925 
iteration = 30 | loss = 1.652520 
iteration = 35 | loss = 1.614822 
iteration = 40 | loss = 1.160468 
iteration = 45 | loss = 1.827811 
iteration = 50 | loss = 1.411439 
iteration = 55 | loss = 2.079092 
iteration = 60 | loss = 1.566072 
iteration = 65 | loss = 1.284659 
iteration = 70 | loss = 1.554484 
iteration = 75 | loss = 1.973727 
iteration = 80 | loss = 1.447178 
iteration = 85 | loss = 1.731849 
iteration = 90 | loss = 1.863438 
iteration = 95 | loss = 1.504572 
iteration = 100 | loss = 1.499371 
iteration = 105 | loss = 1.759068 
iteration = 0 | loss = 1.381901 
iteration = 5 | loss = 1.413353 
iteration = 10 | loss = 1.206808 
iteration = 15 | loss = 1.381571 
iteration = 20 | loss = 1.420614 
iteration = 25 | loss = 1.177842 
iteration = 30 | loss = 1.624473 
iteration = 35 | loss = 1.355207 
iteration = 40 | loss = 1.277805 
iteration = 45 | loss = 1.626160 
iteration = 50 | loss = 1.407385 
iteration = 55 | loss = 1.620045 
iteration = 60 | loss = 1.381938 
iteration = 65 | loss = 1.232543 
iteration = 70 | loss = 1.698476 
iteration = 75 | loss = 1.474272 
iteration = 80 | loss = 1.246755 
iteration = 85 | loss = 1.303975 
iteration = 90 | loss = 1.366084 
iteration = 95 | loss = 1.649372 
iteration = 100 | loss = 1.542144 
iteration = 105 | loss = 1.859792 
iteration = 0 | loss = 1.209049 
iteration = 5 | loss = 1.325232 
iteration = 10 | loss = 1.516086 
iteration = 15 | loss = 1.536029 
iteration = 20 | loss = 1.664378 
iteration = 25 | loss = 1.632338 
iteration = 30 | loss = 1.350744 
iteration = 35 | loss = 1.384943 
iteration = 40 | loss = 1.413112 
iteration = 45 | loss = 1.616189 
iteration = 50 | loss = 1.509111 
iteration = 55 | loss = 1.171007 
iteration = 60 | loss = 1.499079 
iteration = 65 | loss = 1.705271 
iteration = 70 | loss = 1.517411 
iteration = 75 | loss = 1.223310 
iteration = 80 | loss = 1.489470 
iteration = 85 | loss = 1.686390 
iteration = 90 | loss = 1.310764 
iteration = 95 | loss = 1.393119 
iteration = 100 | loss = 1.410144 
iteration = 105 | loss = 1.730331 
iteration = 0 | loss = 1.230937 
iteration = 5 | loss = 1.393853 
iteration = 10 | loss = 1.253005 
iteration = 15 | loss = 1.638460 
iteration = 20 | loss = 1.224361 
iteration = 25 | loss = 1.209648 
iteration = 30 | loss = 1.256713 
iteration = 35 | loss = 1.792872 
iteration = 40 | loss = 1.689169 
iteration = 45 | loss = 1.282893 
iteration = 50 | loss = 1.469963 
iteration = 55 | loss = 1.306487 
iteration = 60 | loss = 1.437065 
iteration = 65 | loss = 1.631822 
iteration = 70 | loss = 1.443882 
iteration = 75 | loss = 1.518193 
iteration = 80 | loss = 1.300983 
iteration = 85 | loss = 1.441376 
iteration = 90 | loss = 1.277251 
iteration = 95 | loss = 1.276716 
iteration = 100 | loss = 1.641419 
iteration = 105 | loss = 1.808742 
iteration = 0 | loss = 1.571670 
iteration = 5 | loss = 1.192278 
iteration = 10 | loss = 1.581333 
iteration = 15 | loss = 1.740536 
iteration = 20 | loss = 1.546357 
iteration = 25 | loss = 1.539798 
iteration = 30 | loss = 1.575633 
iteration = 35 | loss = 1.549412 
iteration = 40 | loss = 1.763813 
iteration = 45 | loss = 1.820027 
iteration = 50 | loss = 1.406106 
iteration = 55 | loss = 1.845842 
iteration = 60 | loss = 1.474770 
iteration = 65 | loss = 1.250133 
iteration = 70 | loss = 1.462790 
iteration = 75 | loss = 1.605675 
iteration = 80 | loss = 1.658202 
iteration = 85 | loss = 1.166308 
iteration = 90 | loss = 1.529110 
iteration = 95 | loss = 1.685095 
iteration = 100 | loss = 1.330301 
iteration = 105 | loss = 1.443364 
 Epoch: [90] Loss: 1.8010  R1_I2A: 0.5654 R1_A2I: 0.4506 
                 
iteration = 0 | loss = 1.911727 
iteration = 5 | loss = 1.815543 
iteration = 10 | loss = 1.723273 
iteration = 15 | loss = 2.005419 
iteration = 20 | loss = 1.625421 
iteration = 25 | loss = 1.548137 
iteration = 30 | loss = 1.377393 
iteration = 35 | loss = 1.579594 
iteration = 40 | loss = 1.793947 
iteration = 45 | loss = 1.589292 
iteration = 50 | loss = 1.330555 
iteration = 55 | loss = 1.414157 
iteration = 60 | loss = 1.373928 
iteration = 65 | loss = 1.747343 
iteration = 70 | loss = 1.606797 
iteration = 75 | loss = 1.079772 
iteration = 80 | loss = 1.355000 
iteration = 85 | loss = 1.846891 
iteration = 90 | loss = 1.631220 
iteration = 95 | loss = 1.583381 
iteration = 100 | loss = 1.454675 
iteration = 105 | loss = 1.515531 
iteration = 0 | loss = 1.320163 
iteration = 5 | loss = 1.734878 
iteration = 10 | loss = 1.700581 
iteration = 15 | loss = 1.485354 
iteration = 20 | loss = 1.588953 
iteration = 25 | loss = 1.584893 
iteration = 30 | loss = 1.525493 
iteration = 35 | loss = 1.502853 
iteration = 40 | loss = 1.330424 
iteration = 45 | loss = 1.562667 
iteration = 50 | loss = 1.394291 
iteration = 55 | loss = 1.394851 
iteration = 60 | loss = 1.766759 
iteration = 65 | loss = 1.729924 
iteration = 70 | loss = 1.689983 
iteration = 75 | loss = 1.270016 
iteration = 80 | loss = 1.340781 
iteration = 85 | loss = 1.265540 
iteration = 90 | loss = 1.700510 
iteration = 95 | loss = 2.370734 
iteration = 100 | loss = 1.620405 
iteration = 105 | loss = 1.455027 
iteration = 0 | loss = 1.709358 
iteration = 5 | loss = 1.458250 
iteration = 10 | loss = 1.346442 
iteration = 15 | loss = 1.198328 
iteration = 20 | loss = 1.386676 
iteration = 25 | loss = 1.323936 
iteration = 30 | loss = 1.388181 
iteration = 35 | loss = 1.602648 
iteration = 40 | loss = 1.376268 
iteration = 45 | loss = 1.402045 
iteration = 50 | loss = 1.307897 
iteration = 55 | loss = 1.449543 
iteration = 60 | loss = 1.534808 
iteration = 65 | loss = 1.467775 
iteration = 70 | loss = 1.570587 
iteration = 75 | loss = 1.328855 
iteration = 80 | loss = 1.070808 
iteration = 85 | loss = 1.581569 
iteration = 90 | loss = 1.815164 
iteration = 95 | loss = 1.614970 
iteration = 100 | loss = 2.065894 
iteration = 105 | loss = 1.549567 
iteration = 0 | loss = 1.298559 
iteration = 5 | loss = 1.198727 
iteration = 10 | loss = 1.623965 
iteration = 15 | loss = 1.874331 
iteration = 20 | loss = 1.662610 
iteration = 25 | loss = 1.483248 
iteration = 30 | loss = 1.422720 
iteration = 35 | loss = 1.438913 
iteration = 40 | loss = 1.541469 
iteration = 45 | loss = 1.702264 
iteration = 50 | loss = 1.518630 
iteration = 55 | loss = 1.354557 
iteration = 60 | loss = 1.604481 
iteration = 65 | loss = 1.463516 
iteration = 70 | loss = 1.658870 
iteration = 75 | loss = 1.099003 
iteration = 80 | loss = 1.607177 
iteration = 85 | loss = 1.652299 
iteration = 90 | loss = 1.517353 
iteration = 95 | loss = 1.256006 
iteration = 100 | loss = 1.182207 
iteration = 105 | loss = 1.547116 
iteration = 0 | loss = 1.398936 
iteration = 5 | loss = 1.570541 
iteration = 10 | loss = 1.413236 
iteration = 15 | loss = 1.858291 
iteration = 20 | loss = 1.276355 
iteration = 25 | loss = 1.171308 
iteration = 30 | loss = 1.211073 
iteration = 35 | loss = 1.654981 
iteration = 40 | loss = 1.099997 
iteration = 45 | loss = 1.452502 
iteration = 50 | loss = 1.523066 
iteration = 55 | loss = 1.397416 
iteration = 60 | loss = 1.687778 
iteration = 65 | loss = 1.627674 
iteration = 70 | loss = 1.673803 
iteration = 75 | loss = 1.587084 
iteration = 80 | loss = 1.207735 
iteration = 85 | loss = 1.492578 
iteration = 90 | loss = 1.609175 
iteration = 95 | loss = 1.565970 
iteration = 100 | loss = 1.571958 
iteration = 105 | loss = 1.119125 
 Epoch: [95] Loss: 1.4557  R1_I2A: 0.5489 R1_A2I: 0.4437 
                 
iteration = 0 | loss = 1.540586 
iteration = 5 | loss = 1.174415 
iteration = 10 | loss = 1.516391 
iteration = 15 | loss = 1.375405 
iteration = 20 | loss = 1.243893 
iteration = 25 | loss = 1.252592 
iteration = 30 | loss = 1.871028 
iteration = 35 | loss = 1.558368 
iteration = 40 | loss = 1.340246 
iteration = 45 | loss = 1.429205 
iteration = 50 | loss = 1.805865 
iteration = 55 | loss = 1.765656 
iteration = 60 | loss = 1.515108 
iteration = 65 | loss = 1.306322 
iteration = 70 | loss = 1.495915 
iteration = 75 | loss = 1.593735 
iteration = 80 | loss = 1.347153 
iteration = 85 | loss = 1.927646 
iteration = 90 | loss = 1.633761 
iteration = 95 | loss = 1.478721 
iteration = 100 | loss = 1.557095 
iteration = 105 | loss = 1.359840 
iteration = 0 | loss = 1.445053 
iteration = 5 | loss = 1.494598 
iteration = 10 | loss = 1.350630 
iteration = 15 | loss = 1.282763 
iteration = 20 | loss = 1.451933 
iteration = 25 | loss = 1.607193 
iteration = 30 | loss = 1.462719 
iteration = 35 | loss = 1.444491 
iteration = 40 | loss = 1.471451 
iteration = 45 | loss = 1.483998 
iteration = 50 | loss = 1.542710 
iteration = 55 | loss = 1.631663 
iteration = 60 | loss = 1.243174 
iteration = 65 | loss = 1.526398 
iteration = 70 | loss = 1.521482 
iteration = 75 | loss = 1.399998 
iteration = 80 | loss = 1.273832 
iteration = 85 | loss = 1.293200 
iteration = 90 | loss = 1.930951 
iteration = 95 | loss = 1.272429 
iteration = 100 | loss = 1.299794 
iteration = 105 | loss = 1.440092 
iteration = 0 | loss = 1.492710 
iteration = 5 | loss = 1.470994 
iteration = 10 | loss = 1.361185 
iteration = 15 | loss = 1.287600 
iteration = 20 | loss = 1.473127 
iteration = 25 | loss = 1.618954 
iteration = 30 | loss = 1.275625 
iteration = 35 | loss = 1.299042 
iteration = 40 | loss = 1.669237 
iteration = 45 | loss = 1.725861 
iteration = 50 | loss = 1.620533 
iteration = 55 | loss = 1.815385 
iteration = 60 | loss = 1.607801 
iteration = 65 | loss = 0.931202 
iteration = 70 | loss = 1.459670 
iteration = 75 | loss = 1.377907 
iteration = 80 | loss = 2.004274 
iteration = 85 | loss = 1.407712 
iteration = 90 | loss = 1.725596 
iteration = 95 | loss = 1.272882 
iteration = 100 | loss = 1.701634 
iteration = 105 | loss = 1.096143 
iteration = 0 | loss = 1.746522 
iteration = 5 | loss = 1.254255 
iteration = 10 | loss = 1.541724 
iteration = 15 | loss = 1.578229 
iteration = 20 | loss = 1.612741 
iteration = 25 | loss = 1.283997 
iteration = 30 | loss = 1.209297 
iteration = 35 | loss = 1.613572 
iteration = 40 | loss = 1.289638 
iteration = 45 | loss = 1.493471 
iteration = 50 | loss = 1.534862 
iteration = 55 | loss = 1.124417 
iteration = 60 | loss = 1.166889 
iteration = 65 | loss = 1.233849 
iteration = 70 | loss = 1.301378 
iteration = 75 | loss = 1.329490 
iteration = 80 | loss = 1.557823 
iteration = 85 | loss = 1.572978 
iteration = 90 | loss = 1.163167 
iteration = 95 | loss = 1.515464 
iteration = 100 | loss = 1.527883 
iteration = 105 | loss = 1.277416 
iteration = 0 | loss = 1.447994 
iteration = 5 | loss = 1.460713 
iteration = 10 | loss = 1.584015 
iteration = 15 | loss = 1.419028 
iteration = 20 | loss = 1.227662 
iteration = 25 | loss = 1.130065 
iteration = 30 | loss = 1.224284 
iteration = 35 | loss = 1.389688 
iteration = 40 | loss = 1.130848 
iteration = 45 | loss = 1.342648 
iteration = 50 | loss = 1.389203 
iteration = 55 | loss = 1.805630 
iteration = 60 | loss = 1.236297 
iteration = 65 | loss = 1.532440 
iteration = 70 | loss = 1.328402 
iteration = 75 | loss = 1.219622 
iteration = 80 | loss = 1.067689 
iteration = 85 | loss = 0.924520 
iteration = 90 | loss = 1.713197 
iteration = 95 | loss = 1.504660 
iteration = 100 | loss = 1.694871 
iteration = 105 | loss = 1.217560 
 Epoch: [100] Loss: 1.5236  R1_I2A: 0.5654 R1_A2I: 0.4501 
                 
iteration = 0 | loss = 1.655991 
iteration = 5 | loss = 1.330705 
iteration = 10 | loss = 1.070216 
iteration = 15 | loss = 1.315495 
iteration = 20 | loss = 1.172413 
iteration = 25 | loss = 1.299252 
iteration = 30 | loss = 1.360029 
iteration = 35 | loss = 1.309199 
iteration = 40 | loss = 1.516016 
iteration = 45 | loss = 1.098866 
iteration = 50 | loss = 1.281695 
iteration = 55 | loss = 1.556500 
iteration = 60 | loss = 1.730486 
iteration = 65 | loss = 1.213315 
iteration = 70 | loss = 1.119836 
iteration = 75 | loss = 0.856479 
iteration = 80 | loss = 1.232944 
iteration = 85 | loss = 1.420941 
iteration = 90 | loss = 1.224025 
iteration = 95 | loss = 1.410305 
iteration = 100 | loss = 1.418501 
iteration = 105 | loss = 1.057549 
iteration = 0 | loss = 1.040843 
iteration = 5 | loss = 1.357571 
iteration = 10 | loss = 1.610917 
iteration = 15 | loss = 0.908022 
iteration = 20 | loss = 1.289613 
iteration = 25 | loss = 0.948253 
iteration = 30 | loss = 1.030262 
iteration = 35 | loss = 1.378771 
iteration = 40 | loss = 1.158268 
iteration = 45 | loss = 1.117155 
iteration = 50 | loss = 1.125156 
iteration = 55 | loss = 1.012018 
iteration = 60 | loss = 1.212202 
iteration = 65 | loss = 1.197533 
iteration = 70 | loss = 1.256920 
iteration = 75 | loss = 1.674287 
iteration = 80 | loss = 1.287437 
iteration = 85 | loss = 1.224240 
iteration = 90 | loss = 1.550333 
iteration = 95 | loss = 1.256963 
iteration = 100 | loss = 1.339266 
iteration = 105 | loss = 1.600129 
iteration = 0 | loss = 1.065776 
iteration = 5 | loss = 1.391546 
iteration = 10 | loss = 1.146807 
iteration = 15 | loss = 1.182058 
iteration = 20 | loss = 1.109420 
iteration = 25 | loss = 1.146362 
iteration = 30 | loss = 1.032785 
iteration = 35 | loss = 1.618869 
iteration = 40 | loss = 1.264812 
iteration = 45 | loss = 1.071336 
iteration = 50 | loss = 1.706736 
iteration = 55 | loss = 1.336044 
iteration = 60 | loss = 0.959926 
iteration = 65 | loss = 1.226104 
iteration = 70 | loss = 1.466300 
iteration = 75 | loss = 1.196228 
iteration = 80 | loss = 1.146508 
iteration = 85 | loss = 1.325361 
iteration = 90 | loss = 1.134412 
iteration = 95 | loss = 1.161454 
iteration = 100 | loss = 1.338170 
iteration = 105 | loss = 0.957165 
iteration = 0 | loss = 1.176878 
iteration = 5 | loss = 1.114802 
iteration = 10 | loss = 1.462574 
iteration = 15 | loss = 0.747341 
iteration = 20 | loss = 1.135298 
iteration = 25 | loss = 1.364601 
iteration = 30 | loss = 0.995138 
iteration = 35 | loss = 1.147484 
iteration = 40 | loss = 0.936286 
iteration = 45 | loss = 1.187824 
iteration = 50 | loss = 1.355678 
iteration = 55 | loss = 1.224412 
iteration = 60 | loss = 0.907974 
iteration = 65 | loss = 1.168054 
iteration = 70 | loss = 1.186531 
iteration = 75 | loss = 1.259686 
iteration = 80 | loss = 1.355034 
iteration = 85 | loss = 1.351028 
iteration = 90 | loss = 1.576172 
iteration = 95 | loss = 1.342792 
iteration = 100 | loss = 1.329309 
iteration = 105 | loss = 0.981638 
iteration = 0 | loss = 1.001042 
iteration = 5 | loss = 1.137387 
iteration = 10 | loss = 1.067710 
iteration = 15 | loss = 1.260423 
iteration = 20 | loss = 1.380978 
iteration = 25 | loss = 1.225784 
iteration = 30 | loss = 1.070735 
iteration = 35 | loss = 1.226588 
iteration = 40 | loss = 0.880558 
iteration = 45 | loss = 1.199108 
iteration = 50 | loss = 1.062829 
iteration = 55 | loss = 1.233797 
iteration = 60 | loss = 1.127693 
iteration = 65 | loss = 1.137029 
iteration = 70 | loss = 1.197047 
iteration = 75 | loss = 1.301737 
iteration = 80 | loss = 1.189254 
iteration = 85 | loss = 1.052601 
iteration = 90 | loss = 1.069290 
iteration = 95 | loss = 1.233207 
iteration = 100 | loss = 1.177526 
iteration = 105 | loss = 1.351130 
 Epoch: [105] Loss: 1.2533  R1_I2A: 0.5463 R1_A2I: 0.4495 
                 
iteration = 0 | loss = 1.197251 
iteration = 5 | loss = 1.082460 
iteration = 10 | loss = 1.357226 
iteration = 15 | loss = 0.933016 
iteration = 20 | loss = 1.017368 
iteration = 25 | loss = 1.213670 
iteration = 30 | loss = 1.140970 
iteration = 35 | loss = 1.344444 
iteration = 40 | loss = 0.980841 
iteration = 45 | loss = 1.289325 
iteration = 50 | loss = 1.030628 
iteration = 55 | loss = 1.300049 
iteration = 60 | loss = 1.103801 
iteration = 65 | loss = 1.522641 
iteration = 70 | loss = 1.269850 
iteration = 75 | loss = 1.272028 
iteration = 80 | loss = 1.213874 
iteration = 85 | loss = 1.114443 
iteration = 90 | loss = 1.176526 
iteration = 95 | loss = 1.214108 
iteration = 100 | loss = 1.000078 
iteration = 105 | loss = 1.013816 
iteration = 0 | loss = 1.168222 
iteration = 5 | loss = 1.280019 
iteration = 10 | loss = 1.135383 
iteration = 15 | loss = 1.224039 
iteration = 20 | loss = 1.018072 
iteration = 25 | loss = 1.101331 
iteration = 30 | loss = 1.313635 
iteration = 35 | loss = 1.239310 
iteration = 40 | loss = 0.800900 
iteration = 45 | loss = 0.856551 
iteration = 50 | loss = 1.140646 
iteration = 55 | loss = 1.125089 
iteration = 60 | loss = 1.014494 
iteration = 65 | loss = 0.970216 
iteration = 70 | loss = 1.071737 
iteration = 75 | loss = 1.367954 
iteration = 80 | loss = 1.147770 
iteration = 85 | loss = 0.799359 
iteration = 90 | loss = 1.386949 
iteration = 95 | loss = 1.159656 
iteration = 100 | loss = 0.865227 
iteration = 105 | loss = 1.586135 
iteration = 0 | loss = 1.291304 
iteration = 5 | loss = 1.184846 
iteration = 10 | loss = 0.910776 
iteration = 15 | loss = 1.181431 
iteration = 20 | loss = 1.210713 
iteration = 25 | loss = 0.915954 
iteration = 30 | loss = 1.088262 
iteration = 35 | loss = 1.287341 
iteration = 40 | loss = 1.164698 
iteration = 45 | loss = 1.290256 
iteration = 50 | loss = 1.282236 
iteration = 55 | loss = 0.955247 
iteration = 60 | loss = 1.050897 
iteration = 65 | loss = 1.002091 
iteration = 70 | loss = 0.986217 
iteration = 75 | loss = 0.987447 
iteration = 80 | loss = 1.114116 
iteration = 85 | loss = 1.204046 
iteration = 90 | loss = 0.979063 
iteration = 95 | loss = 1.074322 
iteration = 100 | loss = 0.919988 
iteration = 105 | loss = 1.061056 
iteration = 0 | loss = 1.218445 
iteration = 5 | loss = 0.994773 
iteration = 10 | loss = 0.967939 
iteration = 15 | loss = 1.137728 
iteration = 20 | loss = 1.158854 
iteration = 25 | loss = 0.915729 
iteration = 30 | loss = 0.872782 
iteration = 35 | loss = 0.964082 
iteration = 40 | loss = 1.147682 
iteration = 45 | loss = 1.178145 
iteration = 50 | loss = 1.140860 
iteration = 55 | loss = 1.076348 
iteration = 60 | loss = 1.141631 
iteration = 65 | loss = 1.078633 
iteration = 70 | loss = 1.170558 
iteration = 75 | loss = 1.053684 
iteration = 80 | loss = 0.873196 
iteration = 85 | loss = 1.154937 
iteration = 90 | loss = 0.918006 
iteration = 95 | loss = 1.185580 
iteration = 100 | loss = 0.900757 
iteration = 105 | loss = 0.962423 
iteration = 0 | loss = 0.937054 
iteration = 5 | loss = 0.915862 
iteration = 10 | loss = 1.000434 
iteration = 15 | loss = 1.076959 
iteration = 20 | loss = 1.104574 
iteration = 25 | loss = 0.935125 
iteration = 30 | loss = 0.967872 
iteration = 35 | loss = 1.069252 
iteration = 40 | loss = 0.865178 
iteration = 45 | loss = 0.889854 
iteration = 50 | loss = 0.969691 
iteration = 55 | loss = 1.092236 
iteration = 60 | loss = 1.344768 
iteration = 65 | loss = 1.142685 
iteration = 70 | loss = 0.920675 
iteration = 75 | loss = 0.995762 
iteration = 80 | loss = 0.861568 
iteration = 85 | loss = 1.013429 
iteration = 90 | loss = 1.036217 
iteration = 95 | loss = 0.993937 
iteration = 100 | loss = 0.939984 
iteration = 105 | loss = 1.029741 
 Epoch: [110] Loss: 1.2592  R1_I2A: 0.5645 R1_A2I: 0.4494 
                 
iteration = 0 | loss = 1.189715 
iteration = 5 | loss = 1.228928 
iteration = 10 | loss = 0.969126 
iteration = 15 | loss = 0.886016 
iteration = 20 | loss = 1.138938 
iteration = 25 | loss = 1.049059 
iteration = 30 | loss = 0.770957 
iteration = 35 | loss = 1.055911 
iteration = 40 | loss = 0.964440 
iteration = 45 | loss = 1.091415 
iteration = 50 | loss = 0.883243 
iteration = 55 | loss = 1.199951 
iteration = 60 | loss = 0.986669 
iteration = 65 | loss = 1.211504 
iteration = 70 | loss = 0.922139 
iteration = 75 | loss = 1.179154 
iteration = 80 | loss = 1.093834 
iteration = 85 | loss = 1.112245 
iteration = 90 | loss = 1.337231 
iteration = 95 | loss = 0.986732 
iteration = 100 | loss = 0.852095 
iteration = 105 | loss = 0.861504 
iteration = 0 | loss = 1.031202 
iteration = 5 | loss = 1.134548 
iteration = 10 | loss = 1.238888 
iteration = 15 | loss = 1.074771 
iteration = 20 | loss = 1.160171 
iteration = 25 | loss = 1.208934 
iteration = 30 | loss = 1.039802 
iteration = 35 | loss = 1.120660 
iteration = 40 | loss = 1.245516 
iteration = 45 | loss = 1.098187 
iteration = 50 | loss = 0.916076 
iteration = 55 | loss = 0.980766 
iteration = 60 | loss = 0.998124 
iteration = 65 | loss = 0.865550 
iteration = 70 | loss = 0.805332 
iteration = 75 | loss = 0.901711 
iteration = 80 | loss = 1.031808 
iteration = 85 | loss = 0.867813 
iteration = 90 | loss = 1.121474 
iteration = 95 | loss = 1.154272 
iteration = 100 | loss = 0.974341 
iteration = 105 | loss = 0.903819 
iteration = 0 | loss = 1.049573 
iteration = 5 | loss = 1.044969 
iteration = 10 | loss = 0.967192 
iteration = 15 | loss = 1.107759 
iteration = 20 | loss = 0.934760 
iteration = 25 | loss = 1.006699 
iteration = 30 | loss = 1.117231 
iteration = 35 | loss = 0.855123 
iteration = 40 | loss = 0.951723 
iteration = 45 | loss = 1.000286 
iteration = 50 | loss = 1.374056 
iteration = 55 | loss = 1.198935 
iteration = 60 | loss = 0.732674 
iteration = 65 | loss = 0.845527 
iteration = 70 | loss = 1.315974 
iteration = 75 | loss = 1.189704 
iteration = 80 | loss = 1.054518 
iteration = 85 | loss = 0.838159 
iteration = 90 | loss = 0.880170 
iteration = 95 | loss = 1.163637 
iteration = 100 | loss = 1.051551 
iteration = 105 | loss = 0.960782 
iteration = 0 | loss = 1.269682 
iteration = 5 | loss = 0.753178 
iteration = 10 | loss = 1.308329 
iteration = 15 | loss = 1.376460 
iteration = 20 | loss = 1.198260 
iteration = 25 | loss = 0.797414 
iteration = 30 | loss = 0.922319 
iteration = 35 | loss = 1.146962 
iteration = 40 | loss = 1.114349 
iteration = 45 | loss = 1.091225 
iteration = 50 | loss = 0.932226 
iteration = 55 | loss = 0.584996 
iteration = 60 | loss = 0.973803 
iteration = 65 | loss = 1.081403 
iteration = 70 | loss = 0.811889 
iteration = 75 | loss = 0.868100 
iteration = 80 | loss = 1.015274 
iteration = 85 | loss = 0.953474 
iteration = 90 | loss = 1.203974 
iteration = 95 | loss = 1.077590 
iteration = 100 | loss = 1.017456 
iteration = 105 | loss = 1.207510 
iteration = 0 | loss = 0.901091 
iteration = 5 | loss = 0.871710 
iteration = 10 | loss = 1.123052 
iteration = 15 | loss = 1.149744 
iteration = 20 | loss = 1.212635 
iteration = 25 | loss = 0.854090 
iteration = 30 | loss = 0.993645 
iteration = 35 | loss = 0.804228 
iteration = 40 | loss = 0.951864 
iteration = 45 | loss = 0.968090 
iteration = 50 | loss = 0.992777 
iteration = 55 | loss = 0.931567 
iteration = 60 | loss = 0.887304 
iteration = 65 | loss = 0.856674 
iteration = 70 | loss = 1.061974 
iteration = 75 | loss = 0.965226 
iteration = 80 | loss = 0.850823 
iteration = 85 | loss = 0.665000 
iteration = 90 | loss = 1.089388 
iteration = 95 | loss = 1.290715 
iteration = 100 | loss = 0.945241 
iteration = 105 | loss = 1.065373 
 Epoch: [115] Loss: 0.7350  R1_I2A: 0.5654 R1_A2I: 0.4428 
                 
iteration = 0 | loss = 0.917754 
iteration = 5 | loss = 1.093068 
iteration = 10 | loss = 1.122228 
iteration = 15 | loss = 1.000002 
iteration = 20 | loss = 0.928950 
iteration = 25 | loss = 0.911116 
iteration = 30 | loss = 1.086957 
iteration = 35 | loss = 0.926234 
iteration = 40 | loss = 0.744137 
iteration = 45 | loss = 1.270654 
iteration = 50 | loss = 0.877408 
iteration = 55 | loss = 1.200614 
iteration = 60 | loss = 0.782687 
iteration = 65 | loss = 0.955023 
iteration = 70 | loss = 1.102078 
iteration = 75 | loss = 1.182345 
iteration = 80 | loss = 1.032791 
iteration = 85 | loss = 1.102069 
iteration = 90 | loss = 0.926351 
iteration = 95 | loss = 1.373906 
iteration = 100 | loss = 0.963291 
iteration = 105 | loss = 1.189956 
iteration = 0 | loss = 1.195243 
iteration = 5 | loss = 1.182582 
iteration = 10 | loss = 0.950817 
iteration = 15 | loss = 1.206712 
iteration = 20 | loss = 1.143867 
iteration = 25 | loss = 0.854286 
iteration = 30 | loss = 1.095889 
iteration = 35 | loss = 1.067948 
iteration = 40 | loss = 0.916078 
iteration = 45 | loss = 1.172300 
iteration = 50 | loss = 1.029977 
iteration = 55 | loss = 1.290520 
iteration = 60 | loss = 1.260587 
iteration = 65 | loss = 1.165035 
iteration = 70 | loss = 0.960455 
iteration = 75 | loss = 1.143606 
iteration = 80 | loss = 1.213239 
iteration = 85 | loss = 1.300579 
iteration = 90 | loss = 1.028409 
iteration = 95 | loss = 1.094176 
iteration = 100 | loss = 0.995242 
iteration = 105 | loss = 1.151372 
iteration = 0 | loss = 1.002300 
iteration = 5 | loss = 1.144647 
iteration = 10 | loss = 1.341210 
iteration = 15 | loss = 1.151179 
iteration = 20 | loss = 1.042168 
iteration = 25 | loss = 0.941262 
iteration = 30 | loss = 1.139305 
iteration = 35 | loss = 1.230615 
iteration = 40 | loss = 1.024616 
iteration = 45 | loss = 1.170930 
iteration = 50 | loss = 0.955345 
iteration = 55 | loss = 1.161022 
iteration = 60 | loss = 1.147794 
iteration = 65 | loss = 0.831734 
iteration = 70 | loss = 0.973166 
iteration = 75 | loss = 0.957324 
iteration = 80 | loss = 1.067444 
iteration = 85 | loss = 0.996143 
iteration = 90 | loss = 0.698593 
iteration = 95 | loss = 1.182307 
iteration = 100 | loss = 1.191136 
iteration = 105 | loss = 0.949303 
iteration = 0 | loss = 1.059537 
iteration = 5 | loss = 1.393534 
iteration = 10 | loss = 1.010556 
iteration = 15 | loss = 0.950784 
iteration = 20 | loss = 0.806315 
iteration = 25 | loss = 0.953048 
iteration = 30 | loss = 0.745043 
iteration = 35 | loss = 1.147064 
iteration = 40 | loss = 0.949685 
iteration = 45 | loss = 0.983703 
iteration = 50 | loss = 0.851955 
iteration = 55 | loss = 0.736736 
iteration = 60 | loss = 0.903253 
iteration = 65 | loss = 1.037533 
iteration = 70 | loss = 0.967152 
iteration = 75 | loss = 1.304947 
iteration = 80 | loss = 1.083883 
iteration = 85 | loss = 0.998606 
iteration = 90 | loss = 1.005063 
iteration = 95 | loss = 0.933817 
iteration = 100 | loss = 0.836007 
iteration = 105 | loss = 0.822964 
iteration = 0 | loss = 0.882771 
iteration = 5 | loss = 0.875127 
iteration = 10 | loss = 1.196445 
iteration = 15 | loss = 0.983612 
iteration = 20 | loss = 1.138750 
iteration = 25 | loss = 1.063623 
iteration = 30 | loss = 1.231246 
iteration = 35 | loss = 0.865770 
iteration = 40 | loss = 1.007110 
iteration = 45 | loss = 1.023432 
iteration = 50 | loss = 1.012918 
iteration = 55 | loss = 0.929178 
iteration = 60 | loss = 1.126670 
slurmstepd: error: *** STEP 5245305.0 ON insy5 CANCELLED AT 2020-05-26T02:11:42 DUE TO TIME LIMIT ***

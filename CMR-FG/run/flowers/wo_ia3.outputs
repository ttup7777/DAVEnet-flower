Namespace(RNN_dropout=0.0, WORKERS=8, audio_attention=None, audio_model='Davenet', batch_size=64, cfg_file='Confg/flower_train_batch_wo_ia.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gamma_clss=1.0, gpu_id=0, image_attention=None, image_model='VGG16', img_size=256, loss_clss=None, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=120, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_ia.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/wo_ia', simtype='MISA', smooth_gamm3=10.0, smooth_imgatt1=1.0, smooth_imgatt2=1.0, start_epoch=80, tasks='extraction', topk=3, weight_decay=1e-05)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
loaded parameters from epoch 80
current #steps=0, #epochs=80
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 1.576468 
iteration = 5 | loss = 1.444759 
iteration = 10 | loss = 1.877653 
iteration = 15 | loss = 1.889120 
iteration = 20 | loss = 1.670144 
iteration = 25 | loss = 2.354874 
iteration = 30 | loss = 1.681765 
iteration = 35 | loss = 1.993406 
iteration = 40 | loss = 1.965921 
iteration = 45 | loss = 2.524716 
iteration = 50 | loss = 2.179132 
iteration = 55 | loss = 2.157694 
iteration = 60 | loss = 1.785053 
iteration = 65 | loss = 1.883052 
iteration = 70 | loss = 1.575949 
iteration = 75 | loss = 1.641218 
iteration = 80 | loss = 2.264277 
iteration = 85 | loss = 2.169480 
iteration = 90 | loss = 1.866366 
iteration = 95 | loss = 1.916634 
iteration = 100 | loss = 1.974059 
iteration = 105 | loss = 1.990552 
/scratch/xinshengwang/software/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 1.991412 
iteration = 5 | loss = 2.069326 
iteration = 10 | loss = 2.053504 
iteration = 15 | loss = 1.896929 
iteration = 20 | loss = 1.795660 
iteration = 25 | loss = 1.767056 
iteration = 30 | loss = 1.715604 
iteration = 35 | loss = 1.566170 
iteration = 40 | loss = 1.889416 
iteration = 45 | loss = 2.251816 
iteration = 50 | loss = 1.605305 
iteration = 55 | loss = 1.648813 
iteration = 60 | loss = 2.148671 
iteration = 65 | loss = 2.012106 
iteration = 70 | loss = 1.545541 
iteration = 75 | loss = 1.890432 
iteration = 80 | loss = 1.813614 
iteration = 85 | loss = 1.606466 
iteration = 90 | loss = 1.942509 
iteration = 95 | loss = 2.093619 
iteration = 100 | loss = 1.585046 
iteration = 105 | loss = 1.484195 
iteration = 0 | loss = 1.845473 
iteration = 5 | loss = 1.534497 
iteration = 10 | loss = 1.284165 
iteration = 15 | loss = 2.193478 
iteration = 20 | loss = 1.837990 
iteration = 25 | loss = 2.014948 
iteration = 30 | loss = 1.664985 
iteration = 35 | loss = 2.275655 
iteration = 40 | loss = 2.097433 
iteration = 45 | loss = 1.519907 
iteration = 50 | loss = 1.974919 
iteration = 55 | loss = 1.776727 
iteration = 60 | loss = 1.626693 
iteration = 65 | loss = 1.765302 
iteration = 70 | loss = 1.912277 
iteration = 75 | loss = 1.566844 
iteration = 80 | loss = 1.418735 
iteration = 85 | loss = 2.075852 
iteration = 90 | loss = 1.483552 
iteration = 95 | loss = 1.907340 
iteration = 100 | loss = 1.555909 
iteration = 105 | loss = 2.021890 
iteration = 0 | loss = 1.532174 
iteration = 5 | loss = 1.721977 
iteration = 10 | loss = 1.994156 
iteration = 15 | loss = 1.482107 
iteration = 20 | loss = 1.833735 
iteration = 25 | loss = 1.843053 
iteration = 30 | loss = 2.021161 
iteration = 35 | loss = 1.462442 
iteration = 40 | loss = 1.870916 
iteration = 45 | loss = 1.699370 
iteration = 50 | loss = 1.956584 
iteration = 55 | loss = 1.684536 
iteration = 60 | loss = 1.872034 
iteration = 65 | loss = 1.609541 
iteration = 70 | loss = 1.506168 
iteration = 75 | loss = 1.738243 
iteration = 80 | loss = 1.561744 
iteration = 85 | loss = 1.949542 
iteration = 90 | loss = 1.479912 
iteration = 95 | loss = 1.892009 
iteration = 100 | loss = 1.413461 
iteration = 105 | loss = 1.554168 
iteration = 0 | loss = 1.832705 
iteration = 5 | loss = 1.661009 
iteration = 10 | loss = 1.381317 
iteration = 15 | loss = 1.702525 
iteration = 20 | loss = 1.761310 
iteration = 25 | loss = 1.533914 
iteration = 30 | loss = 1.575246 
iteration = 35 | loss = 1.645194 
iteration = 40 | loss = 1.705833 
iteration = 45 | loss = 1.920974 
iteration = 50 | loss = 1.806986 
iteration = 55 | loss = 1.677154 
iteration = 60 | loss = 1.644929 
iteration = 65 | loss = 1.705688 
iteration = 70 | loss = 1.720402 
iteration = 75 | loss = 1.593926 
iteration = 80 | loss = 2.023449 
iteration = 85 | loss = 1.867475 
iteration = 90 | loss = 1.756596 
iteration = 95 | loss = 1.645152 
iteration = 100 | loss = 1.714975 
iteration = 105 | loss = 1.644172 
 Epoch: [85] Loss: 1.7432  R1_I2A: 0.5680 R1_A2I: 0.4518 
                 
 Epoch: [85] Loss: 1.7432  R1_I2A: 0.5689 mAP_I2A: 0.5020  R1_A2I: 0.4518 mAP_A2I: 0.4019 
                     
iteration = 0 | loss = 2.092126 
iteration = 5 | loss = 1.613105 
iteration = 10 | loss = 1.481024 
iteration = 15 | loss = 1.522677 
iteration = 20 | loss = 1.988581 
iteration = 25 | loss = 1.809041 
iteration = 30 | loss = 1.573892 
iteration = 35 | loss = 1.572093 
iteration = 40 | loss = 1.557423 
iteration = 45 | loss = 1.629824 
iteration = 50 | loss = 1.629737 
iteration = 55 | loss = 1.717847 
iteration = 60 | loss = 1.462647 
iteration = 65 | loss = 1.897149 
iteration = 70 | loss = 1.572499 
iteration = 75 | loss = 2.018876 
iteration = 80 | loss = 1.758098 
iteration = 85 | loss = 1.668726 
iteration = 90 | loss = 1.740132 
iteration = 95 | loss = 2.018736 
iteration = 100 | loss = 1.858978 
iteration = 105 | loss = 1.663720 
iteration = 0 | loss = 1.716674 
iteration = 5 | loss = 1.556137 
iteration = 10 | loss = 1.649025 
iteration = 15 | loss = 1.753683 
iteration = 20 | loss = 1.626455 
iteration = 25 | loss = 1.614605 
iteration = 30 | loss = 1.534448 
iteration = 35 | loss = 1.615596 
iteration = 40 | loss = 1.666847 
iteration = 45 | loss = 1.652526 
iteration = 50 | loss = 1.900911 
iteration = 55 | loss = 1.966408 
iteration = 60 | loss = 1.738066 
iteration = 65 | loss = 1.510289 
iteration = 70 | loss = 1.765740 
iteration = 75 | loss = 1.734688 
iteration = 80 | loss = 1.923689 
iteration = 85 | loss = 1.279299 
iteration = 90 | loss = 1.127743 
iteration = 95 | loss = 1.744350 
iteration = 100 | loss = 1.545938 
iteration = 105 | loss = 1.694181 
iteration = 0 | loss = 1.461457 
iteration = 5 | loss = 1.509279 
iteration = 10 | loss = 1.684126 
iteration = 15 | loss = 1.675968 
iteration = 20 | loss = 2.036232 
iteration = 25 | loss = 1.516439 
iteration = 30 | loss = 1.629962 
iteration = 35 | loss = 1.520140 
iteration = 40 | loss = 1.655688 
iteration = 45 | loss = 1.829747 
iteration = 50 | loss = 1.745395 
iteration = 55 | loss = 1.525485 
iteration = 60 | loss = 1.506555 
iteration = 65 | loss = 1.536757 
iteration = 70 | loss = 1.595238 
iteration = 75 | loss = 1.704443 
iteration = 80 | loss = 1.732797 
iteration = 85 | loss = 2.019463 
iteration = 90 | loss = 1.707221 
iteration = 95 | loss = 1.677845 
iteration = 100 | loss = 1.939568 
iteration = 105 | loss = 1.805192 
iteration = 0 | loss = 1.719930 
iteration = 5 | loss = 1.440754 
iteration = 10 | loss = 2.076331 
iteration = 15 | loss = 1.629184 
iteration = 20 | loss = 2.044223 
iteration = 25 | loss = 1.616041 
iteration = 30 | loss = 1.553863 
iteration = 35 | loss = 1.803818 
iteration = 40 | loss = 1.643038 
iteration = 45 | loss = 1.818599 
iteration = 50 | loss = 1.610485 
iteration = 55 | loss = 1.640018 
iteration = 60 | loss = 1.528036 
iteration = 65 | loss = 1.729433 
iteration = 70 | loss = 1.630024 
iteration = 75 | loss = 1.541290 
iteration = 80 | loss = 1.952094 
iteration = 85 | loss = 1.581065 
iteration = 90 | loss = 1.736706 
iteration = 95 | loss = 1.756002 
iteration = 100 | loss = 1.716236 
iteration = 105 | loss = 2.081477 
iteration = 0 | loss = 1.743877 
iteration = 5 | loss = 1.773829 
iteration = 10 | loss = 1.449599 
iteration = 15 | loss = 2.121504 
iteration = 20 | loss = 1.746078 
iteration = 25 | loss = 1.392881 
iteration = 30 | loss = 1.864037 
iteration = 35 | loss = 1.637481 
iteration = 40 | loss = 1.974420 
iteration = 45 | loss = 1.973595 
iteration = 50 | loss = 1.644106 
iteration = 55 | loss = 2.385243 
iteration = 60 | loss = 1.884689 
iteration = 65 | loss = 1.808108 
iteration = 70 | loss = 1.897803 
iteration = 75 | loss = 1.539941 
iteration = 80 | loss = 1.792006 
iteration = 85 | loss = 1.624340 
iteration = 90 | loss = 1.486217 
iteration = 95 | loss = 1.707202 
iteration = 100 | loss = 2.014663 
iteration = 105 | loss = 1.592315 
 Epoch: [90] Loss: 1.5806  R1_I2A: 0.5645 R1_A2I: 0.4509 
                 
iteration = 0 | loss = 1.777958 
iteration = 5 | loss = 1.600365 
iteration = 10 | loss = 1.650958 
iteration = 15 | loss = 1.852471 
iteration = 20 | loss = 2.151348 
iteration = 25 | loss = 1.975343 
iteration = 30 | loss = 1.516913 
iteration = 35 | loss = 1.657230 
iteration = 40 | loss = 1.551768 
iteration = 45 | loss = 1.883968 
iteration = 50 | loss = 2.015684 
iteration = 55 | loss = 1.975921 
iteration = 60 | loss = 1.758270 
iteration = 65 | loss = 2.020963 
iteration = 70 | loss = 1.903304 
iteration = 75 | loss = 2.188162 
iteration = 80 | loss = 1.887055 
iteration = 85 | loss = 1.837102 
iteration = 90 | loss = 1.756620 
iteration = 95 | loss = 1.657221 
iteration = 100 | loss = 2.052483 
iteration = 105 | loss = 1.659756 
iteration = 0 | loss = 1.874492 
iteration = 5 | loss = 1.637594 
iteration = 10 | loss = 1.772141 
iteration = 15 | loss = 2.203097 
iteration = 20 | loss = 2.046923 
iteration = 25 | loss = 1.410031 
iteration = 30 | loss = 1.819382 
iteration = 35 | loss = 2.081842 
iteration = 40 | loss = 2.104656 
iteration = 45 | loss = 2.290337 
iteration = 50 | loss = 1.928978 
iteration = 55 | loss = 2.005255 
iteration = 60 | loss = 1.702543 
iteration = 65 | loss = 1.852897 
iteration = 70 | loss = 2.001217 
iteration = 75 | loss = 2.069565 
iteration = 80 | loss = 1.536929 
iteration = 85 | loss = 1.880115 
iteration = 90 | loss = 1.755177 
iteration = 95 | loss = 2.025640 
iteration = 100 | loss = 1.726448 
iteration = 105 | loss = 1.852801 
iteration = 0 | loss = 1.895978 
iteration = 5 | loss = 1.711277 
iteration = 10 | loss = 2.039427 
iteration = 15 | loss = 1.545031 
iteration = 20 | loss = 1.817052 
iteration = 25 | loss = 1.587615 
iteration = 30 | loss = 2.200876 
iteration = 35 | loss = 1.694419 
iteration = 40 | loss = 1.661201 
iteration = 45 | loss = 2.056691 
iteration = 50 | loss = 1.767821 
iteration = 55 | loss = 1.899446 
iteration = 60 | loss = 2.017522 
iteration = 65 | loss = 1.687262 
iteration = 70 | loss = 2.005978 
iteration = 75 | loss = 1.692913 
iteration = 80 | loss = 1.769046 
iteration = 85 | loss = 2.002155 
iteration = 90 | loss = 2.270529 
iteration = 95 | loss = 2.299383 
iteration = 100 | loss = 1.902146 
iteration = 105 | loss = 1.641134 
iteration = 0 | loss = 1.436074 
iteration = 5 | loss = 1.968348 
iteration = 10 | loss = 1.953423 
iteration = 15 | loss = 1.752045 
iteration = 20 | loss = 1.796382 
iteration = 25 | loss = 1.448209 
iteration = 30 | loss = 1.819777 
iteration = 35 | loss = 1.624429 
iteration = 40 | loss = 1.578614 
iteration = 45 | loss = 1.702917 
iteration = 50 | loss = 1.750663 
iteration = 55 | loss = 1.732661 
iteration = 60 | loss = 1.666166 
iteration = 65 | loss = 1.860455 
iteration = 70 | loss = 2.330439 
iteration = 75 | loss = 2.061278 
iteration = 80 | loss = 1.970243 
iteration = 85 | loss = 1.729867 
iteration = 90 | loss = 2.076721 
iteration = 95 | loss = 1.946975 
iteration = 100 | loss = 2.027608 
iteration = 105 | loss = 1.881900 
iteration = 0 | loss = 1.839267 
iteration = 5 | loss = 1.316115 
iteration = 10 | loss = 1.876298 
iteration = 15 | loss = 1.602495 
iteration = 20 | loss = 1.818992 
iteration = 25 | loss = 1.788803 
iteration = 30 | loss = 1.881120 
iteration = 35 | loss = 1.934638 
iteration = 40 | loss = 1.463704 
iteration = 45 | loss = 1.502314 
iteration = 50 | loss = 1.867597 
iteration = 55 | loss = 2.195188 
iteration = 60 | loss = 1.660588 
iteration = 65 | loss = 1.729047 
iteration = 70 | loss = 1.936612 
iteration = 75 | loss = 1.811980 
iteration = 80 | loss = 1.725110 
iteration = 85 | loss = 1.901096 
iteration = 90 | loss = 2.141132 
iteration = 95 | loss = 1.700348 
iteration = 100 | loss = 1.466950 
iteration = 105 | loss = 1.852012 
 Epoch: [95] Loss: 1.6930  R1_I2A: 0.5887 R1_A2I: 0.4636 
                 
 Epoch: [95] Loss: 1.6930  R1_I2A: 0.5889 mAP_I2A: 0.5126  R1_A2I: 0.4636 mAP_A2I: 0.4048 
                     
iteration = 0 | loss = 1.791402 
iteration = 5 | loss = 1.738618 
iteration = 10 | loss = 1.906314 
iteration = 15 | loss = 1.848581 
iteration = 20 | loss = 1.670705 
iteration = 25 | loss = 1.727019 
iteration = 30 | loss = 1.702233 
iteration = 35 | loss = 1.471020 
iteration = 40 | loss = 1.838359 
iteration = 45 | loss = 1.506795 
iteration = 50 | loss = 1.586525 
iteration = 55 | loss = 1.540215 
iteration = 60 | loss = 1.503757 
iteration = 65 | loss = 2.115847 
iteration = 70 | loss = 1.476211 
iteration = 75 | loss = 1.745542 
iteration = 80 | loss = 1.960506 
iteration = 85 | loss = 2.057454 
iteration = 90 | loss = 2.043723 
iteration = 95 | loss = 1.744314 
iteration = 100 | loss = 1.784948 
iteration = 105 | loss = 1.563210 
iteration = 0 | loss = 1.679365 
iteration = 5 | loss = 1.635721 
iteration = 10 | loss = 1.488781 
iteration = 15 | loss = 1.342314 
iteration = 20 | loss = 2.141636 
iteration = 25 | loss = 1.421454 
iteration = 30 | loss = 1.960205 
iteration = 35 | loss = 1.542458 
iteration = 40 | loss = 1.984350 
iteration = 45 | loss = 1.343553 
iteration = 50 | loss = 1.485164 
iteration = 55 | loss = 2.036841 
iteration = 60 | loss = 1.758752 
iteration = 65 | loss = 1.472159 
iteration = 70 | loss = 1.839643 
iteration = 75 | loss = 1.498710 
iteration = 80 | loss = 1.641317 
iteration = 85 | loss = 1.533511 
iteration = 90 | loss = 1.905248 
iteration = 95 | loss = 1.564621 
iteration = 100 | loss = 1.700657 
iteration = 105 | loss = 1.777075 
iteration = 0 | loss = 1.658026 
iteration = 5 | loss = 1.688414 
iteration = 10 | loss = 1.666717 
iteration = 15 | loss = 1.848044 
iteration = 20 | loss = 1.698767 
iteration = 25 | loss = 1.398006 
iteration = 30 | loss = 1.883064 
iteration = 35 | loss = 1.514028 
iteration = 40 | loss = 1.424077 
iteration = 45 | loss = 1.612490 
iteration = 50 | loss = 1.544801 
iteration = 55 | loss = 1.993079 
iteration = 60 | loss = 1.812883 
iteration = 65 | loss = 2.095133 
iteration = 70 | loss = 1.719068 
iteration = 75 | loss = 2.090597 
iteration = 80 | loss = 1.665243 
iteration = 85 | loss = 1.716326 
iteration = 90 | loss = 1.637091 
iteration = 95 | loss = 1.526536 
iteration = 100 | loss = 1.720784 
iteration = 105 | loss = 1.517131 
iteration = 0 | loss = 1.710319 
iteration = 5 | loss = 1.779690 
iteration = 10 | loss = 1.617720 
iteration = 15 | loss = 1.333610 
iteration = 20 | loss = 1.598383 
iteration = 25 | loss = 1.817710 
iteration = 30 | loss = 1.398158 
iteration = 35 | loss = 1.881495 
iteration = 40 | loss = 1.999828 
iteration = 45 | loss = 1.374279 
iteration = 50 | loss = 1.879775 
iteration = 55 | loss = 1.857760 
iteration = 60 | loss = 1.470670 
iteration = 65 | loss = 1.531657 
iteration = 70 | loss = 1.909969 
iteration = 75 | loss = 1.364075 
iteration = 80 | loss = 1.991540 
iteration = 85 | loss = 1.706790 
iteration = 90 | loss = 2.318782 
iteration = 95 | loss = 1.739716 
iteration = 100 | loss = 1.925377 
iteration = 105 | loss = 1.595612 
iteration = 0 | loss = 1.684713 
iteration = 5 | loss = 2.142414 
iteration = 10 | loss = 1.430513 
iteration = 15 | loss = 1.641403 
iteration = 20 | loss = 1.618597 
iteration = 25 | loss = 1.509057 
iteration = 30 | loss = 1.431110 
iteration = 35 | loss = 1.581671 
iteration = 40 | loss = 1.580543 
iteration = 45 | loss = 1.574279 
iteration = 50 | loss = 1.449037 
iteration = 55 | loss = 1.447911 
iteration = 60 | loss = 1.675679 
iteration = 65 | loss = 1.200847 
iteration = 70 | loss = 1.242612 
iteration = 75 | loss = 1.728725 
iteration = 80 | loss = 1.933371 
iteration = 85 | loss = 1.717246 
iteration = 90 | loss = 1.693102 
iteration = 95 | loss = 1.482059 
iteration = 100 | loss = 1.089787 
iteration = 105 | loss = 1.642721 
 Epoch: [100] Loss: 1.1540  R1_I2A: 0.5758 R1_A2I: 0.4720 
                 
iteration = 0 | loss = 1.562104 
iteration = 5 | loss = 1.474678 
iteration = 10 | loss = 1.572734 
iteration = 15 | loss = 1.589268 
iteration = 20 | loss = 1.671852 
iteration = 25 | loss = 1.585595 
iteration = 30 | loss = 1.399522 
iteration = 35 | loss = 1.348794 
iteration = 40 | loss = 1.513848 
iteration = 45 | loss = 1.404654 
iteration = 50 | loss = 1.290827 
iteration = 55 | loss = 1.476555 
iteration = 60 | loss = 1.289196 
iteration = 65 | loss = 1.283569 
iteration = 70 | loss = 1.601187 
iteration = 75 | loss = 1.180526 
iteration = 80 | loss = 1.631818 
iteration = 85 | loss = 1.880938 
iteration = 90 | loss = 1.263835 
iteration = 95 | loss = 1.906934 
iteration = 100 | loss = 1.512267 
iteration = 105 | loss = 1.590935 
iteration = 0 | loss = 1.692273 
iteration = 5 | loss = 1.677341 
iteration = 10 | loss = 1.475627 
iteration = 15 | loss = 1.831732 
iteration = 20 | loss = 1.525289 
iteration = 25 | loss = 1.681518 
iteration = 30 | loss = 1.665766 
iteration = 35 | loss = 1.675274 
iteration = 40 | loss = 1.939550 
iteration = 45 | loss = 1.460892 
iteration = 50 | loss = 1.532698 
iteration = 55 | loss = 1.538181 
iteration = 60 | loss = 1.467231 
iteration = 65 | loss = 1.371584 
iteration = 70 | loss = 1.284853 
iteration = 75 | loss = 1.635424 
iteration = 80 | loss = 1.660111 
iteration = 85 | loss = 1.340777 
iteration = 90 | loss = 1.502459 
iteration = 95 | loss = 1.586379 
iteration = 100 | loss = 1.130170 
iteration = 105 | loss = 1.491248 
iteration = 0 | loss = 1.735588 
iteration = 5 | loss = 1.752684 
iteration = 10 | loss = 0.978618 
iteration = 15 | loss = 1.278093 
iteration = 20 | loss = 1.565588 
iteration = 25 | loss = 1.703626 
iteration = 30 | loss = 1.809812 
iteration = 35 | loss = 1.576328 
iteration = 40 | loss = 1.726608 
iteration = 45 | loss = 1.549265 
iteration = 50 | loss = 1.956630 
iteration = 55 | loss = 1.734544 
iteration = 60 | loss = 1.795896 
iteration = 65 | loss = 1.516689 
iteration = 70 | loss = 1.877248 
iteration = 75 | loss = 1.481840 
iteration = 80 | loss = 1.575959 
iteration = 85 | loss = 1.484683 
iteration = 90 | loss = 1.481786 
iteration = 95 | loss = 1.832620 
iteration = 100 | loss = 1.443428 
iteration = 105 | loss = 1.664560 
iteration = 0 | loss = 1.556956 
iteration = 5 | loss = 1.660881 
iteration = 10 | loss = 1.772973 
iteration = 15 | loss = 1.736142 
iteration = 20 | loss = 1.481504 
iteration = 25 | loss = 1.574475 
iteration = 30 | loss = 1.534785 
iteration = 35 | loss = 1.593933 
iteration = 40 | loss = 1.529482 
iteration = 45 | loss = 1.026764 
iteration = 50 | loss = 1.279685 
iteration = 55 | loss = 1.356081 
iteration = 60 | loss = 1.630141 
iteration = 65 | loss = 1.325424 
iteration = 70 | loss = 1.626104 
iteration = 75 | loss = 1.509616 
iteration = 80 | loss = 1.674552 
iteration = 85 | loss = 1.522263 
iteration = 90 | loss = 1.509292 
iteration = 95 | loss = 1.345921 
iteration = 100 | loss = 1.511426 
iteration = 105 | loss = 1.554139 
iteration = 0 | loss = 1.275555 
iteration = 5 | loss = 1.619916 
iteration = 10 | loss = 1.558150 
iteration = 15 | loss = 1.621575 
iteration = 20 | loss = 1.891406 
iteration = 25 | loss = 1.603044 
iteration = 30 | loss = 1.303871 
iteration = 35 | loss = 1.643991 
iteration = 40 | loss = 1.714629 
iteration = 45 | loss = 1.237105 
iteration = 50 | loss = 1.918144 
iteration = 55 | loss = 1.283917 
iteration = 60 | loss = 1.302759 
iteration = 65 | loss = 1.574038 
iteration = 70 | loss = 1.725797 
iteration = 75 | loss = 1.717430 
iteration = 80 | loss = 1.268229 
iteration = 85 | loss = 1.592820 
iteration = 90 | loss = 1.307595 
iteration = 95 | loss = 1.487161 
iteration = 100 | loss = 1.179419 
iteration = 105 | loss = 1.510966 
 Epoch: [105] Loss: 1.3230  R1_I2A: 0.5498 R1_A2I: 0.4576 
                 
iteration = 0 | loss = 1.420791 
iteration = 5 | loss = 1.213769 
iteration = 10 | loss = 1.756576 
iteration = 15 | loss = 1.567199 
iteration = 20 | loss = 1.354855 
iteration = 25 | loss = 1.590500 
iteration = 30 | loss = 1.477317 
iteration = 35 | loss = 1.449594 
iteration = 40 | loss = 1.108926 
iteration = 45 | loss = 1.468226 
iteration = 50 | loss = 1.851106 
iteration = 55 | loss = 1.505436 
iteration = 60 | loss = 1.345349 
iteration = 65 | loss = 1.680019 
iteration = 70 | loss = 1.370241 
iteration = 75 | loss = 1.574414 
iteration = 80 | loss = 1.659311 
iteration = 85 | loss = 1.725555 
iteration = 90 | loss = 1.378230 
iteration = 95 | loss = 1.477159 
iteration = 100 | loss = 1.625962 
iteration = 105 | loss = 1.493051 
iteration = 0 | loss = 1.483811 
iteration = 5 | loss = 1.259642 
iteration = 10 | loss = 1.391207 
iteration = 15 | loss = 1.521880 
iteration = 20 | loss = 1.477337 
iteration = 25 | loss = 1.286116 
iteration = 30 | loss = 1.641639 
iteration = 35 | loss = 1.254341 
iteration = 40 | loss = 1.378202 
iteration = 45 | loss = 1.373110 
iteration = 50 | loss = 1.250618 
iteration = 55 | loss = 1.808978 
iteration = 60 | loss = 1.777586 
iteration = 65 | loss = 1.606540 
iteration = 70 | loss = 1.469503 
iteration = 75 | loss = 1.286979 
iteration = 80 | loss = 1.291221 
iteration = 85 | loss = 1.422705 
iteration = 90 | loss = 1.456213 
iteration = 95 | loss = 1.586514 
iteration = 100 | loss = 1.753585 
iteration = 105 | loss = 2.059812 
iteration = 0 | loss = 1.127891 
iteration = 5 | loss = 1.489091 
iteration = 10 | loss = 1.634416 
iteration = 15 | loss = 1.309993 
iteration = 20 | loss = 1.518153 
iteration = 25 | loss = 1.238813 
iteration = 30 | loss = 1.766722 
iteration = 35 | loss = 1.387613 
iteration = 40 | loss = 1.197990 
iteration = 45 | loss = 1.254423 
iteration = 50 | loss = 1.790420 
iteration = 55 | loss = 1.217795 
iteration = 60 | loss = 1.364699 
iteration = 65 | loss = 1.495729 
iteration = 70 | loss = 1.408105 
iteration = 75 | loss = 1.266056 
iteration = 80 | loss = 1.569575 
iteration = 85 | loss = 1.437905 
iteration = 90 | loss = 1.690464 
iteration = 95 | loss = 1.553999 
iteration = 100 | loss = 1.358047 
iteration = 105 | loss = 1.439766 
iteration = 0 | loss = 1.227883 
iteration = 5 | loss = 1.705173 
iteration = 10 | loss = 1.247207 
iteration = 15 | loss = 1.374864 
iteration = 20 | loss = 1.406065 
iteration = 25 | loss = 1.470785 
iteration = 30 | loss = 1.063513 
iteration = 35 | loss = 1.746883 
iteration = 40 | loss = 1.203301 
iteration = 45 | loss = 1.151024 
iteration = 50 | loss = 1.285856 
iteration = 55 | loss = 1.268826 
iteration = 60 | loss = 1.364322 
iteration = 65 | loss = 1.333575 
iteration = 70 | loss = 1.235556 
iteration = 75 | loss = 1.523195 
iteration = 80 | loss = 1.338543 
iteration = 85 | loss = 1.491863 
iteration = 90 | loss = 1.668934 
iteration = 95 | loss = 1.356114 
iteration = 100 | loss = 1.280168 
iteration = 105 | loss = 1.386224 
iteration = 0 | loss = 1.485707 
iteration = 5 | loss = 1.417321 
iteration = 10 | loss = 1.648880 
iteration = 15 | loss = 1.605213 
iteration = 20 | loss = 1.324518 
iteration = 25 | loss = 1.630857 
iteration = 30 | loss = 1.447541 
iteration = 35 | loss = 1.334687 
iteration = 40 | loss = 1.105324 
iteration = 45 | loss = 1.357093 
iteration = 50 | loss = 1.331449 
iteration = 55 | loss = 1.602600 
iteration = 60 | loss = 1.369233 
iteration = 65 | loss = 1.091675 
iteration = 70 | loss = 1.334935 
iteration = 75 | loss = 1.394437 
iteration = 80 | loss = 1.510764 
iteration = 85 | loss = 0.981554 
iteration = 90 | loss = 1.621869 
iteration = 95 | loss = 1.606930 
iteration = 100 | loss = 1.604719 
iteration = 105 | loss = 1.750679 
 Epoch: [110] Loss: 1.4751  R1_I2A: 0.5680 R1_A2I: 0.4485 
                 
iteration = 0 | loss = 1.511387 
iteration = 5 | loss = 1.335468 
iteration = 10 | loss = 1.410746 
iteration = 15 | loss = 1.360804 
iteration = 20 | loss = 1.556275 
iteration = 25 | loss = 1.644622 
iteration = 30 | loss = 1.204726 
iteration = 35 | loss = 1.478434 
iteration = 40 | loss = 1.190400 
iteration = 45 | loss = 1.322992 
iteration = 50 | loss = 1.363936 
iteration = 55 | loss = 1.074281 
iteration = 60 | loss = 1.564601 
iteration = 65 | loss = 1.502766 
iteration = 70 | loss = 1.300441 
iteration = 75 | loss = 1.575027 
iteration = 80 | loss = 1.546066 
iteration = 85 | loss = 1.241019 
iteration = 90 | loss = 1.452022 
iteration = 95 | loss = 1.442816 
iteration = 100 | loss = 1.829913 
iteration = 105 | loss = 1.692368 
iteration = 0 | loss = 1.550766 
iteration = 5 | loss = 1.318546 
iteration = 10 | loss = 1.293082 
iteration = 15 | loss = 1.428545 
iteration = 20 | loss = 1.629991 
iteration = 25 | loss = 1.435432 
iteration = 30 | loss = 1.345791 
iteration = 35 | loss = 1.759231 
iteration = 40 | loss = 1.408785 
iteration = 45 | loss = 1.520356 
iteration = 50 | loss = 1.263847 
iteration = 55 | loss = 1.781168 
iteration = 60 | loss = 1.336392 
iteration = 65 | loss = 1.297972 
iteration = 70 | loss = 1.535939 
iteration = 75 | loss = 1.613309 
iteration = 80 | loss = 1.394600 
iteration = 85 | loss = 1.514814 
iteration = 90 | loss = 1.050497 
iteration = 95 | loss = 1.523720 
iteration = 100 | loss = 1.194524 
iteration = 105 | loss = 1.199066 
iteration = 0 | loss = 1.358107 
iteration = 5 | loss = 1.518127 
iteration = 10 | loss = 1.453718 
iteration = 15 | loss = 1.631586 
iteration = 20 | loss = 1.476221 
iteration = 25 | loss = 1.436124 
iteration = 30 | loss = 1.398478 
iteration = 35 | loss = 1.526639 
iteration = 40 | loss = 1.313585 
iteration = 45 | loss = 1.415828 
iteration = 50 | loss = 1.519719 
iteration = 55 | loss = 1.174273 
iteration = 60 | loss = 1.341008 
iteration = 65 | loss = 1.442763 
iteration = 70 | loss = 1.306185 
iteration = 75 | loss = 1.612010 
iteration = 80 | loss = 1.137071 
iteration = 85 | loss = 1.409564 
iteration = 90 | loss = 1.485134 
iteration = 95 | loss = 1.327229 
iteration = 100 | loss = 1.576526 
iteration = 105 | loss = 1.206174 
iteration = 0 | loss = 1.445974 
iteration = 5 | loss = 1.184086 
iteration = 10 | loss = 1.100969 
iteration = 15 | loss = 1.509326 
iteration = 20 | loss = 1.204049 
iteration = 25 | loss = 1.097133 
iteration = 30 | loss = 1.512414 
iteration = 35 | loss = 1.283744 
iteration = 40 | loss = 1.066108 
iteration = 45 | loss = 1.514580 
iteration = 50 | loss = 1.530640 
iteration = 55 | loss = 1.328456 
iteration = 60 | loss = 1.155480 
iteration = 65 | loss = 1.364870 
iteration = 70 | loss = 1.295719 
iteration = 75 | loss = 1.119571 
iteration = 80 | loss = 1.618424 
iteration = 85 | loss = 1.391834 
iteration = 90 | loss = 1.359384 
iteration = 95 | loss = 1.557755 
iteration = 100 | loss = 1.346788 
iteration = 105 | loss = 1.648664 
iteration = 0 | loss = 1.407875 
iteration = 5 | loss = 1.436685 
iteration = 10 | loss = 1.017846 
iteration = 15 | loss = 1.210205 
iteration = 20 | loss = 1.219394 
iteration = 25 | loss = 1.437055 
iteration = 30 | loss = 1.419595 
iteration = 35 | loss = 1.462394 
iteration = 40 | loss = 1.093095 
iteration = 45 | loss = 1.461220 
iteration = 50 | loss = 1.176625 
iteration = 55 | loss = 1.018360 
iteration = 60 | loss = 1.100237 
iteration = 65 | loss = 1.359949 
iteration = 70 | loss = 1.236995 
iteration = 75 | loss = 1.192127 
iteration = 80 | loss = 1.396564 
iteration = 85 | loss = 1.201225 
iteration = 90 | loss = 1.275509 
iteration = 95 | loss = 1.481596 
iteration = 100 | loss = 1.365762 
iteration = 105 | loss = 1.358720 
 Epoch: [115] Loss: 1.3112  R1_I2A: 0.5524 R1_A2I: 0.4429 
                 
iteration = 0 | loss = 1.539640 
iteration = 5 | loss = 1.406262 
iteration = 10 | loss = 1.199386 
iteration = 15 | loss = 1.548278 
iteration = 20 | loss = 1.168471 
iteration = 25 | loss = 1.163831 
iteration = 30 | loss = 0.928396 
iteration = 35 | loss = 1.148170 
iteration = 40 | loss = 1.030999 
iteration = 45 | loss = 1.252078 
iteration = 50 | loss = 1.069587 
iteration = 55 | loss = 1.098443 
iteration = 60 | loss = 1.377955 
iteration = 65 | loss = 1.166011 
iteration = 70 | loss = 1.472416 
iteration = 75 | loss = 1.197032 
iteration = 80 | loss = 0.964064 
iteration = 85 | loss = 1.117352 
iteration = 90 | loss = 1.101311 
iteration = 95 | loss = 1.165480 
iteration = 100 | loss = 1.414690 
iteration = 105 | loss = 1.330328 
iteration = 0 | loss = 1.137516 
iteration = 5 | loss = 1.313986 
iteration = 10 | loss = 1.284388 
iteration = 15 | loss = 0.990543 
iteration = 20 | loss = 1.148250 
iteration = 25 | loss = 1.013844 
iteration = 30 | loss = 1.413909 
iteration = 35 | loss = 1.122455 
iteration = 40 | loss = 1.215701 
iteration = 45 | loss = 1.247293 
iteration = 50 | loss = 1.319432 
iteration = 55 | loss = 1.221556 
iteration = 60 | loss = 1.049066 
iteration = 65 | loss = 1.361084 
iteration = 70 | loss = 1.128134 
iteration = 75 | loss = 1.208584 
iteration = 80 | loss = 1.254706 
iteration = 85 | loss = 1.330836 
iteration = 90 | loss = 0.964240 
iteration = 95 | loss = 0.976467 
iteration = 100 | loss = 1.079719 
iteration = 105 | loss = 1.334640 
iteration = 0 | loss = 1.308453 
iteration = 5 | loss = 1.116212 
iteration = 10 | loss = 0.712504 
iteration = 15 | loss = 1.105193 
iteration = 20 | loss = 1.174970 
iteration = 25 | loss = 1.041521 
iteration = 30 | loss = 1.475963 
iteration = 35 | loss = 0.902686 
iteration = 40 | loss = 0.914178 
iteration = 45 | loss = 1.016121 
iteration = 50 | loss = 1.121271 
iteration = 55 | loss = 1.313806 
iteration = 60 | loss = 1.137675 
iteration = 65 | loss = 1.328144 
iteration = 70 | loss = 1.308760 
iteration = 75 | loss = 1.206654 
iteration = 80 | loss = 0.873806 
iteration = 85 | loss = 1.285330 
iteration = 90 | loss = 1.024028 
iteration = 95 | loss = 1.186399 
iteration = 100 | loss = 1.216368 
iteration = 105 | loss = 1.150947 
iteration = 0 | loss = 1.213532 
iteration = 5 | loss = 1.157529 
iteration = 10 | loss = 1.112031 
iteration = 15 | loss = 1.246356 
iteration = 20 | loss = 0.961320 
iteration = 25 | loss = 1.174505 
iteration = 30 | loss = 1.497184 
iteration = 35 | loss = 1.090387 
iteration = 40 | loss = 1.272736 
iteration = 45 | loss = 1.117539 
iteration = 50 | loss = 1.174580 
iteration = 55 | loss = 1.397930 
iteration = 60 | loss = 1.341517 
iteration = 65 | loss = 1.010964 
iteration = 70 | loss = 1.156346 
iteration = 75 | loss = 1.075541 
iteration = 80 | loss = 1.127540 
iteration = 85 | loss = 1.278026 
iteration = 90 | loss = 1.330837 
iteration = 95 | loss = 1.237751 
iteration = 100 | loss = 1.358655 
iteration = 105 | loss = 1.337537 
iteration = 0 | loss = 1.006818 
iteration = 5 | loss = 1.277873 
iteration = 10 | loss = 1.296535 
iteration = 15 | loss = 1.101226 
iteration = 20 | loss = 1.274543 
iteration = 25 | loss = 1.043866 
iteration = 30 | loss = 1.111967 
iteration = 35 | loss = 1.191105 
iteration = 40 | loss = 1.088043 
iteration = 45 | loss = 1.357924 
iteration = 50 | loss = 1.211940 
iteration = 55 | loss = 1.033467 
iteration = 60 | loss = 1.576108 
iteration = 65 | loss = 0.952858 
iteration = 70 | loss = 1.290816 
iteration = 75 | loss = 1.187268 
iteration = 80 | loss = 1.249262 
iteration = 85 | loss = 1.153434 
iteration = 90 | loss = 1.387519 
iteration = 95 | loss = 1.200358 
iteration = 100 | loss = 1.381441 
iteration = 105 | loss = 1.385384 
 Epoch: [120] Loss: 1.3089  R1_I2A: 0.5541 R1_A2I: 0.4467 
                 
iteration = 0 | loss = 1.265903 
iteration = 5 | loss = 1.329240 
iteration = 10 | loss = 1.407753 
iteration = 15 | loss = 1.423268 
iteration = 20 | loss = 1.186362 
iteration = 25 | loss = 1.139280 
iteration = 30 | loss = 1.189847 
iteration = 35 | loss = 1.372669 
iteration = 40 | loss = 1.212189 
iteration = 45 | loss = 1.210185 
iteration = 50 | loss = 1.383416 
iteration = 55 | loss = 1.440065 
iteration = 60 | loss = 1.049344 
iteration = 65 | loss = 1.289449 
iteration = 70 | loss = 1.055826 
iteration = 75 | loss = 1.308683 
iteration = 80 | loss = 1.537674 
iteration = 85 | loss = 1.174060 
iteration = 90 | loss = 1.077215 
iteration = 95 | loss = 1.283904 
iteration = 100 | loss = 1.587657 
iteration = 105 | loss = 0.973150 

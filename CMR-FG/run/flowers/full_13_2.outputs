{'cmvn': False, 'margin': 0.5, 'max_length': 640, 'DATASET_NAME': 'flowers', 'DATASET_ALL_CLSS_NUM': 102, 'DATASET_TRAIN_CLSS_NUM': 82, 'CONFIG_NAME': '', 'DATA_DIR': '/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102', 'GPU_ID': 0, 'CUDA': True, 'WORKERS': 8, 'result_file': 'full.text', 'start_epoch': 40, 'RNN_TYPE': 'GRU', 'B_VALIDATION': False, 'image_attention': True, 'audio_attention': True, 'add_noise': False, 'TREE': {'BRANCH_NUM': 3, 'BASE_SIZE': 128}, 'TRAIN': {'MODAL': 'co-train', 'BATCH_SIZE': 64, 'MAX_EPOCH': 120, 'SNAPSHOT_INTERVAL': 2000, 'DISCRIMINATOR_LR': 0.0002, 'GENERATOR_LR': 0.0002, 'ENCODER_LR': 0.0002, 'RNN_GRAD_CLIP': 0.25, 'FLAG': True, 'NET_E': '', 'NET_G': '', 'B_NET_D': True, 'SMOOTH': {'GAMMA1': 5.0, 'GAMMA3': 13.0, 'GAMMA2': 5.0, 'LAMBDA': 1.0, 'IMGATT': 1.0, 'IMGATT2': 1.0}}, 'EXTRACT': {'split': 'train'}, 'CROSS_ATT': {'att': False, 'act': 'sigmoid', 'smooth_soft': 1.0, 'smooth_sigm': 0.1}, 'GAN': {'DF_DIM': 64, 'GF_DIM': 128, 'Z_DIM': 100, 'CONDITION_DIM': 100, 'R_NUM': 2, 'B_ATTENTION': True, 'B_DCGAN': False}, 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18}, 'IMG': {'style': 'raw'}, 'IMGF': {'Layer': 1, 'input_dim': 2048, 'hid_dim': 1600, 'embedding_dim': 1024}, 'rnn_type': 'LSTM', 'SPEECH': {'style': 'mel', 'model': 'CRNN', 'self_att': True, 'CAPTIONS_PER_IMAGE': 10, 'window_size': 25, 'stride': 10, 'input_dim': 40, 'hidden_size': 512, 'embedding_dim': 1024, 'num_layers': 2, 'sample': 22050, 'cmvn': True}, 'CNNRNN': {'rnn_type': 'GRU', 'in_channels': 40, 'hid_channels': 64, 'hid2_channels': 64, 'out_channels': 128, 'kernel_size': 6, 'stride': 2, 'padding': 0}, 'CNNRNN_RNN': {'input_size': 128, 'hidden_size': 512, 'num_layers': 2, 'dropout': 0.0, 'bidirectional': True}, 'CNNRNN_ATT': {'in_size': 1024, 'hidden_size': 128, 'n_heads': 1}, 'RNN': {'input_size': 40, 'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.0, 'bidirectional': True}, 'RNN_ATT': {'in_size': 2048, 'hidden_size': 128, 'n_heads': 5}, 'CLASSIFICATION': {'data': 'audio'}, 'EVALUATE': {'dist': 'cosine'}, 'Loss': {'clss': True, 'cont': False, 'hinge': False, 'batch': True, 'KL': False, 'deco': False, 'adv': False, 'trip': False, 'dist': False, 'divers': False, 'batch_loc': False, 'disc': True, 'gamma_disc': 1.0, 'gamma_batch_loc': 1.0, 'gamma_divers': 1.0, 'gamma_clss': 1.0, 'gamma_cont': 1.0, 'gamma_hinge': 1.0, 'gamma_batch': 1.0, 'gamma_KL': 1.0, 'gamma_deco': 1.0, 'gamma_adv': 1.0, 'hinge_margin': 1.0, 'gamma_trip': 1.0, 'trip_margin': 1.0, 'gamma_dist': 1.0, 'dist_T': 1.0, 'adv_k': 5}, 'TEST': {'topk': 3}, 'exp_dir': 'outputs/01_Baseline/flowers/full_13/pre-train'}
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 2.692301 
iteration = 5 | loss = 2.692029 
iteration = 10 | loss = 2.651894 
iteration = 15 | loss = 2.770232 
iteration = 20 | loss = 2.438262 
iteration = 25 | loss = 3.811308 
iteration = 30 | loss = 2.320226 
iteration = 35 | loss = 3.230103 
iteration = 40 | loss = 2.634019 
iteration = 45 | loss = 3.499302 
iteration = 50 | loss = 3.015029 
iteration = 55 | loss = 2.621964 
iteration = 60 | loss = 2.474372 
iteration = 65 | loss = 2.962080 
iteration = 70 | loss = 2.835939 
iteration = 75 | loss = 2.515096 
iteration = 80 | loss = 2.808550 
iteration = 85 | loss = 3.040689 
iteration = 90 | loss = 2.623604 
iteration = 95 | loss = 2.758803 
iteration = 100 | loss = 2.795851 
iteration = 105 | loss = 2.456290 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 2.786388 
iteration = 5 | loss = 2.575346 
iteration = 10 | loss = 2.952388 
iteration = 15 | loss = 2.657862 
iteration = 20 | loss = 2.808999 
iteration = 25 | loss = 2.810645 
iteration = 30 | loss = 2.780196 
iteration = 35 | loss = 2.373775 
iteration = 40 | loss = 2.927588 
iteration = 45 | loss = 2.781253 
iteration = 50 | loss = 2.336194 
iteration = 55 | loss = 2.482458 
iteration = 60 | loss = 2.802674 
iteration = 65 | loss = 3.231741 
iteration = 70 | loss = 2.349263 
iteration = 75 | loss = 2.741312 
iteration = 80 | loss = 2.775637 
iteration = 85 | loss = 2.255455 
iteration = 90 | loss = 2.857597 
iteration = 95 | loss = 2.770888 
iteration = 100 | loss = 2.276654 
iteration = 105 | loss = 2.289918 
iteration = 0 | loss = 2.901666 
iteration = 5 | loss = 2.038474 
iteration = 10 | loss = 1.939587 
iteration = 15 | loss = 2.981988 
iteration = 20 | loss = 2.781294 
iteration = 25 | loss = 3.149297 
iteration = 30 | loss = 2.343251 
iteration = 35 | loss = 3.076654 
iteration = 40 | loss = 2.956173 
iteration = 45 | loss = 2.011090 
iteration = 50 | loss = 2.699965 
iteration = 55 | loss = 2.293476 
iteration = 60 | loss = 2.404837 
iteration = 65 | loss = 2.372225 
iteration = 70 | loss = 2.686662 
iteration = 75 | loss = 2.210805 
iteration = 80 | loss = 1.853814 
iteration = 85 | loss = 2.892399 
iteration = 90 | loss = 2.261206 
iteration = 95 | loss = 2.673451 
iteration = 100 | loss = 2.266198 
iteration = 105 | loss = 2.660738 
iteration = 0 | loss = 2.360925 
iteration = 5 | loss = 2.432513 
iteration = 10 | loss = 2.619017 
iteration = 15 | loss = 2.159914 
iteration = 20 | loss = 2.567167 
iteration = 25 | loss = 2.642264 
iteration = 30 | loss = 2.540197 
iteration = 35 | loss = 2.313229 
iteration = 40 | loss = 2.365952 
iteration = 45 | loss = 2.504049 
iteration = 50 | loss = 2.736259 
iteration = 55 | loss = 2.564564 
iteration = 60 | loss = 2.698170 
iteration = 65 | loss = 2.556838 
iteration = 70 | loss = 2.138262 
iteration = 75 | loss = 2.709032 
iteration = 80 | loss = 1.949913 
iteration = 85 | loss = 2.553980 
iteration = 90 | loss = 2.037430 
iteration = 95 | loss = 2.539792 
iteration = 100 | loss = 2.322316 
iteration = 105 | loss = 2.359136 
iteration = 0 | loss = 2.290389 
iteration = 5 | loss = 2.637032 
iteration = 10 | loss = 1.771682 
iteration = 15 | loss = 2.362200 
iteration = 20 | loss = 2.450095 
iteration = 25 | loss = 2.108191 
iteration = 30 | loss = 2.194529 
iteration = 35 | loss = 2.140060 
iteration = 40 | loss = 2.783853 
iteration = 45 | loss = 2.872163 
iteration = 50 | loss = 2.614252 
iteration = 55 | loss = 2.412630 
iteration = 60 | loss = 2.310464 
iteration = 65 | loss = 2.500087 
iteration = 70 | loss = 2.514097 
iteration = 75 | loss = 2.393429 
iteration = 80 | loss = 3.029487 
iteration = 85 | loss = 2.840550 
iteration = 90 | loss = 2.453296 
iteration = 95 | loss = 2.252588 
iteration = 100 | loss = 2.458109 
iteration = 105 | loss = 2.465405 
 Epoch: [45] Loss: 2.4949  R1_I2A: 0.6130 R1_A2I: 0.4802 
                 
 Epoch: [45] Loss: 2.4949  R1_I2A: 0.6128 mAP_I2A: 0.5321  R1_A2I: 0.4802 mAP_A2I: 0.4220 
                     
iteration = 0 | loss = 2.884965 
iteration = 5 | loss = 2.189709 
iteration = 10 | loss = 2.455809 
iteration = 15 | loss = 2.566373 
iteration = 20 | loss = 2.911876 
iteration = 25 | loss = 2.530245 
iteration = 30 | loss = 2.449634 
iteration = 35 | loss = 2.144622 
iteration = 40 | loss = 2.251116 
iteration = 45 | loss = 2.279004 
iteration = 50 | loss = 2.401840 
iteration = 55 | loss = 2.783069 
iteration = 60 | loss = 2.308939 
iteration = 65 | loss = 2.674360 
iteration = 70 | loss = 2.559188 
iteration = 75 | loss = 2.711360 
iteration = 80 | loss = 2.490828 
iteration = 85 | loss = 2.525289 
iteration = 90 | loss = 2.548602 
iteration = 95 | loss = 2.711105 
iteration = 100 | loss = 2.605611 
iteration = 105 | loss = 2.793226 
iteration = 0 | loss = 2.506692 
iteration = 5 | loss = 2.223756 
iteration = 10 | loss = 2.237555 
iteration = 15 | loss = 2.371769 
iteration = 20 | loss = 2.374385 
iteration = 25 | loss = 2.511368 
iteration = 30 | loss = 2.130617 
iteration = 35 | loss = 2.522405 
iteration = 40 | loss = 2.582790 
iteration = 45 | loss = 2.257434 
iteration = 50 | loss = 2.515165 
iteration = 55 | loss = 3.134382 
iteration = 60 | loss = 2.418680 
iteration = 65 | loss = 2.212455 
iteration = 70 | loss = 2.649029 
iteration = 75 | loss = 2.577215 
iteration = 80 | loss = 2.923563 
iteration = 85 | loss = 1.971480 
iteration = 90 | loss = 1.774372 
iteration = 95 | loss = 2.829872 
iteration = 100 | loss = 2.289745 
iteration = 105 | loss = 2.565313 
iteration = 0 | loss = 2.094637 
iteration = 5 | loss = 2.396297 
iteration = 10 | loss = 2.440508 
iteration = 15 | loss = 2.247465 
iteration = 20 | loss = 2.800061 
iteration = 25 | loss = 2.437783 
iteration = 30 | loss = 1.920139 
iteration = 35 | loss = 2.452006 
iteration = 40 | loss = 2.339031 
iteration = 45 | loss = 2.581622 
iteration = 50 | loss = 2.568729 
iteration = 55 | loss = 2.424537 
iteration = 60 | loss = 2.385912 
iteration = 65 | loss = 2.262665 
iteration = 70 | loss = 2.269739 
iteration = 75 | loss = 2.142434 
iteration = 80 | loss = 2.381232 
iteration = 85 | loss = 2.602407 
iteration = 90 | loss = 2.713976 
iteration = 95 | loss = 2.632041 
iteration = 100 | loss = 2.607613 
iteration = 105 | loss = 2.702775 
iteration = 0 | loss = 2.630150 
iteration = 5 | loss = 2.026156 
iteration = 10 | loss = 2.908749 
iteration = 15 | loss = 2.085944 
iteration = 20 | loss = 2.801770 
iteration = 25 | loss = 2.084491 
iteration = 30 | loss = 2.436934 
iteration = 35 | loss = 2.439175 
iteration = 40 | loss = 2.253963 
iteration = 45 | loss = 2.613104 
iteration = 50 | loss = 2.511920 
iteration = 55 | loss = 2.519867 
iteration = 60 | loss = 2.253725 
iteration = 65 | loss = 2.605318 
iteration = 70 | loss = 2.772672 
iteration = 75 | loss = 2.273270 
iteration = 80 | loss = 2.580805 
iteration = 85 | loss = 2.049816 
iteration = 90 | loss = 2.366423 
iteration = 95 | loss = 2.568784 
iteration = 100 | loss = 2.535444 
iteration = 105 | loss = 2.692427 
iteration = 0 | loss = 2.452275 
iteration = 5 | loss = 2.528245 
iteration = 10 | loss = 1.870631 
iteration = 15 | loss = 3.017086 
iteration = 20 | loss = 2.257823 
iteration = 25 | loss = 2.048020 
iteration = 30 | loss = 2.288253 
iteration = 35 | loss = 2.043422 
iteration = 40 | loss = 2.564748 
iteration = 45 | loss = 2.650254 
iteration = 50 | loss = 2.355854 
iteration = 55 | loss = 2.890021 
iteration = 60 | loss = 2.539190 
iteration = 65 | loss = 2.654166 
iteration = 70 | loss = 2.554891 
iteration = 75 | loss = 2.079401 
iteration = 80 | loss = 2.540745 
iteration = 85 | loss = 2.187360 
iteration = 90 | loss = 2.331134 
iteration = 95 | loss = 2.438556 
iteration = 100 | loss = 2.601665 
iteration = 105 | loss = 2.039900 
 Epoch: [50] Loss: 1.9960  R1_I2A: 0.5723 R1_A2I: 0.4848 
                 
iteration = 0 | loss = 2.066570 
iteration = 5 | loss = 2.080221 
iteration = 10 | loss = 2.241806 
iteration = 15 | loss = 2.011791 
iteration = 20 | loss = 2.562763 
iteration = 25 | loss = 2.531839 
iteration = 30 | loss = 2.307450 
iteration = 35 | loss = 2.164320 
iteration = 40 | loss = 1.989438 
iteration = 45 | loss = 2.451713 
iteration = 50 | loss = 2.377455 
iteration = 55 | loss = 2.245158 
iteration = 60 | loss = 2.107621 
iteration = 65 | loss = 2.600561 
iteration = 70 | loss = 2.322348 
iteration = 75 | loss = 2.567860 
iteration = 80 | loss = 2.481693 
iteration = 85 | loss = 2.280498 
iteration = 90 | loss = 2.407412 
iteration = 95 | loss = 2.048040 
iteration = 100 | loss = 2.693157 
iteration = 105 | loss = 2.364810 
iteration = 0 | loss = 2.265358 
iteration = 5 | loss = 2.113677 
iteration = 10 | loss = 2.132481 
iteration = 15 | loss = 2.444724 
iteration = 20 | loss = 2.372446 
iteration = 25 | loss = 1.688301 
iteration = 30 | loss = 2.177997 
iteration = 35 | loss = 2.424034 
iteration = 40 | loss = 2.608249 
iteration = 45 | loss = 2.563724 
iteration = 50 | loss = 2.358365 
iteration = 55 | loss = 2.487557 
iteration = 60 | loss = 2.113921 
iteration = 65 | loss = 2.096064 
iteration = 70 | loss = 2.466546 
iteration = 75 | loss = 2.586522 
iteration = 80 | loss = 1.886117 
iteration = 85 | loss = 2.367044 
iteration = 90 | loss = 1.818763 
iteration = 95 | loss = 2.276133 
iteration = 100 | loss = 2.058761 
iteration = 105 | loss = 2.278171 
iteration = 0 | loss = 2.340261 
iteration = 5 | loss = 1.946233 
iteration = 10 | loss = 2.508412 
iteration = 15 | loss = 1.933779 
iteration = 20 | loss = 2.083088 
iteration = 25 | loss = 2.319420 
iteration = 30 | loss = 2.758217 
iteration = 35 | loss = 2.104223 
iteration = 40 | loss = 1.989561 
iteration = 45 | loss = 2.779928 
iteration = 50 | loss = 2.144246 
iteration = 55 | loss = 2.237165 
iteration = 60 | loss = 2.391181 
iteration = 65 | loss = 1.831663 
iteration = 70 | loss = 2.370355 
iteration = 75 | loss = 2.203111 
iteration = 80 | loss = 2.143582 
iteration = 85 | loss = 2.074916 
iteration = 90 | loss = 2.432383 
iteration = 95 | loss = 2.749648 
iteration = 100 | loss = 2.222958 
iteration = 105 | loss = 2.178549 
iteration = 0 | loss = 1.944402 
iteration = 5 | loss = 2.507059 
iteration = 10 | loss = 2.427037 
iteration = 15 | loss = 2.218932 
iteration = 20 | loss = 1.952549 
iteration = 25 | loss = 1.810005 
iteration = 30 | loss = 2.568660 
iteration = 35 | loss = 1.723215 
iteration = 40 | loss = 1.878404 
iteration = 45 | loss = 2.224955 
iteration = 50 | loss = 2.104918 
iteration = 55 | loss = 2.107898 
iteration = 60 | loss = 2.153329 
iteration = 65 | loss = 2.414989 
iteration = 70 | loss = 2.800158 
iteration = 75 | loss = 2.395170 
iteration = 80 | loss = 2.389562 
iteration = 85 | loss = 2.044923 
iteration = 90 | loss = 2.361770 
iteration = 95 | loss = 2.385217 
iteration = 100 | loss = 2.384339 
iteration = 105 | loss = 2.297467 
iteration = 0 | loss = 2.073705 
iteration = 5 | loss = 1.588108 
iteration = 10 | loss = 2.229208 
iteration = 15 | loss = 2.139835 
iteration = 20 | loss = 2.213156 
iteration = 25 | loss = 1.975044 
iteration = 30 | loss = 2.012367 
iteration = 35 | loss = 2.539877 
iteration = 40 | loss = 1.956086 
iteration = 45 | loss = 1.826425 
iteration = 50 | loss = 2.285219 
iteration = 55 | loss = 2.460727 
iteration = 60 | loss = 2.118224 
iteration = 65 | loss = 1.887799 
iteration = 70 | loss = 2.355528 
iteration = 75 | loss = 2.206684 
iteration = 80 | loss = 2.067568 
iteration = 85 | loss = 2.495616 
iteration = 90 | loss = 2.488113 
iteration = 95 | loss = 2.146487 
iteration = 100 | loss = 2.027533 
iteration = 105 | loss = 2.216094 
 Epoch: [55] Loss: 2.0016  R1_I2A: 0.5905 R1_A2I: 0.4879 
                 
iteration = 0 | loss = 2.487497 
iteration = 5 | loss = 2.397099 
iteration = 10 | loss = 1.880636 
iteration = 15 | loss = 2.218022 
iteration = 20 | loss = 2.179587 
iteration = 25 | loss = 2.048275 
iteration = 30 | loss = 2.210231 
iteration = 35 | loss = 2.250988 
iteration = 40 | loss = 1.734095 
iteration = 45 | loss = 2.175434 
iteration = 50 | loss = 1.897727 
iteration = 55 | loss = 1.900036 
iteration = 60 | loss = 2.286818 
iteration = 65 | loss = 2.066254 
iteration = 70 | loss = 2.536893 
iteration = 75 | loss = 2.224098 
iteration = 80 | loss = 2.104335 
iteration = 85 | loss = 2.291069 
iteration = 90 | loss = 2.315929 
iteration = 95 | loss = 1.907884 
iteration = 100 | loss = 1.871868 
iteration = 105 | loss = 1.527578 
iteration = 0 | loss = 2.377352 
iteration = 5 | loss = 2.497072 
iteration = 10 | loss = 2.320792 
iteration = 15 | loss = 2.059795 
iteration = 20 | loss = 2.073512 
iteration = 25 | loss = 2.290183 
iteration = 30 | loss = 1.944657 
iteration = 35 | loss = 2.459397 
iteration = 40 | loss = 1.915865 
iteration = 45 | loss = 2.118255 
iteration = 50 | loss = 2.339520 
iteration = 55 | loss = 2.328434 
iteration = 60 | loss = 2.257344 
iteration = 65 | loss = 2.275572 
iteration = 70 | loss = 2.063248 
iteration = 75 | loss = 1.955588 
iteration = 80 | loss = 1.948479 
iteration = 85 | loss = 2.100949 
iteration = 90 | loss = 2.479936 
iteration = 95 | loss = 2.152534 
iteration = 100 | loss = 2.047599 
iteration = 105 | loss = 1.830781 
iteration = 0 | loss = 2.232805 
iteration = 5 | loss = 1.968069 
iteration = 10 | loss = 2.328756 
iteration = 15 | loss = 2.417594 
iteration = 20 | loss = 1.956812 
iteration = 25 | loss = 2.623978 
iteration = 30 | loss = 2.033151 
iteration = 35 | loss = 2.313449 
iteration = 40 | loss = 2.077485 
iteration = 45 | loss = 1.948970 
iteration = 50 | loss = 2.379174 
iteration = 55 | loss = 2.366943 
iteration = 60 | loss = 2.087467 
iteration = 65 | loss = 2.342089 
iteration = 70 | loss = 2.662940 
iteration = 75 | loss = 1.858787 
iteration = 80 | loss = 2.650964 
iteration = 85 | loss = 2.152051 
iteration = 90 | loss = 1.854899 
iteration = 95 | loss = 1.944786 
iteration = 100 | loss = 2.299697 
iteration = 105 | loss = 2.519759 
iteration = 0 | loss = 2.538791 
iteration = 5 | loss = 1.781531 
iteration = 10 | loss = 1.835209 
iteration = 15 | loss = 2.292283 
iteration = 20 | loss = 1.670932 
iteration = 25 | loss = 2.264502 
iteration = 30 | loss = 2.363429 
iteration = 35 | loss = 2.730416 
iteration = 40 | loss = 1.902551 
iteration = 45 | loss = 2.314143 
iteration = 50 | loss = 1.882427 
iteration = 55 | loss = 2.175396 
iteration = 60 | loss = 2.206463 
iteration = 65 | loss = 2.176306 
iteration = 70 | loss = 2.512034 
iteration = 75 | loss = 1.801181 
iteration = 80 | loss = 2.194387 
iteration = 85 | loss = 1.792897 
iteration = 90 | loss = 2.063906 
iteration = 95 | loss = 2.265653 
iteration = 100 | loss = 2.368753 
iteration = 105 | loss = 1.740994 
iteration = 0 | loss = 1.856302 
iteration = 5 | loss = 2.469076 
iteration = 10 | loss = 2.097381 
iteration = 15 | loss = 1.766901 
iteration = 20 | loss = 2.079010 
iteration = 25 | loss = 1.849152 
iteration = 30 | loss = 2.057502 
iteration = 35 | loss = 2.084857 
iteration = 40 | loss = 1.912950 
iteration = 45 | loss = 2.272733 
iteration = 50 | loss = 2.348297 
iteration = 55 | loss = 1.863844 
iteration = 60 | loss = 1.987682 
iteration = 65 | loss = 2.127150 
iteration = 70 | loss = 1.561649 
iteration = 75 | loss = 1.884626 
iteration = 80 | loss = 2.300932 
iteration = 85 | loss = 2.409846 
iteration = 90 | loss = 1.977037 
iteration = 95 | loss = 1.968964 
iteration = 100 | loss = 2.375920 
iteration = 105 | loss = 2.549999 
 Epoch: [60] Loss: 1.5492  R1_I2A: 0.6346 R1_A2I: 0.4803 
                 
 Epoch: [60] Loss: 1.5492  R1_I2A: 0.6374 mAP_I2A: 0.5447  R1_A2I: 0.4803 mAP_A2I: 0.4248 
                     
iteration = 0 | loss = 2.324641 
iteration = 5 | loss = 2.228272 
iteration = 10 | loss = 2.269735 
iteration = 15 | loss = 1.970824 
iteration = 20 | loss = 1.848537 
iteration = 25 | loss = 2.074798 
iteration = 30 | loss = 2.009508 
iteration = 35 | loss = 1.734916 
iteration = 40 | loss = 2.031169 
iteration = 45 | loss = 1.840187 
iteration = 50 | loss = 1.726798 
iteration = 55 | loss = 2.009038 
iteration = 60 | loss = 2.092780 
iteration = 65 | loss = 1.894063 
iteration = 70 | loss = 2.270475 
iteration = 75 | loss = 1.911667 
iteration = 80 | loss = 2.587388 
iteration = 85 | loss = 2.111441 
iteration = 90 | loss = 1.730624 
iteration = 95 | loss = 2.528417 
iteration = 100 | loss = 2.120102 
iteration = 105 | loss = 2.134619 
iteration = 0 | loss = 2.368745 
iteration = 5 | loss = 2.124615 
iteration = 10 | loss = 1.991681 
iteration = 15 | loss = 2.159672 
iteration = 20 | loss = 1.865347 
iteration = 25 | loss = 2.059314 
iteration = 30 | loss = 2.378160 
iteration = 35 | loss = 1.893900 
iteration = 40 | loss = 2.482127 
iteration = 45 | loss = 2.042826 
iteration = 50 | loss = 1.923625 
iteration = 55 | loss = 2.080557 
iteration = 60 | loss = 2.153752 
iteration = 65 | loss = 1.825025 
iteration = 70 | loss = 1.797524 
iteration = 75 | loss = 2.066074 
iteration = 80 | loss = 2.339092 
iteration = 85 | loss = 1.709210 
iteration = 90 | loss = 1.840766 
iteration = 95 | loss = 2.303966 
iteration = 100 | loss = 1.457111 
iteration = 105 | loss = 2.011626 
iteration = 0 | loss = 2.066817 
iteration = 5 | loss = 1.982354 
iteration = 10 | loss = 1.602595 
iteration = 15 | loss = 1.816570 
iteration = 20 | loss = 1.987267 
iteration = 25 | loss = 2.589120 
iteration = 30 | loss = 2.256438 
iteration = 35 | loss = 2.454360 
iteration = 40 | loss = 2.185540 
iteration = 45 | loss = 2.365087 
iteration = 50 | loss = 2.282281 
iteration = 55 | loss = 2.159167 
iteration = 60 | loss = 2.370214 
iteration = 65 | loss = 1.879315 
iteration = 70 | loss = 2.532365 
iteration = 75 | loss = 1.959650 
iteration = 80 | loss = 2.191093 
iteration = 85 | loss = 2.201150 
iteration = 90 | loss = 2.010249 
iteration = 95 | loss = 2.142409 
iteration = 100 | loss = 2.003223 
iteration = 105 | loss = 1.986366 
iteration = 0 | loss = 1.706760 
iteration = 5 | loss = 1.948202 
iteration = 10 | loss = 1.998570 
iteration = 15 | loss = 2.234830 
iteration = 20 | loss = 1.818214 
iteration = 25 | loss = 1.932730 
iteration = 30 | loss = 2.006221 
iteration = 35 | loss = 2.103363 
iteration = 40 | loss = 2.124645 
iteration = 45 | loss = 1.575646 
iteration = 50 | loss = 1.634193 
iteration = 55 | loss = 1.835136 
iteration = 60 | loss = 1.875665 
iteration = 65 | loss = 1.627014 
iteration = 70 | loss = 2.130713 
iteration = 75 | loss = 1.837830 
iteration = 80 | loss = 1.851993 
iteration = 85 | loss = 2.239276 
iteration = 90 | loss = 1.987547 
iteration = 95 | loss = 2.116779 
iteration = 100 | loss = 1.911531 
iteration = 105 | loss = 2.288854 
iteration = 0 | loss = 1.754295 
iteration = 5 | loss = 2.280027 
iteration = 10 | loss = 2.396067 
iteration = 15 | loss = 2.236074 
iteration = 20 | loss = 2.249852 
iteration = 25 | loss = 1.906333 
iteration = 30 | loss = 1.662373 
iteration = 35 | loss = 2.140944 
iteration = 40 | loss = 1.986081 
iteration = 45 | loss = 1.760825 
iteration = 50 | loss = 2.006943 
iteration = 55 | loss = 1.903920 
iteration = 60 | loss = 1.667858 
iteration = 65 | loss = 1.847683 
iteration = 70 | loss = 2.108488 
iteration = 75 | loss = 2.288890 
iteration = 80 | loss = 1.677842 
iteration = 85 | loss = 1.989348 
iteration = 90 | loss = 1.839011 
iteration = 95 | loss = 1.648223 
iteration = 100 | loss = 1.646169 
iteration = 105 | loss = 1.946884 
 Epoch: [65] Loss: 1.5126  R1_I2A: 0.6104 R1_A2I: 0.4810 
                 
iteration = 0 | loss = 1.813519 
iteration = 5 | loss = 1.937874 
iteration = 10 | loss = 2.228143 
iteration = 15 | loss = 2.068354 
iteration = 20 | loss = 1.935702 
iteration = 25 | loss = 1.983987 
iteration = 30 | loss = 2.282232 
iteration = 35 | loss = 2.016679 
iteration = 40 | loss = 1.529805 
iteration = 45 | loss = 2.079293 
iteration = 50 | loss = 2.392437 
iteration = 55 | loss = 2.194735 
iteration = 60 | loss = 2.014483 
iteration = 65 | loss = 2.189432 
iteration = 70 | loss = 1.843830 
iteration = 75 | loss = 2.026246 
iteration = 80 | loss = 2.237563 
iteration = 85 | loss = 2.096068 
iteration = 90 | loss = 1.714285 
iteration = 95 | loss = 2.117524 
iteration = 100 | loss = 2.108693 
iteration = 105 | loss = 2.063012 
iteration = 0 | loss = 2.001013 
iteration = 5 | loss = 1.660918 
iteration = 10 | loss = 1.924400 
iteration = 15 | loss = 2.042254 
iteration = 20 | loss = 1.808095 
iteration = 25 | loss = 1.868028 
iteration = 30 | loss = 2.240367 
iteration = 35 | loss = 1.806961 
iteration = 40 | loss = 2.191135 
iteration = 45 | loss = 2.037888 
iteration = 50 | loss = 1.625296 
iteration = 55 | loss = 2.317511 
iteration = 60 | loss = 2.175535 
iteration = 65 | loss = 2.028527 
iteration = 70 | loss = 1.825419 
iteration = 75 | loss = 1.668886 
iteration = 80 | loss = 1.709339 
iteration = 85 | loss = 2.014697 
iteration = 90 | loss = 1.893774 
iteration = 95 | loss = 1.841115 
iteration = 100 | loss = 2.226246 
iteration = 105 | loss = 2.955439 
iteration = 0 | loss = 1.398876 
iteration = 5 | loss = 2.042204 
iteration = 10 | loss = 2.071558 
iteration = 15 | loss = 1.733722 
iteration = 20 | loss = 2.045484 
iteration = 25 | loss = 1.982517 
iteration = 30 | loss = 2.125146 
iteration = 35 | loss = 1.819606 
iteration = 40 | loss = 1.665725 
iteration = 45 | loss = 1.832876 
iteration = 50 | loss = 2.327563 
iteration = 55 | loss = 2.080951 
iteration = 60 | loss = 1.735183 
iteration = 65 | loss = 2.046608 
iteration = 70 | loss = 2.024462 
iteration = 75 | loss = 2.039972 
iteration = 80 | loss = 1.934750 
iteration = 85 | loss = 2.076396 
iteration = 90 | loss = 2.052667 
iteration = 95 | loss = 2.192350 
iteration = 100 | loss = 1.648616 
iteration = 105 | loss = 2.293373 
iteration = 0 | loss = 1.700879 
iteration = 5 | loss = 2.194487 
iteration = 10 | loss = 1.958156 
iteration = 15 | loss = 2.000951 
iteration = 20 | loss = 1.771657 
iteration = 25 | loss = 1.992160 
iteration = 30 | loss = 1.457638 
iteration = 35 | loss = 2.143235 
iteration = 40 | loss = 1.554933 
iteration = 45 | loss = 1.621140 
iteration = 50 | loss = 1.853905 
iteration = 55 | loss = 1.619434 
iteration = 60 | loss = 1.950728 
iteration = 65 | loss = 1.770856 
iteration = 70 | loss = 1.782747 
iteration = 75 | loss = 2.162933 
iteration = 80 | loss = 1.949589 
iteration = 85 | loss = 1.821872 
iteration = 90 | loss = 2.260793 
iteration = 95 | loss = 1.869299 
iteration = 100 | loss = 1.542855 
iteration = 105 | loss = 2.061723 
iteration = 0 | loss = 1.903348 
iteration = 5 | loss = 1.811983 
iteration = 10 | loss = 2.113405 
iteration = 15 | loss = 2.075989 
iteration = 20 | loss = 1.706146 
iteration = 25 | loss = 2.407216 
iteration = 30 | loss = 1.836404 
iteration = 35 | loss = 1.739160 
iteration = 40 | loss = 1.546857 
iteration = 45 | loss = 2.091326 
iteration = 50 | loss = 1.905263 
iteration = 55 | loss = 2.147495 
iteration = 60 | loss = 1.932309 
iteration = 65 | loss = 1.588499 
iteration = 70 | loss = 1.973532 
iteration = 75 | loss = 2.018250 
iteration = 80 | loss = 2.100091 
iteration = 85 | loss = 1.407507 
iteration = 90 | loss = 1.742517 
iteration = 95 | loss = 2.072150 
iteration = 100 | loss = 2.127739 
iteration = 105 | loss = 2.139308 
 Epoch: [70] Loss: 2.2557  R1_I2A: 0.5870 R1_A2I: 0.4829 
                 
iteration = 0 | loss = 1.828771 
iteration = 5 | loss = 2.065702 
iteration = 10 | loss = 1.733900 
iteration = 15 | loss = 2.026248 
iteration = 20 | loss = 2.086592 
iteration = 25 | loss = 2.164813 
iteration = 30 | loss = 1.622315 
iteration = 35 | loss = 1.948851 
iteration = 40 | loss = 1.647807 
iteration = 45 | loss = 1.905588 
iteration = 50 | loss = 1.966484 
iteration = 55 | loss = 1.613581 
iteration = 60 | loss = 2.070911 
iteration = 65 | loss = 2.108422 
iteration = 70 | loss = 1.824230 
iteration = 75 | loss = 2.029458 
iteration = 80 | loss = 2.097292 
iteration = 85 | loss = 1.745880 
iteration = 90 | loss = 1.844360 
iteration = 95 | loss = 1.959808 
iteration = 100 | loss = 2.404981 
iteration = 105 | loss = 2.252203 
iteration = 0 | loss = 2.108845 
iteration = 5 | loss = 1.590857 
iteration = 10 | loss = 2.011757 
iteration = 15 | loss = 1.713185 
iteration = 20 | loss = 2.141793 
iteration = 25 | loss = 1.831869 
iteration = 30 | loss = 1.773420 
iteration = 35 | loss = 2.093207 
iteration = 40 | loss = 2.023004 
iteration = 45 | loss = 2.020471 
iteration = 50 | loss = 1.692807 
iteration = 55 | loss = 2.260681 
iteration = 60 | loss = 1.806456 
iteration = 65 | loss = 1.717938 
iteration = 70 | loss = 1.732356 
iteration = 75 | loss = 2.086155 
iteration = 80 | loss = 1.973542 
iteration = 85 | loss = 1.756140 
iteration = 90 | loss = 1.508666 
iteration = 95 | loss = 2.197702 
iteration = 100 | loss = 1.465370 
iteration = 105 | loss = 1.718896 
iteration = 0 | loss = 1.725669 
iteration = 5 | loss = 1.747339 
iteration = 10 | loss = 2.112037 
iteration = 15 | loss = 2.500132 
iteration = 20 | loss = 2.295520 
iteration = 25 | loss = 1.781492 
iteration = 30 | loss = 1.595724 
iteration = 35 | loss = 2.306674 
iteration = 40 | loss = 1.724212 
iteration = 45 | loss = 1.763810 
iteration = 50 | loss = 2.163871 
iteration = 55 | loss = 1.989560 
iteration = 60 | loss = 1.800729 
iteration = 65 | loss = 1.615923 
iteration = 70 | loss = 1.792192 
iteration = 75 | loss = 1.807736 
iteration = 80 | loss = 1.637436 
iteration = 85 | loss = 2.103663 
iteration = 90 | loss = 1.858775 
iteration = 95 | loss = 1.985955 
iteration = 100 | loss = 2.471347 
iteration = 105 | loss = 1.706679 
iteration = 0 | loss = 2.099901 
iteration = 5 | loss = 1.841727 
iteration = 10 | loss = 1.439053 
iteration = 15 | loss = 2.099942 
iteration = 20 | loss = 1.600509 
iteration = 25 | loss = 1.572290 
iteration = 30 | loss = 1.935821 
iteration = 35 | loss = 1.621926 
iteration = 40 | loss = 1.417812 
iteration = 45 | loss = 2.055192 
iteration = 50 | loss = 1.781683 
iteration = 55 | loss = 1.702005 
iteration = 60 | loss = 1.813030 
iteration = 65 | loss = 1.849010 
iteration = 70 | loss = 1.755031 
iteration = 75 | loss = 1.430643 
iteration = 80 | loss = 1.828234 
iteration = 85 | loss = 1.792790 
iteration = 90 | loss = 1.769887 
iteration = 95 | loss = 2.263281 
iteration = 100 | loss = 2.007339 
iteration = 105 | loss = 2.159064 
iteration = 0 | loss = 1.763429 
iteration = 5 | loss = 1.899937 
iteration = 10 | loss = 1.733305 
iteration = 15 | loss = 1.805416 
iteration = 20 | loss = 1.723817 
iteration = 25 | loss = 1.975961 
iteration = 30 | loss = 2.111297 
iteration = 35 | loss = 2.004004 
iteration = 40 | loss = 1.386977 
iteration = 45 | loss = 1.918654 
iteration = 50 | loss = 1.638170 
iteration = 55 | loss = 1.542058 
iteration = 60 | loss = 1.306781 
iteration = 65 | loss = 2.261130 
iteration = 70 | loss = 1.694824 
iteration = 75 | loss = 1.722992 
iteration = 80 | loss = 1.692923 
iteration = 85 | loss = 1.701096 
iteration = 90 | loss = 1.625350 
iteration = 95 | loss = 2.317916 
iteration = 100 | loss = 1.937354 
iteration = 105 | loss = 1.986200 
 Epoch: [75] Loss: 2.1301  R1_I2A: 0.5991 R1_A2I: 0.4902 
                 
iteration = 0 | loss = 1.999007 
iteration = 5 | loss = 2.000731 
iteration = 10 | loss = 1.476056 
iteration = 15 | loss = 1.671685 
iteration = 20 | loss = 1.405432 
iteration = 25 | loss = 1.504373 
iteration = 30 | loss = 1.314071 
iteration = 35 | loss = 1.328343 
iteration = 40 | loss = 1.480518 
iteration = 45 | loss = 1.470634 
iteration = 50 | loss = 1.441335 
iteration = 55 | loss = 1.351857 
iteration = 60 | loss = 1.878618 
iteration = 65 | loss = 1.460205 
iteration = 70 | loss = 1.759024 
iteration = 75 | loss = 1.547886 
iteration = 80 | loss = 1.433895 
iteration = 85 | loss = 1.436561 
iteration = 90 | loss = 1.616386 
iteration = 95 | loss = 1.559576 
iteration = 100 | loss = 1.861247 
iteration = 105 | loss = 1.622703 
iteration = 0 | loss = 1.381396 
iteration = 5 | loss = 1.567866 
iteration = 10 | loss = 1.660421 
iteration = 15 | loss = 1.264940 
iteration = 20 | loss = 1.435967 
iteration = 25 | loss = 1.295175 
iteration = 30 | loss = 1.443434 
iteration = 35 | loss = 1.305155 
iteration = 40 | loss = 1.552704 
iteration = 45 | loss = 1.494538 
iteration = 50 | loss = 1.836153 
iteration = 55 | loss = 1.549224 
iteration = 60 | loss = 1.610394 
iteration = 65 | loss = 1.503978 
iteration = 70 | loss = 1.664021 
iteration = 75 | loss = 1.457738 
iteration = 80 | loss = 1.622352 
iteration = 85 | loss = 1.618267 
iteration = 90 | loss = 1.402323 
iteration = 95 | loss = 1.306628 
iteration = 100 | loss = 1.451390 
iteration = 105 | loss = 1.344210 
iteration = 0 | loss = 1.620830 
iteration = 5 | loss = 1.511463 
iteration = 10 | loss = 1.109456 
iteration = 15 | loss = 1.301647 
iteration = 20 | loss = 1.394290 
iteration = 25 | loss = 1.493044 
iteration = 30 | loss = 2.040810 
iteration = 35 | loss = 1.322495 
iteration = 40 | loss = 1.093932 
iteration = 45 | loss = 1.331800 
iteration = 50 | loss = 1.428696 
iteration = 55 | loss = 1.690960 
iteration = 60 | loss = 1.332670 
iteration = 65 | loss = 1.722798 
iteration = 70 | loss = 1.577423 
iteration = 75 | loss = 1.611414 
iteration = 80 | loss = 1.333000 
iteration = 85 | loss = 1.718052 
iteration = 90 | loss = 1.537261 
iteration = 95 | loss = 1.419163 
iteration = 100 | loss = 1.628168 
iteration = 105 | loss = 1.543882 
iteration = 0 | loss = 1.659785 
iteration = 5 | loss = 1.293415 
iteration = 10 | loss = 1.186438 
iteration = 15 | loss = 1.801307 
iteration = 20 | loss = 1.399394 
iteration = 25 | loss = 1.647921 
iteration = 30 | loss = 1.593027 
iteration = 35 | loss = 1.347763 
iteration = 40 | loss = 1.667841 
iteration = 45 | loss = 1.382646 
iteration = 50 | loss = 1.516600 
iteration = 55 | loss = 1.773611 
iteration = 60 | loss = 1.700296 
iteration = 65 | loss = 1.183179 
iteration = 70 | loss = 1.695051 
iteration = 75 | loss = 1.186563 
iteration = 80 | loss = 1.283045 
iteration = 85 | loss = 1.894233 
iteration = 90 | loss = 1.438967 
iteration = 95 | loss = 1.541794 
iteration = 100 | loss = 1.687775 
iteration = 105 | loss = 1.580621 
iteration = 0 | loss = 1.384714 
iteration = 5 | loss = 1.731983 
iteration = 10 | loss = 1.749375 
iteration = 15 | loss = 1.515920 
iteration = 20 | loss = 1.766307 
iteration = 25 | loss = 1.509316 
iteration = 30 | loss = 1.338655 
iteration = 35 | loss = 1.441290 
iteration = 40 | loss = 1.215908 
iteration = 45 | loss = 1.819111 
iteration = 50 | loss = 1.431757 
iteration = 55 | loss = 1.383660 
iteration = 60 | loss = 1.841883 
iteration = 65 | loss = 1.573032 
iteration = 70 | loss = 1.547111 
iteration = 75 | loss = 1.462196 
iteration = 80 | loss = 1.481045 
iteration = 85 | loss = 1.494485 
iteration = 90 | loss = 1.455567 
iteration = 95 | loss = 1.672185 
iteration = 100 | loss = 1.740300 
iteration = 105 | loss = 1.612286 
 Epoch: [80] Loss: 1.6998  R1_I2A: 0.5784 R1_A2I: 0.4694 
                 
iteration = 0 | loss = 1.678675 
iteration = 5 | loss = 1.897867 
iteration = 10 | loss = 1.782395 
iteration = 15 | loss = 1.577545 
iteration = 20 | loss = 1.380094 
iteration = 25 | loss = 1.399635 
iteration = 30 | loss = 1.765793 
iteration = 35 | loss = 1.662807 
iteration = 40 | loss = 1.692766 
iteration = 45 | loss = 1.501286 
iteration = 50 | loss = 1.738934 
iteration = 55 | loss = 1.681702 
iteration = 60 | loss = 1.309235 
iteration = 65 | loss = 1.798396 
iteration = 70 | loss = 1.473343 
iteration = 75 | loss = 1.682597 
iteration = 80 | loss = 2.095435 
iteration = 85 | loss = 1.725764 
iteration = 90 | loss = 1.363399 
iteration = 95 | loss = 1.714185 
iteration = 100 | loss = 2.293987 
iteration = 105 | loss = 1.333964 
iteration = 0 | loss = 1.721843 
iteration = 5 | loss = 1.948781 
iteration = 10 | loss = 1.778968 
iteration = 15 | loss = 1.649163 
iteration = 20 | loss = 1.619123 
iteration = 25 | loss = 2.020170 
iteration = 30 | loss = 1.879651 
iteration = 35 | loss = 1.798306 
iteration = 40 | loss = 1.284392 
iteration = 45 | loss = 1.690581 
iteration = 50 | loss = 1.931615 
iteration = 55 | loss = 1.732370 
iteration = 60 | loss = 1.860559 
iteration = 65 | loss = 1.701013 
iteration = 70 | loss = 1.705472 
iteration = 75 | loss = 1.206644 
iteration = 80 | loss = 1.748194 
iteration = 85 | loss = 1.669271 
iteration = 90 | loss = 1.602301 
iteration = 95 | loss = 2.027246 
iteration = 100 | loss = 1.563667 
iteration = 105 | loss = 1.905796 
iteration = 0 | loss = 2.043759 
iteration = 5 | loss = 1.854343 
iteration = 10 | loss = 1.239834 
iteration = 15 | loss = 1.429926 
iteration = 20 | loss = 1.233909 
iteration = 25 | loss = 1.417338 
iteration = 30 | loss = 1.518689 
iteration = 35 | loss = 1.616646 
iteration = 40 | loss = 1.601382 
iteration = 45 | loss = 2.149519 
iteration = 50 | loss = 1.530282 
iteration = 55 | loss = 1.807207 
iteration = 60 | loss = 1.794794 
iteration = 65 | loss = 1.935774 
iteration = 70 | loss = 1.587510 
iteration = 75 | loss = 1.704907 
iteration = 80 | loss = 1.483130 
iteration = 85 | loss = 1.884547 
iteration = 90 | loss = 2.341879 
iteration = 95 | loss = 1.779100 
iteration = 100 | loss = 1.818224 
iteration = 105 | loss = 1.388971 
iteration = 0 | loss = 1.166295 
iteration = 5 | loss = 1.974418 
iteration = 10 | loss = 1.473171 
iteration = 15 | loss = 1.605805 
iteration = 20 | loss = 1.192231 
iteration = 25 | loss = 1.569051 
iteration = 30 | loss = 1.664855 
iteration = 35 | loss = 1.583570 
iteration = 40 | loss = 1.272968 
iteration = 45 | loss = 1.501129 
iteration = 50 | loss = 1.467426 
iteration = 55 | loss = 1.750595 
iteration = 60 | loss = 1.731618 
iteration = 65 | loss = 1.528082 
iteration = 70 | loss = 2.142298 
iteration = 75 | loss = 1.891532 
iteration = 80 | loss = 1.853798 
iteration = 85 | loss = 1.316495 
iteration = 90 | loss = 1.834048 
iteration = 95 | loss = 1.403875 
iteration = 100 | loss = 1.717467 
iteration = 105 | loss = 1.469628 
iteration = 0 | loss = 1.656218 
iteration = 5 | loss = 1.343904 
iteration = 10 | loss = 1.835296 
iteration = 15 | loss = 1.423721 
iteration = 20 | loss = 1.665328 
iteration = 25 | loss = 2.133616 
iteration = 30 | loss = 1.739237 
iteration = 35 | loss = 1.736171 
iteration = 40 | loss = 1.444869 
iteration = 45 | loss = 1.923815 
iteration = 50 | loss = 1.548253 
iteration = 55 | loss = 1.743827 
iteration = 60 | loss = 1.341888 
iteration = 65 | loss = 1.859032 
iteration = 70 | loss = 1.357419 
iteration = 75 | loss = 1.204934 
iteration = 80 | loss = 2.057812 
iteration = 85 | loss = 1.488554 
iteration = 90 | loss = 1.549909 
iteration = 95 | loss = 1.567003 
iteration = 100 | loss = 1.396534 
iteration = 105 | loss = 1.350075 
 Epoch: [85] Loss: 1.5752  R1_I2A: 0.6069 R1_A2I: 0.4740 
                 
iteration = 0 | loss = 1.428696 
iteration = 5 | loss = 1.894481 
iteration = 10 | loss = 1.709468 
iteration = 15 | loss = 1.599185 
iteration = 20 | loss = 1.635363 
iteration = 25 | loss = 1.431534 
iteration = 30 | loss = 1.512439 
iteration = 35 | loss = 1.490527 
iteration = 40 | loss = 1.335130 
iteration = 45 | loss = 1.642825 
iteration = 50 | loss = 1.263658 
iteration = 55 | loss = 1.342933 
iteration = 60 | loss = 1.089852 
iteration = 65 | loss = 1.542114 
iteration = 70 | loss = 1.126323 
iteration = 75 | loss = 1.958193 
iteration = 80 | loss = 1.824923 
iteration = 85 | loss = 1.450128 
iteration = 90 | loss = 1.622572 
iteration = 95 | loss = 1.394952 
iteration = 100 | loss = 1.892219 
iteration = 105 | loss = 1.245848 
iteration = 0 | loss = 1.542412 
iteration = 5 | loss = 1.786231 
iteration = 10 | loss = 1.616548 
iteration = 15 | loss = 1.584586 
iteration = 20 | loss = 1.600696 
iteration = 25 | loss = 1.415695 
iteration = 30 | loss = 1.369690 
iteration = 35 | loss = 1.358002 
iteration = 40 | loss = 1.648952 
iteration = 45 | loss = 1.247127 
iteration = 50 | loss = 1.819272 
iteration = 55 | loss = 1.570347 
iteration = 60 | loss = 1.902043 
iteration = 65 | loss = 1.932936 
iteration = 70 | loss = 1.628649 
iteration = 75 | loss = 1.518139 
iteration = 80 | loss = 1.753320 
iteration = 85 | loss = 1.758159 
iteration = 90 | loss = 1.561168 
iteration = 95 | loss = 1.796000 
iteration = 100 | loss = 1.566223 
iteration = 105 | loss = 1.196424 
iteration = 0 | loss = 1.291420 
iteration = 5 | loss = 1.968225 
iteration = 10 | loss = 1.330726 
iteration = 15 | loss = 1.584476 
iteration = 20 | loss = 1.629241 
iteration = 25 | loss = 1.592475 
iteration = 30 | loss = 1.560820 
iteration = 35 | loss = 1.447632 
iteration = 40 | loss = 1.855766 
iteration = 45 | loss = 1.712827 
iteration = 50 | loss = 1.329224 
iteration = 55 | loss = 1.329701 
iteration = 60 | loss = 1.703583 
iteration = 65 | loss = 1.850611 
iteration = 70 | loss = 1.679328 
iteration = 75 | loss = 1.440674 
iteration = 80 | loss = 1.231056 
iteration = 85 | loss = 1.766077 
iteration = 90 | loss = 1.653339 
iteration = 95 | loss = 1.278710 
iteration = 100 | loss = 1.596513 
iteration = 105 | loss = 1.435225 
iteration = 0 | loss = 1.449838 
iteration = 5 | loss = 1.703399 
iteration = 10 | loss = 1.549912 
iteration = 15 | loss = 1.527823 
iteration = 20 | loss = 1.541765 
iteration = 25 | loss = 1.802841 
iteration = 30 | loss = 1.632022 
iteration = 35 | loss = 1.567331 
iteration = 40 | loss = 1.472092 
iteration = 45 | loss = 1.586977 
iteration = 50 | loss = 1.488258 
iteration = 55 | loss = 1.447705 
iteration = 60 | loss = 1.466429 
iteration = 65 | loss = 1.228429 
iteration = 70 | loss = 1.303922 
iteration = 75 | loss = 1.671482 
iteration = 80 | loss = 1.532167 
iteration = 85 | loss = 1.224951 
iteration = 90 | loss = 1.339826 
iteration = 95 | loss = 1.665746 
iteration = 100 | loss = 1.614024 
iteration = 105 | loss = 1.877696 
iteration = 0 | loss = 1.273937 
iteration = 5 | loss = 1.317078 
iteration = 10 | loss = 1.623066 
iteration = 15 | loss = 1.615344 
iteration = 20 | loss = 1.311112 
iteration = 25 | loss = 1.479950 
iteration = 30 | loss = 1.570728 
iteration = 35 | loss = 1.645052 
iteration = 40 | loss = 1.443929 
iteration = 45 | loss = 1.455675 
iteration = 50 | loss = 1.509607 
iteration = 55 | loss = 1.676029 
iteration = 60 | loss = 1.436257 
iteration = 65 | loss = 1.151286 
iteration = 70 | loss = 1.170574 
iteration = 75 | loss = 1.223401 
iteration = 80 | loss = 1.403392 
iteration = 85 | loss = 1.465305 
iteration = 90 | loss = 1.960109 
iteration = 95 | loss = 1.052984 
iteration = 100 | loss = 1.436847 
iteration = 105 | loss = 1.660993 
 Epoch: [90] Loss: 1.1955  R1_I2A: 0.6113 R1_A2I: 0.4749 
                 
iteration = 0 | loss = 1.500585 
iteration = 5 | loss = 1.722544 
iteration = 10 | loss = 1.445623 
iteration = 15 | loss = 1.409337 
iteration = 20 | loss = 1.625644 
iteration = 25 | loss = 1.651966 
iteration = 30 | loss = 1.626385 
iteration = 35 | loss = 1.592147 
iteration = 40 | loss = 1.207504 
iteration = 45 | loss = 1.453090 
iteration = 50 | loss = 1.507363 
iteration = 55 | loss = 1.512538 
iteration = 60 | loss = 1.397746 
iteration = 65 | loss = 1.316833 
iteration = 70 | loss = 1.738059 
iteration = 75 | loss = 1.235350 
iteration = 80 | loss = 1.539023 
iteration = 85 | loss = 1.536133 
iteration = 90 | loss = 1.749863 
iteration = 95 | loss = 1.404577 
iteration = 100 | loss = 1.627307 
iteration = 105 | loss = 1.516044 
iteration = 0 | loss = 1.269801 
iteration = 5 | loss = 1.404502 
iteration = 10 | loss = 1.228227 
iteration = 15 | loss = 1.595369 
iteration = 20 | loss = 1.536123 
iteration = 25 | loss = 1.411216 
iteration = 30 | loss = 1.258568 
iteration = 35 | loss = 1.354487 
iteration = 40 | loss = 1.567683 
iteration = 45 | loss = 1.340590 
iteration = 50 | loss = 1.520794 
iteration = 55 | loss = 1.137152 
iteration = 60 | loss = 1.183304 
iteration = 65 | loss = 1.344589 
iteration = 70 | loss = 1.811080 
iteration = 75 | loss = 1.139409 
iteration = 80 | loss = 1.749869 
iteration = 85 | loss = 1.748116 
iteration = 90 | loss = 1.622799 
iteration = 95 | loss = 1.271535 
iteration = 100 | loss = 1.439510 
iteration = 105 | loss = 1.390306 
iteration = 0 | loss = 1.710987 
iteration = 5 | loss = 1.569693 
iteration = 10 | loss = 1.669178 
iteration = 15 | loss = 1.506557 
iteration = 20 | loss = 1.503016 
iteration = 25 | loss = 1.238811 
iteration = 30 | loss = 1.464480 
iteration = 35 | loss = 1.492621 
iteration = 40 | loss = 1.288290 
iteration = 45 | loss = 1.542433 
iteration = 50 | loss = 1.251613 
iteration = 55 | loss = 1.600289 
iteration = 60 | loss = 1.498189 
iteration = 65 | loss = 1.750665 
iteration = 70 | loss = 1.713478 
iteration = 75 | loss = 2.030307 
iteration = 80 | loss = 1.206472 
iteration = 85 | loss = 1.489188 
iteration = 90 | loss = 1.237641 
iteration = 95 | loss = 1.213597 
iteration = 100 | loss = 1.470595 
iteration = 105 | loss = 1.882101 
iteration = 0 | loss = 1.200549 
iteration = 5 | loss = 1.257612 
iteration = 10 | loss = 1.298600 
iteration = 15 | loss = 1.543356 
iteration = 20 | loss = 1.458742 
iteration = 25 | loss = 1.127152 
iteration = 30 | loss = 1.346311 
iteration = 35 | loss = 1.456863 
iteration = 40 | loss = 1.455286 
iteration = 45 | loss = 1.734931 
iteration = 50 | loss = 1.595139 
iteration = 55 | loss = 1.253951 
iteration = 60 | loss = 1.283310 
iteration = 65 | loss = 1.761355 
iteration = 70 | loss = 1.396281 
iteration = 75 | loss = 1.147651 
iteration = 80 | loss = 1.305613 
iteration = 85 | loss = 1.575146 
iteration = 90 | loss = 1.468898 
iteration = 95 | loss = 1.205001 
iteration = 100 | loss = 1.594949 
iteration = 105 | loss = 1.274320 
iteration = 0 | loss = 1.435585 
iteration = 5 | loss = 1.963054 
iteration = 10 | loss = 1.174551 
iteration = 15 | loss = 1.235503 
iteration = 20 | loss = 1.649224 
iteration = 25 | loss = 1.406941 
iteration = 30 | loss = 1.602523 
iteration = 35 | loss = 1.627932 
iteration = 40 | loss = 1.447748 
iteration = 45 | loss = 1.149922 
iteration = 50 | loss = 1.603762 
iteration = 55 | loss = 1.590440 
iteration = 60 | loss = 1.194564 
iteration = 65 | loss = 1.357903 
iteration = 70 | loss = 1.460920 
iteration = 75 | loss = 1.188788 
iteration = 80 | loss = 1.590806 
iteration = 85 | loss = 1.568288 
iteration = 90 | loss = 1.376874 
iteration = 95 | loss = 1.503543 
iteration = 100 | loss = 1.679565 
iteration = 105 | loss = 1.528708 
 Epoch: [95] Loss: 1.5397  R1_I2A: 0.5887 R1_A2I: 0.4700 
                 
iteration = 0 | loss = 1.288828 
iteration = 5 | loss = 1.175532 
iteration = 10 | loss = 1.905666 
iteration = 15 | loss = 1.384587 
iteration = 20 | loss = 1.329956 
iteration = 25 | loss = 1.187872 
iteration = 30 | loss = 1.292282 
iteration = 35 | loss = 1.149816 
iteration = 40 | loss = 1.698110 
iteration = 45 | loss = 1.392707 
iteration = 50 | loss = 1.251217 
iteration = 55 | loss = 1.295687 
iteration = 60 | loss = 1.322112 
iteration = 65 | loss = 1.474767 
iteration = 70 | loss = 1.510676 
iteration = 75 | loss = 1.320172 
iteration = 80 | loss = 1.601103 
iteration = 85 | loss = 1.316564 
iteration = 90 | loss = 1.493385 
iteration = 95 | loss = 1.374236 
iteration = 100 | loss = 1.157315 
iteration = 105 | loss = 1.302820 
iteration = 0 | loss = 1.407670 
iteration = 5 | loss = 1.086869 
iteration = 10 | loss = 1.518099 
iteration = 15 | loss = 1.150051 
iteration = 20 | loss = 1.366328 
iteration = 25 | loss = 1.431775 
iteration = 30 | loss = 1.383042 
iteration = 35 | loss = 1.341593 
iteration = 40 | loss = 1.207343 
iteration = 45 | loss = 1.657090 
iteration = 50 | loss = 1.215301 
iteration = 55 | loss = 1.375231 
iteration = 60 | loss = 1.554023 
iteration = 65 | loss = 1.383847 
iteration = 70 | loss = 1.139831 
iteration = 75 | loss = 1.566712 
iteration = 80 | loss = 1.210449 
iteration = 85 | loss = 1.852230 
iteration = 90 | loss = 1.381668 
iteration = 95 | loss = 1.328397 
iteration = 100 | loss = 1.325777 
iteration = 105 | loss = 1.457869 
iteration = 0 | loss = 1.517867 
iteration = 5 | loss = 1.508252 
iteration = 10 | loss = 1.553000 
iteration = 15 | loss = 1.252721 
iteration = 20 | loss = 1.293631 
iteration = 25 | loss = 1.226887 
iteration = 30 | loss = 1.291567 
iteration = 35 | loss = 1.313358 
iteration = 40 | loss = 1.314560 
iteration = 45 | loss = 1.385126 
iteration = 50 | loss = 1.344305 
iteration = 55 | loss = 1.472879 
iteration = 60 | loss = 1.318524 
iteration = 65 | loss = 1.545794 
iteration = 70 | loss = 1.521177 
iteration = 75 | loss = 1.197061 
iteration = 80 | loss = 1.202648 
iteration = 85 | loss = 1.296161 
iteration = 90 | loss = 1.657831 
iteration = 95 | loss = 1.241228 
iteration = 100 | loss = 1.341608 
iteration = 105 | loss = 1.310199 
iteration = 0 | loss = 1.372579 
iteration = 5 | loss = 1.221349 
iteration = 10 | loss = 1.183105 
iteration = 15 | loss = 1.104269 
iteration = 20 | loss = 1.455513 
iteration = 25 | loss = 1.322952 
iteration = 30 | loss = 1.646360 
iteration = 35 | loss = 1.491724 
iteration = 40 | loss = 1.049172 
iteration = 45 | loss = 1.392542 
iteration = 50 | loss = 1.142418 
iteration = 55 | loss = 1.509795 
iteration = 60 | loss = 1.271583 
iteration = 65 | loss = 1.308893 
iteration = 70 | loss = 1.188156 
iteration = 75 | loss = 1.712133 
iteration = 80 | loss = 1.313367 
iteration = 85 | loss = 1.164330 
iteration = 90 | loss = 1.391526 
iteration = 95 | loss = 1.342839 
iteration = 100 | loss = 1.344530 
iteration = 105 | loss = 1.209325 
iteration = 0 | loss = 1.158566 
iteration = 5 | loss = 1.344292 
iteration = 10 | loss = 1.270743 
iteration = 15 | loss = 1.381628 
iteration = 20 | loss = 1.132920 
iteration = 25 | loss = 1.189157 
iteration = 30 | loss = 1.008055 
iteration = 35 | loss = 1.499265 
iteration = 40 | loss = 1.253860 
iteration = 45 | loss = 1.183822 
iteration = 50 | loss = 1.117547 
iteration = 55 | loss = 1.399281 
iteration = 60 | loss = 1.211120 
iteration = 65 | loss = 1.631898 
iteration = 70 | loss = 1.309585 
iteration = 75 | loss = 1.365333 
iteration = 80 | loss = 1.540728 
iteration = 85 | loss = 1.373461 
iteration = 90 | loss = 1.098815 
iteration = 95 | loss = 1.582311 
iteration = 100 | loss = 1.386693 
iteration = 105 | loss = 1.473772 
 Epoch: [100] Loss: 1.4916  R1_I2A: 0.5939 R1_A2I: 0.4623 
                 
iteration = 0 | loss = 1.139282 
iteration = 5 | loss = 1.438339 
iteration = 10 | loss = 1.409615 
iteration = 15 | loss = 1.370878 
iteration = 20 | loss = 1.459084 
iteration = 25 | loss = 1.717830 
iteration = 30 | loss = 1.166133 
iteration = 35 | loss = 1.272582 
iteration = 40 | loss = 1.114615 
iteration = 45 | loss = 1.122586 
iteration = 50 | loss = 1.101783 
iteration = 55 | loss = 1.341461 
iteration = 60 | loss = 1.249726 
iteration = 65 | loss = 0.990836 
iteration = 70 | loss = 1.359148 
iteration = 75 | loss = 1.064155 
iteration = 80 | loss = 0.868046 
iteration = 85 | loss = 1.369120 
iteration = 90 | loss = 1.151959 
iteration = 95 | loss = 1.291723 
iteration = 100 | loss = 1.178047 
iteration = 105 | loss = 1.239204 
iteration = 0 | loss = 1.444251 
iteration = 5 | loss = 1.316363 
iteration = 10 | loss = 1.362942 
iteration = 15 | loss = 1.039515 
iteration = 20 | loss = 1.405749 
iteration = 25 | loss = 1.046645 
iteration = 30 | loss = 0.915061 
iteration = 35 | loss = 1.011191 
iteration = 40 | loss = 0.848593 
iteration = 45 | loss = 0.770822 
iteration = 50 | loss = 1.091636 
iteration = 55 | loss = 1.263188 
iteration = 60 | loss = 1.379065 
iteration = 65 | loss = 1.190325 
iteration = 70 | loss = 1.036059 
iteration = 75 | loss = 1.588050 
iteration = 80 | loss = 1.122953 
iteration = 85 | loss = 1.367041 
iteration = 90 | loss = 1.560786 
iteration = 95 | loss = 1.230621 
iteration = 100 | loss = 1.076030 
iteration = 105 | loss = 1.179992 
iteration = 0 | loss = 1.303393 
iteration = 5 | loss = 1.270865 
iteration = 10 | loss = 1.143812 
iteration = 15 | loss = 1.275404 
iteration = 20 | loss = 1.095472 
iteration = 25 | loss = 1.424407 
iteration = 30 | loss = 1.139097 
iteration = 35 | loss = 1.271042 
iteration = 40 | loss = 1.407401 
iteration = 45 | loss = 1.031945 
iteration = 50 | loss = 0.933638 
iteration = 55 | loss = 1.023093 
iteration = 60 | loss = 1.220996 
iteration = 65 | loss = 1.165158 
iteration = 70 | loss = 1.372926 
iteration = 75 | loss = 1.072116 
iteration = 80 | loss = 1.251958 
iteration = 85 | loss = 1.318396 
iteration = 90 | loss = 1.116061 
iteration = 95 | loss = 1.146517 
iteration = 100 | loss = 0.911019 
iteration = 105 | loss = 1.369471 
iteration = 0 | loss = 1.134537 
iteration = 5 | loss = 1.089555 
iteration = 10 | loss = 1.310165 
iteration = 15 | loss = 1.064128 
iteration = 20 | loss = 1.078613 
iteration = 25 | loss = 1.029569 
iteration = 30 | loss = 1.215304 
iteration = 35 | loss = 1.156284 
iteration = 40 | loss = 1.018427 
iteration = 45 | loss = 1.278618 
iteration = 50 | loss = 1.378121 
iteration = 55 | loss = 1.349617 
iteration = 60 | loss = 1.142552 
iteration = 65 | loss = 0.775374 
iteration = 70 | loss = 1.108291 
iteration = 75 | loss = 1.311995 
iteration = 80 | loss = 0.999570 
iteration = 85 | loss = 0.951523 
iteration = 90 | loss = 1.011621 
iteration = 95 | loss = 1.215440 
iteration = 100 | loss = 1.230027 
iteration = 105 | loss = 1.020563 
iteration = 0 | loss = 1.016645 
iteration = 5 | loss = 1.132885 
iteration = 10 | loss = 1.403050 
iteration = 15 | loss = 0.973167 
iteration = 20 | loss = 0.957213 
iteration = 25 | loss = 1.565852 
iteration = 30 | loss = 1.442521 
iteration = 35 | loss = 1.083178 
iteration = 40 | loss = 1.243047 
iteration = 45 | loss = 1.083040 
iteration = 50 | loss = 1.115422 
iteration = 55 | loss = 1.113869 
iteration = 60 | loss = 1.421010 
iteration = 65 | loss = 1.210018 
iteration = 70 | loss = 1.398896 
iteration = 75 | loss = 1.147071 
iteration = 80 | loss = 1.304556 
iteration = 85 | loss = 1.104102 
iteration = 90 | loss = 1.433955 
iteration = 95 | loss = 1.190064 
iteration = 100 | loss = 0.897753 
iteration = 105 | loss = 1.134104 
 Epoch: [105] Loss: 1.0392  R1_I2A: 0.5957 R1_A2I: 0.4657 
                 
iteration = 0 | loss = 1.011575 
iteration = 5 | loss = 0.967058 
iteration = 10 | loss = 1.093432 
iteration = 15 | loss = 0.846764 
iteration = 20 | loss = 1.060288 
iteration = 25 | loss = 1.013191 
iteration = 30 | loss = 0.964191 
iteration = 35 | loss = 0.923079 
iteration = 40 | loss = 1.185602 
iteration = 45 | loss = 1.255002 
iteration = 50 | loss = 1.169593 
iteration = 55 | loss = 1.194087 
iteration = 60 | loss = 0.867420 
iteration = 65 | loss = 1.081556 
iteration = 70 | loss = 1.016387 
iteration = 75 | loss = 0.997464 
iteration = 80 | loss = 0.957740 
iteration = 85 | loss = 1.233543 
iteration = 90 | loss = 1.311218 
iteration = 95 | loss = 1.086349 
iteration = 100 | loss = 1.003686 
iteration = 105 | loss = 0.990799 
iteration = 0 | loss = 1.225368 
iteration = 5 | loss = 0.938084 
iteration = 10 | loss = 1.206404 
iteration = 15 | loss = 1.253239 
iteration = 20 | loss = 1.253538 
iteration = 25 | loss = 0.948305 
iteration = 30 | loss = 1.182523 
iteration = 35 | loss = 1.014221 
iteration = 40 | loss = 0.935507 
iteration = 45 | loss = 1.000976 
iteration = 50 | loss = 0.964270 
iteration = 55 | loss = 1.242163 
iteration = 60 | loss = 1.622226 
iteration = 65 | loss = 1.255165 
iteration = 70 | loss = 1.059678 
iteration = 75 | loss = 0.866672 
iteration = 80 | loss = 1.017359 
iteration = 85 | loss = 0.964014 
iteration = 90 | loss = 0.910750 
iteration = 95 | loss = 0.854425 
iteration = 100 | loss = 0.893950 
iteration = 105 | loss = 1.422302 
iteration = 0 | loss = 0.998672 
iteration = 5 | loss = 0.889481 
iteration = 10 | loss = 1.281367 
iteration = 15 | loss = 1.199847 
iteration = 20 | loss = 1.276853 
iteration = 25 | loss = 1.191989 
iteration = 30 | loss = 0.673601 
iteration = 35 | loss = 0.879467 
iteration = 40 | loss = 1.019993 
iteration = 45 | loss = 1.187396 
iteration = 50 | loss = 0.775391 
iteration = 55 | loss = 1.307858 
iteration = 60 | loss = 1.218166 
iteration = 65 | loss = 0.744508 
iteration = 70 | loss = 1.360563 
iteration = 75 | loss = 1.193698 
iteration = 80 | loss = 1.124969 
iteration = 85 | loss = 0.991538 
iteration = 90 | loss = 1.207322 
iteration = 95 | loss = 1.144468 
iteration = 100 | loss = 0.922708 
iteration = 105 | loss = 1.072539 
iteration = 0 | loss = 1.529230 
iteration = 5 | loss = 1.038191 
iteration = 10 | loss = 1.018600 
iteration = 15 | loss = 1.116761 
iteration = 20 | loss = 1.158890 
iteration = 25 | loss = 1.017919 
iteration = 30 | loss = 1.124926 
iteration = 35 | loss = 0.995305 
iteration = 40 | loss = 1.336626 
iteration = 45 | loss = 0.729997 
iteration = 50 | loss = 1.083763 
iteration = 55 | loss = 1.009008 
iteration = 60 | loss = 0.911890 
iteration = 65 | loss = 1.084268 
iteration = 70 | loss = 1.098528 
iteration = 75 | loss = 1.100322 
iteration = 80 | loss = 0.937244 
iteration = 85 | loss = 1.230266 
iteration = 90 | loss = 0.897118 
iteration = 95 | loss = 1.160247 
iteration = 100 | loss = 1.063218 
iteration = 105 | loss = 1.082256 
iteration = 0 | loss = 0.864436 
iteration = 5 | loss = 1.497852 
iteration = 10 | loss = 1.030161 
iteration = 15 | loss = 0.862334 
iteration = 20 | loss = 0.940671 
iteration = 25 | loss = 1.199815 
iteration = 30 | loss = 1.011520 
iteration = 35 | loss = 1.045747 
iteration = 40 | loss = 1.672114 
iteration = 45 | loss = 0.749992 
iteration = 50 | loss = 1.322271 
iteration = 55 | loss = 1.200780 
iteration = 60 | loss = 1.123585 
iteration = 65 | loss = 1.075374 
iteration = 70 | loss = 1.312018 
iteration = 75 | loss = 1.303242 
iteration = 80 | loss = 0.969293 
iteration = 85 | loss = 1.164737 
iteration = 90 | loss = 1.303129 
iteration = 95 | loss = 0.915259 
iteration = 100 | loss = 1.053413 
iteration = 105 | loss = 1.194085 
 Epoch: [110] Loss: 1.0959  R1_I2A: 0.5913 R1_A2I: 0.4418 
                 
iteration = 0 | loss = 0.715384 
iteration = 5 | loss = 1.071246 
iteration = 10 | loss = 1.209683 
iteration = 15 | loss = 0.875123 
iteration = 20 | loss = 1.315136 
iteration = 25 | loss = 0.893278 
iteration = 30 | loss = 1.055669 
iteration = 35 | loss = 1.170777 
iteration = 40 | loss = 0.985208 
iteration = 45 | loss = 1.072295 
iteration = 50 | loss = 0.938862 
iteration = 55 | loss = 1.111247 
iteration = 60 | loss = 1.113107 
iteration = 65 | loss = 1.047688 
iteration = 70 | loss = 1.160837 
iteration = 75 | loss = 1.151718 
iteration = 80 | loss = 1.298044 
iteration = 85 | loss = 0.929572 
iteration = 90 | loss = 1.242121 
iteration = 95 | loss = 0.815039 
iteration = 100 | loss = 1.326805 
iteration = 105 | loss = 1.186400 
iteration = 0 | loss = 1.013888 
iteration = 5 | loss = 1.152588 
iteration = 10 | loss = 1.267563 
iteration = 15 | loss = 0.981186 
iteration = 20 | loss = 1.124547 
iteration = 25 | loss = 1.071889 
iteration = 30 | loss = 1.119933 
iteration = 35 | loss = 1.159423 
iteration = 40 | loss = 1.184864 
iteration = 45 | loss = 0.954569 
iteration = 50 | loss = 1.033440 
iteration = 55 | loss = 0.586524 
iteration = 60 | loss = 0.843891 
iteration = 65 | loss = 1.130467 
iteration = 70 | loss = 1.254702 
iteration = 75 | loss = 0.839807 
iteration = 80 | loss = 1.012603 
iteration = 85 | loss = 1.059790 
iteration = 90 | loss = 1.026056 
iteration = 95 | loss = 0.984107 
iteration = 100 | loss = 0.886431 
iteration = 105 | loss = 0.982904 
iteration = 0 | loss = 1.008903 
iteration = 5 | loss = 1.024597 
iteration = 10 | loss = 1.192135 
iteration = 15 | loss = 1.034145 
iteration = 20 | loss = 1.170130 
iteration = 25 | loss = 0.917233 
iteration = 30 | loss = 0.957547 
iteration = 35 | loss = 1.148284 
iteration = 40 | loss = 1.001531 
iteration = 45 | loss = 1.176091 
iteration = 50 | loss = 1.118118 
iteration = 55 | loss = 1.232950 
iteration = 60 | loss = 1.093978 
iteration = 65 | loss = 0.702811 
iteration = 70 | loss = 0.834535 
iteration = 75 | loss = 1.283424 
iteration = 80 | loss = 0.929266 
iteration = 85 | loss = 0.948376 
iteration = 90 | loss = 0.840745 
iteration = 95 | loss = 0.944156 
iteration = 100 | loss = 1.090150 
iteration = 105 | loss = 0.976484 
iteration = 0 | loss = 0.908855 
iteration = 5 | loss = 0.849796 
iteration = 10 | loss = 0.884982 
iteration = 15 | loss = 1.046009 
iteration = 20 | loss = 0.980882 
iteration = 25 | loss = 1.000122 
iteration = 30 | loss = 0.982767 
iteration = 35 | loss = 1.002155 
iteration = 40 | loss = 0.784861 
iteration = 45 | loss = 1.179260 
iteration = 50 | loss = 1.211264 
iteration = 55 | loss = 0.932237 
iteration = 60 | loss = 0.861610 
iteration = 65 | loss = 0.896522 
iteration = 70 | loss = 0.738184 
iteration = 75 | loss = 0.891060 
iteration = 80 | loss = 1.058073 
iteration = 85 | loss = 0.893728 
iteration = 90 | loss = 0.954954 
iteration = 95 | loss = 0.942381 
iteration = 100 | loss = 0.869983 
iteration = 105 | loss = 0.792343 
iteration = 0 | loss = 0.784409 
iteration = 5 | loss = 1.039699 
iteration = 10 | loss = 0.999101 
iteration = 15 | loss = 1.221505 
iteration = 20 | loss = 1.169420 
iteration = 25 | loss = 1.120830 
iteration = 30 | loss = 0.798257 
iteration = 35 | loss = 0.823399 
iteration = 40 | loss = 0.542688 
iteration = 45 | loss = 0.841160 
iteration = 50 | loss = 0.943455 
iteration = 55 | loss = 1.044993 
iteration = 60 | loss = 1.125326 
iteration = 65 | loss = 0.967568 
iteration = 70 | loss = 0.936063 
iteration = 75 | loss = 0.771077 
iteration = 80 | loss = 0.935944 
iteration = 85 | loss = 1.095919 
iteration = 90 | loss = 0.880189 
iteration = 95 | loss = 0.888277 
iteration = 100 | loss = 1.037635 
iteration = 105 | loss = 1.155154 
 Epoch: [115] Loss: 1.2146  R1_I2A: 0.5861 R1_A2I: 0.4482 
                 
iteration = 0 | loss = 1.143891 
iteration = 5 | loss = 1.132418 
iteration = 10 | loss = 1.213954 
iteration = 15 | loss = 1.245317 
iteration = 20 | loss = 1.051304 
iteration = 25 | loss = 0.718022 
iteration = 30 | loss = 0.987910 
iteration = 35 | loss = 1.462074 
iteration = 40 | loss = 1.072119 
iteration = 45 | loss = 0.994529 
iteration = 50 | loss = 0.990744 
iteration = 55 | loss = 0.895124 
iteration = 60 | loss = 0.914820 
iteration = 65 | loss = 1.207108 
iteration = 70 | loss = 1.068131 
iteration = 75 | loss = 0.811267 
iteration = 80 | loss = 1.044387 
iteration = 85 | loss = 1.037800 
iteration = 90 | loss = 0.880834 
iteration = 95 | loss = 0.855336 
iteration = 100 | loss = 1.111638 
iteration = 105 | loss = 0.999504 
iteration = 0 | loss = 0.817631 
iteration = 5 | loss = 0.811205 
iteration = 10 | loss = 0.762193 
iteration = 15 | loss = 1.017862 
iteration = 20 | loss = 1.008950 
iteration = 25 | loss = 1.225802 
iteration = 30 | loss = 1.175515 
iteration = 35 | loss = 1.074751 
iteration = 40 | loss = 0.841479 
iteration = 45 | loss = 0.960266 
iteration = 50 | loss = 1.023133 
iteration = 55 | loss = 1.167454 
iteration = 60 | loss = 1.103308 
iteration = 65 | loss = 1.016263 
iteration = 70 | loss = 0.724665 
iteration = 75 | loss = 1.197113 
iteration = 80 | loss = 0.776841 
iteration = 85 | loss = 1.192001 
iteration = 90 | loss = 0.893946 
iteration = 95 | loss = 1.192201 
iteration = 100 | loss = 1.001248 
iteration = 105 | loss = 1.050355 
iteration = 0 | loss = 0.940080 
iteration = 5 | loss = 1.085734 
iteration = 10 | loss = 1.096164 
iteration = 15 | loss = 1.107409 
iteration = 20 | loss = 0.965326 
iteration = 25 | loss = 1.014538 
iteration = 30 | loss = 0.789196 
iteration = 35 | loss = 0.722608 
iteration = 40 | loss = 0.756224 
iteration = 45 | loss = 1.218578 
iteration = 50 | loss = 1.027958 
iteration = 55 | loss = 0.986788 
iteration = 60 | loss = 1.052000 
iteration = 65 | loss = 0.845307 
iteration = 70 | loss = 0.936627 
iteration = 75 | loss = 1.011230 
iteration = 80 | loss = 0.779168 
iteration = 85 | loss = 0.865931 
iteration = 90 | loss = 0.984278 
iteration = 95 | loss = 0.818632 
iteration = 100 | loss = 1.052427 
iteration = 105 | loss = 0.800564 
iteration = 0 | loss = 0.830742 
iteration = 5 | loss = 0.816637 
iteration = 10 | loss = 1.128510 
iteration = 15 | loss = 1.192818 
iteration = 20 | loss = 0.921174 
iteration = 25 | loss = 1.102700 
iteration = 30 | loss = 0.952581 
iteration = 35 | loss = 0.966588 
iteration = 40 | loss = 0.932340 
iteration = 45 | loss = 0.802705 
iteration = 50 | loss = 0.814737 
iteration = 55 | loss = 1.029616 
iteration = 60 | loss = 0.764384 
iteration = 65 | loss = 0.826354 
iteration = 70 | loss = 0.908921 
iteration = 75 | loss = 0.842833 
iteration = 80 | loss = 1.193288 
iteration = 85 | loss = 1.082030 
iteration = 90 | loss = 0.774014 
iteration = 95 | loss = 0.889969 
iteration = 100 | loss = 1.016737 
iteration = 105 | loss = 0.650057 
iteration = 0 | loss = 0.821863 
iteration = 5 | loss = 1.298440 
iteration = 10 | loss = 1.075625 
iteration = 15 | loss = 0.710436 
iteration = 20 | loss = 1.079103 
iteration = 25 | loss = 0.865330 
iteration = 30 | loss = 0.727689 
iteration = 35 | loss = 1.219604 
iteration = 40 | loss = 1.078176 
iteration = 45 | loss = 0.795330 
iteration = 50 | loss = 0.953109 
iteration = 55 | loss = 0.767086 
iteration = 60 | loss = 0.655616 
iteration = 65 | loss = 0.933561 
iteration = 70 | loss = 0.946714 
iteration = 75 | loss = 0.838086 
iteration = 80 | loss = 1.022045 
iteration = 85 | loss = 1.294069 
iteration = 90 | loss = 1.032638 
iteration = 95 | loss = 0.978794 
iteration = 100 | loss = 0.898834 
iteration = 105 | loss = 0.938893 
 Epoch: [120] Loss: 0.8511  R1_I2A: 0.5983 R1_A2I: 0.4519 
                 
iteration = 0 | loss = 0.837281 
iteration = 5 | loss = 0.874068 
iteration = 10 | loss = 0.972845 
iteration = 15 | loss = 0.746847 
iteration = 20 | loss = 0.939042 
iteration = 25 | loss = 1.055688 
iteration = 30 | loss = 0.912974 
iteration = 35 | loss = 0.912861 
iteration = 40 | loss = 1.044962 
iteration = 45 | loss = 0.925060 
iteration = 50 | loss = 0.988381 
iteration = 55 | loss = 0.767671 
iteration = 60 | loss = 1.049026 
iteration = 65 | loss = 0.719536 
iteration = 70 | loss = 0.991284 
iteration = 75 | loss = 0.837874 
iteration = 80 | loss = 0.814148 
iteration = 85 | loss = 0.742542 
iteration = 90 | loss = 0.839195 
iteration = 95 | loss = 1.052100 
iteration = 100 | loss = 1.175045 
iteration = 105 | loss = 1.093796 

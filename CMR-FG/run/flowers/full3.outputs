Namespace(RNN_dropout=0.0, WORKERS=8, audio_attention=None, audio_model='Davenet', batch_size=64, cfg_file='Confg/flower_train_batch.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gamma_clss=1.0, gpu_id=0, image_attention=None, image_model='VGG16', img_size=256, loss_clss=None, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=120, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='full.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/full', simtype='MISA', smooth_gamm3=10.0, smooth_imgatt1=1.0, smooth_imgatt2=1.0, start_epoch=80, tasks='extraction', topk=3, weight_decay=1e-05)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
loaded parameters from epoch 80
current #steps=0, #epochs=80
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 1.413081 
iteration = 5 | loss = 1.452667 
iteration = 10 | loss = 1.850287 
iteration = 15 | loss = 2.028691 
iteration = 20 | loss = 1.591520 
iteration = 25 | loss = 2.269051 
iteration = 30 | loss = 1.662636 
iteration = 35 | loss = 1.814021 
iteration = 40 | loss = 1.996812 
iteration = 45 | loss = 2.312313 
iteration = 50 | loss = 1.789780 
iteration = 55 | loss = 1.845972 
iteration = 60 | loss = 1.717134 
iteration = 65 | loss = 1.917130 
iteration = 70 | loss = 1.639119 
iteration = 75 | loss = 1.628579 
iteration = 80 | loss = 2.068527 
iteration = 85 | loss = 1.949877 
iteration = 90 | loss = 1.617288 
iteration = 95 | loss = 1.739674 
iteration = 100 | loss = 1.716654 
iteration = 105 | loss = 1.629280 
/scratch/xinshengwang/software/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 1.989578 
iteration = 5 | loss = 1.858756 
iteration = 10 | loss = 1.993103 
iteration = 15 | loss = 1.758397 
iteration = 20 | loss = 1.727192 
iteration = 25 | loss = 1.618789 
iteration = 30 | loss = 1.598819 
iteration = 35 | loss = 1.410058 
iteration = 40 | loss = 1.992616 
iteration = 45 | loss = 1.760729 
iteration = 50 | loss = 1.346362 
iteration = 55 | loss = 1.563402 
iteration = 60 | loss = 2.076763 
iteration = 65 | loss = 2.017339 
iteration = 70 | loss = 1.351207 
iteration = 75 | loss = 1.778472 
iteration = 80 | loss = 1.749000 
iteration = 85 | loss = 1.520961 
iteration = 90 | loss = 1.896358 
iteration = 95 | loss = 1.892967 
iteration = 100 | loss = 1.557021 
iteration = 105 | loss = 1.361167 
iteration = 0 | loss = 1.679680 
iteration = 5 | loss = 1.313429 
iteration = 10 | loss = 1.185696 
iteration = 15 | loss = 1.955876 
iteration = 20 | loss = 1.799456 
iteration = 25 | loss = 1.797846 
iteration = 30 | loss = 1.554033 
iteration = 35 | loss = 2.103032 
iteration = 40 | loss = 1.837708 
iteration = 45 | loss = 1.484991 
iteration = 50 | loss = 1.736050 
iteration = 55 | loss = 1.733454 
iteration = 60 | loss = 1.486737 
iteration = 65 | loss = 1.566010 
iteration = 70 | loss = 1.975300 
iteration = 75 | loss = 1.514189 
iteration = 80 | loss = 1.147080 
iteration = 85 | loss = 1.885557 
iteration = 90 | loss = 1.361404 
iteration = 95 | loss = 1.576433 
iteration = 100 | loss = 1.516483 
iteration = 105 | loss = 1.748158 
iteration = 0 | loss = 1.435160 
iteration = 5 | loss = 1.584741 
iteration = 10 | loss = 1.945199 
iteration = 15 | loss = 1.358729 
iteration = 20 | loss = 1.719996 
iteration = 25 | loss = 1.700135 
iteration = 30 | loss = 1.694351 
iteration = 35 | loss = 1.384248 
iteration = 40 | loss = 1.718995 
iteration = 45 | loss = 1.690110 
iteration = 50 | loss = 1.840587 
iteration = 55 | loss = 1.623767 
iteration = 60 | loss = 1.792053 
iteration = 65 | loss = 1.577204 
iteration = 70 | loss = 1.475523 
iteration = 75 | loss = 1.664052 
iteration = 80 | loss = 1.403862 
iteration = 85 | loss = 1.845559 
iteration = 90 | loss = 1.571814 
iteration = 95 | loss = 1.628434 
iteration = 100 | loss = 1.341819 
iteration = 105 | loss = 1.426013 
iteration = 0 | loss = 1.739191 
iteration = 5 | loss = 1.616785 
iteration = 10 | loss = 1.276842 
iteration = 15 | loss = 1.440331 
iteration = 20 | loss = 1.780775 
iteration = 25 | loss = 1.456344 
iteration = 30 | loss = 1.385621 
iteration = 35 | loss = 1.339817 
iteration = 40 | loss = 1.576664 
iteration = 45 | loss = 1.836975 
iteration = 50 | loss = 1.698282 
iteration = 55 | loss = 1.686801 
iteration = 60 | loss = 1.710032 
iteration = 65 | loss = 1.551721 
iteration = 70 | loss = 1.523779 
iteration = 75 | loss = 1.394498 
iteration = 80 | loss = 2.009561 
iteration = 85 | loss = 1.796580 
iteration = 90 | loss = 1.736482 
iteration = 95 | loss = 1.660198 
iteration = 100 | loss = 1.543795 
iteration = 105 | loss = 1.488289 
 Epoch: [85] Loss: 1.5776  R1_I2A: 0.6113 R1_A2I: 0.4567 
                 
 Epoch: [85] Loss: 1.5776  R1_I2A: 0.6105 mAP_I2A: 0.5322  R1_A2I: 0.4567 mAP_A2I: 0.4089 
                     
iteration = 0 | loss = 2.079778 
iteration = 5 | loss = 1.402215 
iteration = 10 | loss = 1.480822 
iteration = 15 | loss = 1.331754 
iteration = 20 | loss = 1.662486 
iteration = 25 | loss = 1.680797 
iteration = 30 | loss = 1.525020 
iteration = 35 | loss = 1.439771 
iteration = 40 | loss = 1.501157 
iteration = 45 | loss = 1.445371 
iteration = 50 | loss = 1.529035 
iteration = 55 | loss = 1.792832 
iteration = 60 | loss = 1.391876 
iteration = 65 | loss = 1.663097 
iteration = 70 | loss = 1.535459 
iteration = 75 | loss = 1.676504 
iteration = 80 | loss = 1.727069 
iteration = 85 | loss = 1.616129 
iteration = 90 | loss = 1.500033 
iteration = 95 | loss = 1.765752 
iteration = 100 | loss = 1.719653 
iteration = 105 | loss = 1.470046 
iteration = 0 | loss = 1.607644 
iteration = 5 | loss = 1.394479 
iteration = 10 | loss = 1.608767 
iteration = 15 | loss = 1.388560 
iteration = 20 | loss = 1.452821 
iteration = 25 | loss = 1.564095 
iteration = 30 | loss = 1.421432 
iteration = 35 | loss = 1.510562 
iteration = 40 | loss = 1.615801 
iteration = 45 | loss = 1.392965 
iteration = 50 | loss = 1.680583 
iteration = 55 | loss = 2.002599 
iteration = 60 | loss = 1.764169 
iteration = 65 | loss = 1.471618 
iteration = 70 | loss = 1.629314 
iteration = 75 | loss = 1.464163 
iteration = 80 | loss = 1.877136 
iteration = 85 | loss = 1.172909 
iteration = 90 | loss = 1.096583 
iteration = 95 | loss = 1.905285 
iteration = 100 | loss = 1.209045 
iteration = 105 | loss = 1.595253 
iteration = 0 | loss = 1.437559 
iteration = 5 | loss = 1.450558 
iteration = 10 | loss = 1.557631 
iteration = 15 | loss = 1.603396 
iteration = 20 | loss = 1.805363 
iteration = 25 | loss = 1.283521 
iteration = 30 | loss = 1.414119 
iteration = 35 | loss = 1.604795 
iteration = 40 | loss = 1.726148 
iteration = 45 | loss = 1.686486 
iteration = 50 | loss = 1.807357 
iteration = 55 | loss = 1.572453 
iteration = 60 | loss = 1.294948 
iteration = 65 | loss = 1.344366 
iteration = 70 | loss = 1.393700 
iteration = 75 | loss = 1.449364 
iteration = 80 | loss = 1.512429 
iteration = 85 | loss = 1.668583 
iteration = 90 | loss = 1.649114 
iteration = 95 | loss = 1.629120 
iteration = 100 | loss = 1.677987 
iteration = 105 | loss = 1.674169 
iteration = 0 | loss = 1.549236 
iteration = 5 | loss = 1.294821 
iteration = 10 | loss = 1.983769 
iteration = 15 | loss = 1.480730 
iteration = 20 | loss = 1.810533 
iteration = 25 | loss = 1.408939 
iteration = 30 | loss = 1.319105 
iteration = 35 | loss = 1.583876 
iteration = 40 | loss = 1.410130 
iteration = 45 | loss = 1.777245 
iteration = 50 | loss = 1.557174 
iteration = 55 | loss = 1.502594 
iteration = 60 | loss = 1.331298 
iteration = 65 | loss = 1.637691 
iteration = 70 | loss = 1.655870 
iteration = 75 | loss = 1.498573 
iteration = 80 | loss = 1.753098 
iteration = 85 | loss = 1.559736 
iteration = 90 | loss = 1.527056 
iteration = 95 | loss = 1.676312 
iteration = 100 | loss = 1.787405 
iteration = 105 | loss = 2.031537 
iteration = 0 | loss = 1.516868 
iteration = 5 | loss = 1.772359 
iteration = 10 | loss = 1.282065 
iteration = 15 | loss = 2.046272 
iteration = 20 | loss = 1.567188 
iteration = 25 | loss = 1.325390 
iteration = 30 | loss = 1.690454 
iteration = 35 | loss = 1.459720 
iteration = 40 | loss = 1.730380 
iteration = 45 | loss = 1.721771 
iteration = 50 | loss = 1.588590 
iteration = 55 | loss = 1.982980 
iteration = 60 | loss = 1.730585 
iteration = 65 | loss = 1.565394 
iteration = 70 | loss = 1.852923 
iteration = 75 | loss = 1.367419 
iteration = 80 | loss = 1.610232 
iteration = 85 | loss = 1.531684 
iteration = 90 | loss = 1.618806 
iteration = 95 | loss = 1.703246 
iteration = 100 | loss = 1.722921 
iteration = 105 | loss = 1.356533 
 Epoch: [90] Loss: 1.4729  R1_I2A: 0.5887 R1_A2I: 0.4583 
                 
iteration = 0 | loss = 1.643603 
iteration = 5 | loss = 1.425059 
iteration = 10 | loss = 1.705779 
iteration = 15 | loss = 1.628200 
iteration = 20 | loss = 2.114305 
iteration = 25 | loss = 1.909021 
iteration = 30 | loss = 1.527050 
iteration = 35 | loss = 1.628756 
iteration = 40 | loss = 1.384723 
iteration = 45 | loss = 1.863510 
iteration = 50 | loss = 1.832152 
iteration = 55 | loss = 1.736733 
iteration = 60 | loss = 1.434490 
iteration = 65 | loss = 1.669178 
iteration = 70 | loss = 1.829097 
iteration = 75 | loss = 1.829300 
iteration = 80 | loss = 1.746108 
iteration = 85 | loss = 1.568695 
iteration = 90 | loss = 1.586532 
iteration = 95 | loss = 1.634019 
iteration = 100 | loss = 2.117430 
iteration = 105 | loss = 1.682435 
iteration = 0 | loss = 1.637596 
iteration = 5 | loss = 1.462228 
iteration = 10 | loss = 1.745027 
iteration = 15 | loss = 1.813615 
iteration = 20 | loss = 1.930521 
iteration = 25 | loss = 1.321998 
iteration = 30 | loss = 1.703834 
iteration = 35 | loss = 1.829488 
iteration = 40 | loss = 1.997546 
iteration = 45 | loss = 2.172993 
iteration = 50 | loss = 1.770020 
iteration = 55 | loss = 1.978346 
iteration = 60 | loss = 1.637407 
iteration = 65 | loss = 1.773084 
iteration = 70 | loss = 1.783006 
iteration = 75 | loss = 2.108458 
iteration = 80 | loss = 1.449610 
iteration = 85 | loss = 1.659039 
iteration = 90 | loss = 1.505337 
iteration = 95 | loss = 1.903046 
iteration = 100 | loss = 1.651733 
iteration = 105 | loss = 1.822648 
iteration = 0 | loss = 1.945389 
iteration = 5 | loss = 1.522147 
iteration = 10 | loss = 1.623028 
iteration = 15 | loss = 1.573240 
iteration = 20 | loss = 1.685643 
iteration = 25 | loss = 1.644657 
iteration = 30 | loss = 2.257644 
iteration = 35 | loss = 1.571694 
iteration = 40 | loss = 1.603871 
iteration = 45 | loss = 2.157265 
iteration = 50 | loss = 1.681456 
iteration = 55 | loss = 1.746702 
iteration = 60 | loss = 1.842895 
iteration = 65 | loss = 1.521256 
iteration = 70 | loss = 1.908777 
iteration = 75 | loss = 1.733103 
iteration = 80 | loss = 1.533945 
iteration = 85 | loss = 1.557872 
iteration = 90 | loss = 1.959660 
iteration = 95 | loss = 2.123271 
iteration = 100 | loss = 1.716094 
iteration = 105 | loss = 1.670177 
iteration = 0 | loss = 1.447381 
iteration = 5 | loss = 1.994614 
iteration = 10 | loss = 1.868366 
iteration = 15 | loss = 1.532237 
iteration = 20 | loss = 1.655300 
iteration = 25 | loss = 1.187791 
iteration = 30 | loss = 1.797841 
iteration = 35 | loss = 1.368183 
iteration = 40 | loss = 1.543340 
iteration = 45 | loss = 1.421245 
iteration = 50 | loss = 1.681818 
iteration = 55 | loss = 1.781720 
iteration = 60 | loss = 1.617068 
iteration = 65 | loss = 1.842381 
iteration = 70 | loss = 2.137067 
iteration = 75 | loss = 1.792603 
iteration = 80 | loss = 1.595345 
iteration = 85 | loss = 1.531881 
iteration = 90 | loss = 1.837379 
iteration = 95 | loss = 1.753399 
iteration = 100 | loss = 1.930433 
iteration = 105 | loss = 1.597204 
iteration = 0 | loss = 1.700705 
iteration = 5 | loss = 1.231335 
iteration = 10 | loss = 1.770377 
iteration = 15 | loss = 1.403479 
iteration = 20 | loss = 1.856207 
iteration = 25 | loss = 1.413465 
iteration = 30 | loss = 1.433410 
iteration = 35 | loss = 1.809295 
iteration = 40 | loss = 1.368101 
iteration = 45 | loss = 1.420468 
iteration = 50 | loss = 1.872577 
iteration = 55 | loss = 2.014812 
iteration = 60 | loss = 1.657131 
iteration = 65 | loss = 1.643151 
iteration = 70 | loss = 1.966023 
iteration = 75 | loss = 1.748286 
iteration = 80 | loss = 1.490164 
iteration = 85 | loss = 1.985975 
iteration = 90 | loss = 2.003387 
iteration = 95 | loss = 1.551212 
iteration = 100 | loss = 1.551200 
iteration = 105 | loss = 1.722100 
 Epoch: [95] Loss: 1.4092  R1_I2A: 0.5879 R1_A2I: 0.4677 
                 
iteration = 0 | loss = 1.915842 
iteration = 5 | loss = 1.564061 
iteration = 10 | loss = 1.570011 
iteration = 15 | loss = 1.759157 
iteration = 20 | loss = 1.525215 
iteration = 25 | loss = 1.622863 
iteration = 30 | loss = 1.666136 
iteration = 35 | loss = 1.870124 
iteration = 40 | loss = 1.389309 
iteration = 45 | loss = 1.478074 
iteration = 50 | loss = 1.542660 
iteration = 55 | loss = 1.316475 
iteration = 60 | loss = 1.841729 
iteration = 65 | loss = 1.529304 
iteration = 70 | loss = 1.855607 
iteration = 75 | loss = 1.663235 
iteration = 80 | loss = 1.620510 
iteration = 85 | loss = 1.680308 
iteration = 90 | loss = 1.714505 
iteration = 95 | loss = 1.439829 
iteration = 100 | loss = 1.518042 
iteration = 105 | loss = 1.324905 
iteration = 0 | loss = 1.734761 
iteration = 5 | loss = 2.087137 
iteration = 10 | loss = 1.618673 
iteration = 15 | loss = 1.486899 
iteration = 20 | loss = 1.637472 
iteration = 25 | loss = 1.673161 
iteration = 30 | loss = 1.599157 
iteration = 35 | loss = 1.992672 
iteration = 40 | loss = 1.569894 
iteration = 45 | loss = 1.604418 
iteration = 50 | loss = 1.889864 
iteration = 55 | loss = 1.717028 
iteration = 60 | loss = 1.722178 
iteration = 65 | loss = 1.515354 
iteration = 70 | loss = 1.541610 
iteration = 75 | loss = 1.597500 
iteration = 80 | loss = 1.484066 
iteration = 85 | loss = 1.719790 
iteration = 90 | loss = 2.008112 
iteration = 95 | loss = 1.633615 
iteration = 100 | loss = 1.579209 
iteration = 105 | loss = 1.350277 
iteration = 0 | loss = 1.619715 
iteration = 5 | loss = 1.425357 
iteration = 10 | loss = 1.575524 
iteration = 15 | loss = 1.860890 
iteration = 20 | loss = 1.361704 
iteration = 25 | loss = 2.092949 
iteration = 30 | loss = 1.350497 
iteration = 35 | loss = 1.586387 
iteration = 40 | loss = 1.489206 
iteration = 45 | loss = 1.304378 
iteration = 50 | loss = 2.120201 
iteration = 55 | loss = 1.661886 
iteration = 60 | loss = 1.549719 
iteration = 65 | loss = 1.707839 
iteration = 70 | loss = 1.976849 
iteration = 75 | loss = 1.232594 
iteration = 80 | loss = 1.810358 
iteration = 85 | loss = 1.684192 
iteration = 90 | loss = 1.510233 
iteration = 95 | loss = 1.737742 
iteration = 100 | loss = 1.880104 
iteration = 105 | loss = 1.729126 
iteration = 0 | loss = 1.947795 
iteration = 5 | loss = 1.302998 
iteration = 10 | loss = 1.440785 
iteration = 15 | loss = 1.658086 
iteration = 20 | loss = 1.173545 
iteration = 25 | loss = 1.721329 
iteration = 30 | loss = 1.630543 
iteration = 35 | loss = 1.961427 
iteration = 40 | loss = 1.279635 
iteration = 45 | loss = 1.638725 
iteration = 50 | loss = 1.376575 
iteration = 55 | loss = 1.838192 
iteration = 60 | loss = 1.646061 
iteration = 65 | loss = 1.803763 
iteration = 70 | loss = 1.935485 
iteration = 75 | loss = 1.349189 
iteration = 80 | loss = 1.695536 
iteration = 85 | loss = 1.350893 
iteration = 90 | loss = 1.683505 
iteration = 95 | loss = 1.695946 
iteration = 100 | loss = 2.061196 
iteration = 105 | loss = 1.313808 
iteration = 0 | loss = 1.623287 
iteration = 5 | loss = 1.926549 
iteration = 10 | loss = 1.543606 
iteration = 15 | loss = 1.339794 
iteration = 20 | loss = 1.582434 
iteration = 25 | loss = 1.442810 
iteration = 30 | loss = 1.540113 
iteration = 35 | loss = 1.469380 
iteration = 40 | loss = 1.278165 
iteration = 45 | loss = 1.597889 
iteration = 50 | loss = 1.629535 
iteration = 55 | loss = 1.212887 
iteration = 60 | loss = 1.264217 
iteration = 65 | loss = 1.522247 
iteration = 70 | loss = 1.209173 
iteration = 75 | loss = 1.228341 
iteration = 80 | loss = 1.657285 
iteration = 85 | loss = 1.801972 
iteration = 90 | loss = 1.416021 
iteration = 95 | loss = 1.250287 
iteration = 100 | loss = 1.559048 
iteration = 105 | loss = 1.682377 
 Epoch: [100] Loss: 1.2295  R1_I2A: 0.6026 R1_A2I: 0.4581 
                 
iteration = 0 | loss = 1.343100 
iteration = 5 | loss = 1.529462 
iteration = 10 | loss = 1.490192 
iteration = 15 | loss = 1.501646 
iteration = 20 | loss = 1.285799 
iteration = 25 | loss = 1.891532 
iteration = 30 | loss = 1.511052 
iteration = 35 | loss = 1.796049 
iteration = 40 | loss = 1.408604 
iteration = 45 | loss = 1.432790 
iteration = 50 | loss = 1.798681 
iteration = 55 | loss = 1.460365 
iteration = 60 | loss = 1.174611 
iteration = 65 | loss = 1.542379 
iteration = 70 | loss = 1.336134 
iteration = 75 | loss = 1.495428 
iteration = 80 | loss = 1.225234 
iteration = 85 | loss = 1.752649 
iteration = 90 | loss = 1.336906 
iteration = 95 | loss = 1.352327 
iteration = 100 | loss = 1.541247 
iteration = 105 | loss = 1.479231 
iteration = 0 | loss = 1.201194 
iteration = 5 | loss = 1.360025 
iteration = 10 | loss = 1.600139 
iteration = 15 | loss = 1.322808 
iteration = 20 | loss = 1.400599 
iteration = 25 | loss = 1.407472 
iteration = 30 | loss = 1.316535 
iteration = 35 | loss = 1.330517 
iteration = 40 | loss = 1.203077 
iteration = 45 | loss = 1.374848 
iteration = 50 | loss = 1.247143 
iteration = 55 | loss = 1.349105 
iteration = 60 | loss = 1.478021 
iteration = 65 | loss = 1.538681 
iteration = 70 | loss = 1.313898 
iteration = 75 | loss = 1.149014 
iteration = 80 | loss = 1.732134 
iteration = 85 | loss = 1.560326 
iteration = 90 | loss = 1.474973 
iteration = 95 | loss = 1.393557 
iteration = 100 | loss = 1.292000 
iteration = 105 | loss = 1.432160 
iteration = 0 | loss = 1.293245 
iteration = 5 | loss = 1.226035 
iteration = 10 | loss = 1.390712 
iteration = 15 | loss = 1.564825 
iteration = 20 | loss = 1.570514 
iteration = 25 | loss = 1.059931 
iteration = 30 | loss = 1.333170 
iteration = 35 | loss = 1.394336 
iteration = 40 | loss = 1.592391 
iteration = 45 | loss = 1.214472 
iteration = 50 | loss = 1.506454 
iteration = 55 | loss = 1.348310 
iteration = 60 | loss = 1.639190 
iteration = 65 | loss = 1.235650 
iteration = 70 | loss = 1.075325 
iteration = 75 | loss = 1.608441 
iteration = 80 | loss = 1.764227 
iteration = 85 | loss = 1.433595 
iteration = 90 | loss = 1.410171 
iteration = 95 | loss = 1.800073 
iteration = 100 | loss = 1.217179 
iteration = 105 | loss = 1.465958 
iteration = 0 | loss = 1.313464 
iteration = 5 | loss = 1.291879 
iteration = 10 | loss = 1.586975 
iteration = 15 | loss = 1.249539 
iteration = 20 | loss = 1.612598 
iteration = 25 | loss = 1.173115 
iteration = 30 | loss = 1.167132 
iteration = 35 | loss = 1.308504 
iteration = 40 | loss = 1.314341 
iteration = 45 | loss = 2.000627 
iteration = 50 | loss = 1.479526 
iteration = 55 | loss = 1.347484 
iteration = 60 | loss = 1.390355 
iteration = 65 | loss = 1.300962 
iteration = 70 | loss = 1.422323 
iteration = 75 | loss = 1.655752 
iteration = 80 | loss = 1.506441 
iteration = 85 | loss = 1.396354 
iteration = 90 | loss = 1.431675 
iteration = 95 | loss = 1.017398 
iteration = 100 | loss = 1.613342 
iteration = 105 | loss = 1.326297 
iteration = 0 | loss = 1.068941 
iteration = 5 | loss = 1.319080 
iteration = 10 | loss = 1.362272 
iteration = 15 | loss = 1.254974 
iteration = 20 | loss = 1.223979 
iteration = 25 | loss = 1.397488 
iteration = 30 | loss = 1.631189 
iteration = 35 | loss = 1.315630 
iteration = 40 | loss = 1.186105 
iteration = 45 | loss = 1.106997 
iteration = 50 | loss = 1.714940 
iteration = 55 | loss = 1.433583 
iteration = 60 | loss = 1.835354 
iteration = 65 | loss = 1.432427 
iteration = 70 | loss = 1.175726 
iteration = 75 | loss = 1.209043 
iteration = 80 | loss = 1.492140 
iteration = 85 | loss = 1.205372 
iteration = 90 | loss = 1.491717 
iteration = 95 | loss = 1.331596 
iteration = 100 | loss = 1.413143 
iteration = 105 | loss = 1.311895 
 Epoch: [105] Loss: 1.3090  R1_I2A: 0.5732 R1_A2I: 0.4539 
                 
iteration = 0 | loss = 1.020738 
iteration = 5 | loss = 1.381643 
iteration = 10 | loss = 1.567741 
iteration = 15 | loss = 1.299501 
iteration = 20 | loss = 1.201185 
iteration = 25 | loss = 1.294909 
iteration = 30 | loss = 1.244684 
iteration = 35 | loss = 1.104504 
iteration = 40 | loss = 1.339228 
iteration = 45 | loss = 1.124132 
iteration = 50 | loss = 1.481448 
iteration = 55 | loss = 1.132568 
iteration = 60 | loss = 1.265182 
iteration = 65 | loss = 1.302996 
iteration = 70 | loss = 1.436682 
iteration = 75 | loss = 1.280067 
iteration = 80 | loss = 1.362356 
iteration = 85 | loss = 1.242070 
iteration = 90 | loss = 1.247876 
iteration = 95 | loss = 1.403938 
iteration = 100 | loss = 1.639954 
iteration = 105 | loss = 1.012220 
iteration = 0 | loss = 1.311394 
iteration = 5 | loss = 1.107720 
iteration = 10 | loss = 0.926429 
iteration = 15 | loss = 1.094548 
iteration = 20 | loss = 0.835318 
iteration = 25 | loss = 1.281743 
iteration = 30 | loss = 1.464646 
iteration = 35 | loss = 1.324792 
iteration = 40 | loss = 1.279037 
iteration = 45 | loss = 1.010670 
iteration = 50 | loss = 1.104720 
iteration = 55 | loss = 1.496453 
iteration = 60 | loss = 1.137987 
iteration = 65 | loss = 1.256678 
iteration = 70 | loss = 1.390260 
iteration = 75 | loss = 1.517394 
iteration = 80 | loss = 1.200262 
iteration = 85 | loss = 1.222518 
iteration = 90 | loss = 1.158709 
iteration = 95 | loss = 1.357926 
iteration = 100 | loss = 1.811337 
iteration = 105 | loss = 1.457734 
iteration = 0 | loss = 1.458503 
iteration = 5 | loss = 1.301831 
iteration = 10 | loss = 1.305583 
iteration = 15 | loss = 1.176824 
iteration = 20 | loss = 1.444656 
iteration = 25 | loss = 0.988422 
iteration = 30 | loss = 1.642732 
iteration = 35 | loss = 1.002040 
iteration = 40 | loss = 1.385171 
iteration = 45 | loss = 1.106516 
iteration = 50 | loss = 1.335423 
iteration = 55 | loss = 1.232322 
iteration = 60 | loss = 1.286221 
iteration = 65 | loss = 1.439333 
iteration = 70 | loss = 1.013089 
iteration = 75 | loss = 1.378523 
iteration = 80 | loss = 1.112839 
iteration = 85 | loss = 1.465667 
iteration = 90 | loss = 1.609831 
iteration = 95 | loss = 0.904380 
iteration = 100 | loss = 1.208118 
iteration = 105 | loss = 1.288197 
iteration = 0 | loss = 1.338723 
iteration = 5 | loss = 1.270984 
iteration = 10 | loss = 1.185614 
iteration = 15 | loss = 1.687270 
iteration = 20 | loss = 1.060794 
iteration = 25 | loss = 1.510211 
iteration = 30 | loss = 1.167011 
iteration = 35 | loss = 1.184607 
iteration = 40 | loss = 1.315068 
iteration = 45 | loss = 1.434026 
iteration = 50 | loss = 1.247719 
iteration = 55 | loss = 1.350780 
iteration = 60 | loss = 1.357092 
iteration = 65 | loss = 1.609331 
iteration = 70 | loss = 1.207024 
iteration = 75 | loss = 1.304494 
iteration = 80 | loss = 1.092290 
iteration = 85 | loss = 1.161041 
iteration = 90 | loss = 1.073119 
iteration = 95 | loss = 1.300360 
iteration = 100 | loss = 1.150905 
iteration = 105 | loss = 1.445365 
iteration = 0 | loss = 1.117847 
iteration = 5 | loss = 1.073805 
iteration = 10 | loss = 1.373410 
iteration = 15 | loss = 1.119577 
iteration = 20 | loss = 1.341878 
iteration = 25 | loss = 1.308834 
iteration = 30 | loss = 0.912879 
iteration = 35 | loss = 1.131601 
iteration = 40 | loss = 1.371318 
iteration = 45 | loss = 1.041599 
iteration = 50 | loss = 1.262346 
iteration = 55 | loss = 1.564266 
iteration = 60 | loss = 1.393893 
iteration = 65 | loss = 1.217013 
iteration = 70 | loss = 1.406510 
iteration = 75 | loss = 1.314489 
iteration = 80 | loss = 1.198240 
iteration = 85 | loss = 1.073499 
iteration = 90 | loss = 1.600135 
iteration = 95 | loss = 1.181291 
iteration = 100 | loss = 1.101201 
iteration = 105 | loss = 1.391062 
 Epoch: [110] Loss: 1.0805  R1_I2A: 0.6052 R1_A2I: 0.4493 
                 
iteration = 0 | loss = 1.332081 
iteration = 5 | loss = 1.162660 
iteration = 10 | loss = 1.049080 
iteration = 15 | loss = 1.338509 
iteration = 20 | loss = 1.306142 
iteration = 25 | loss = 1.262768 
iteration = 30 | loss = 1.235841 
iteration = 35 | loss = 1.084313 
iteration = 40 | loss = 1.261095 
iteration = 45 | loss = 1.161046 
iteration = 50 | loss = 0.985250 
iteration = 55 | loss = 1.522881 
iteration = 60 | loss = 1.502005 
iteration = 65 | loss = 1.448010 
iteration = 70 | loss = 1.492688 
iteration = 75 | loss = 1.354485 
iteration = 80 | loss = 1.578084 
iteration = 85 | loss = 1.350456 
iteration = 90 | loss = 1.418448 
iteration = 95 | loss = 1.394485 
iteration = 100 | loss = 1.267959 
iteration = 105 | loss = 1.163045 
iteration = 0 | loss = 1.026131 
iteration = 5 | loss = 1.458026 
iteration = 10 | loss = 1.756629 
iteration = 15 | loss = 1.288780 
iteration = 20 | loss = 1.328853 
iteration = 25 | loss = 1.605650 
iteration = 30 | loss = 1.221019 
iteration = 35 | loss = 1.586697 
iteration = 40 | loss = 1.373348 
iteration = 45 | loss = 1.143695 
iteration = 50 | loss = 1.228362 
iteration = 55 | loss = 1.431195 
iteration = 60 | loss = 1.255233 
iteration = 65 | loss = 1.478682 
iteration = 70 | loss = 1.307133 
iteration = 75 | loss = 1.135905 
iteration = 80 | loss = 1.444637 
iteration = 85 | loss = 1.141279 
iteration = 90 | loss = 1.251983 
iteration = 95 | loss = 1.336321 
iteration = 100 | loss = 1.152770 
iteration = 105 | loss = 1.264628 
iteration = 0 | loss = 1.455022 
iteration = 5 | loss = 1.269587 
iteration = 10 | loss = 1.227501 
iteration = 15 | loss = 1.536144 
iteration = 20 | loss = 1.085873 
iteration = 25 | loss = 1.323424 
iteration = 30 | loss = 1.311081 
iteration = 35 | loss = 1.356822 
iteration = 40 | loss = 1.160717 
iteration = 45 | loss = 1.357793 
iteration = 50 | loss = 1.128461 
iteration = 55 | loss = 1.467343 
iteration = 60 | loss = 1.126403 
iteration = 65 | loss = 1.207479 
iteration = 70 | loss = 1.361350 
iteration = 75 | loss = 1.388910 
iteration = 80 | loss = 1.430886 
iteration = 85 | loss = 1.408641 
iteration = 90 | loss = 1.492597 
iteration = 95 | loss = 1.309426 
iteration = 100 | loss = 1.194531 
iteration = 105 | loss = 1.328465 
iteration = 0 | loss = 1.192656 
iteration = 5 | loss = 1.467064 
iteration = 10 | loss = 1.117517 
iteration = 15 | loss = 1.267896 
iteration = 20 | loss = 1.089437 
iteration = 25 | loss = 1.063603 
iteration = 30 | loss = 1.350302 
iteration = 35 | loss = 1.131905 
iteration = 40 | loss = 1.564426 
iteration = 45 | loss = 1.201396 
iteration = 50 | loss = 1.394984 
iteration = 55 | loss = 1.075702 
iteration = 60 | loss = 1.270418 
iteration = 65 | loss = 1.268735 
iteration = 70 | loss = 1.304131 
iteration = 75 | loss = 0.959887 
iteration = 80 | loss = 1.365207 
iteration = 85 | loss = 1.513880 
iteration = 90 | loss = 1.296016 
iteration = 95 | loss = 1.458257 
iteration = 100 | loss = 1.142471 
iteration = 105 | loss = 1.580692 
iteration = 0 | loss = 1.482808 
iteration = 5 | loss = 1.202441 
iteration = 10 | loss = 1.016177 
iteration = 15 | loss = 1.373774 
iteration = 20 | loss = 1.464580 
iteration = 25 | loss = 1.205982 
iteration = 30 | loss = 1.247316 
iteration = 35 | loss = 1.585593 
iteration = 40 | loss = 1.100524 
iteration = 45 | loss = 1.178308 
iteration = 50 | loss = 1.162872 
iteration = 55 | loss = 1.069498 
iteration = 60 | loss = 0.885470 
iteration = 65 | loss = 1.091522 
iteration = 70 | loss = 1.108654 
iteration = 75 | loss = 0.944167 
iteration = 80 | loss = 1.166277 
iteration = 85 | loss = 1.315822 
iteration = 90 | loss = 0.992349 
iteration = 95 | loss = 1.256513 
iteration = 100 | loss = 1.073038 
iteration = 105 | loss = 1.406705 
 Epoch: [115] Loss: 1.1402  R1_I2A: 0.6017 R1_A2I: 0.4487 
                 
iteration = 0 | loss = 1.132264 
iteration = 5 | loss = 1.183709 
iteration = 10 | loss = 0.879020 
iteration = 15 | loss = 1.501311 
iteration = 20 | loss = 0.972384 
iteration = 25 | loss = 1.193728 
iteration = 30 | loss = 1.076942 
iteration = 35 | loss = 1.002268 
iteration = 40 | loss = 1.137028 
iteration = 45 | loss = 1.122184 
iteration = 50 | loss = 1.176494 
iteration = 55 | loss = 1.496585 
iteration = 60 | loss = 1.233253 
iteration = 65 | loss = 1.292576 
iteration = 70 | loss = 1.444043 
iteration = 75 | loss = 1.313083 
iteration = 80 | loss = 1.159208 
iteration = 85 | loss = 0.989018 
iteration = 90 | loss = 1.169536 
iteration = 95 | loss = 1.048699 
iteration = 100 | loss = 1.311777 
iteration = 105 | loss = 1.521835 
iteration = 0 | loss = 1.266951 
iteration = 5 | loss = 0.968542 
iteration = 10 | loss = 1.286863 
iteration = 15 | loss = 1.209564 
iteration = 20 | loss = 1.175283 
iteration = 25 | loss = 0.955546 
iteration = 30 | loss = 1.289027 
iteration = 35 | loss = 1.329301 
iteration = 40 | loss = 1.006298 
iteration = 45 | loss = 1.165783 
iteration = 50 | loss = 1.093034 
iteration = 55 | loss = 0.964800 
iteration = 60 | loss = 0.881873 
iteration = 65 | loss = 1.174395 
iteration = 70 | loss = 1.213877 
iteration = 75 | loss = 1.052313 
iteration = 80 | loss = 1.164598 
iteration = 85 | loss = 1.016775 
iteration = 90 | loss = 0.981672 
iteration = 95 | loss = 1.446610 
iteration = 100 | loss = 1.024237 
iteration = 105 | loss = 1.390678 
iteration = 0 | loss = 1.073147 
iteration = 5 | loss = 1.135326 
iteration = 10 | loss = 0.993675 
iteration = 15 | loss = 1.168388 
iteration = 20 | loss = 1.216171 
iteration = 25 | loss = 1.237565 
iteration = 30 | loss = 1.194765 
iteration = 35 | loss = 1.451631 
iteration = 40 | loss = 1.271013 
iteration = 45 | loss = 0.990808 
iteration = 50 | loss = 1.341046 
iteration = 55 | loss = 1.164946 
iteration = 60 | loss = 1.395349 
iteration = 65 | loss = 1.032982 
iteration = 70 | loss = 1.162017 
iteration = 75 | loss = 1.219645 
iteration = 80 | loss = 1.343248 
iteration = 85 | loss = 1.348062 
iteration = 90 | loss = 1.123457 
iteration = 95 | loss = 1.070683 
iteration = 100 | loss = 0.898625 
iteration = 105 | loss = 1.451450 
iteration = 0 | loss = 1.152599 
iteration = 5 | loss = 0.891236 
iteration = 10 | loss = 0.927800 
iteration = 15 | loss = 1.275174 
iteration = 20 | loss = 1.493103 
iteration = 25 | loss = 0.959214 
iteration = 30 | loss = 0.971116 
iteration = 35 | loss = 1.369991 
iteration = 40 | loss = 1.152591 
iteration = 45 | loss = 1.110941 
iteration = 50 | loss = 1.024045 
iteration = 55 | loss = 0.884015 
iteration = 60 | loss = 1.148137 
iteration = 65 | loss = 1.132030 
iteration = 70 | loss = 1.016995 
iteration = 75 | loss = 1.200852 
iteration = 80 | loss = 1.101324 
iteration = 85 | loss = 0.990690 
iteration = 90 | loss = 1.347158 
iteration = 95 | loss = 1.043386 
iteration = 100 | loss = 1.107603 
iteration = 105 | loss = 1.172522 
iteration = 0 | loss = 1.106893 
iteration = 5 | loss = 0.857982 
iteration = 10 | loss = 1.065154 
iteration = 15 | loss = 1.344107 
iteration = 20 | loss = 1.159132 
iteration = 25 | loss = 1.060668 
iteration = 30 | loss = 1.156208 
iteration = 35 | loss = 0.922377 
iteration = 40 | loss = 1.040159 
iteration = 45 | loss = 1.102411 
iteration = 50 | loss = 1.286169 
iteration = 55 | loss = 1.094079 
iteration = 60 | loss = 1.401929 
iteration = 65 | loss = 1.104439 
iteration = 70 | loss = 1.061050 
iteration = 75 | loss = 1.211069 
iteration = 80 | loss = 1.428306 
iteration = 85 | loss = 1.202145 
iteration = 90 | loss = 1.262091 
iteration = 95 | loss = 1.056746 
iteration = 100 | loss = 0.955972 
iteration = 105 | loss = 1.122571 
 Epoch: [120] Loss: 1.1087  R1_I2A: 0.6095 R1_A2I: 0.4423 
                 
iteration = 0 | loss = 1.110038 
iteration = 5 | loss = 1.200760 
iteration = 10 | loss = 1.112759 
iteration = 15 | loss = 1.000180 
iteration = 20 | loss = 1.196472 
iteration = 25 | loss = 1.143972 
iteration = 30 | loss = 1.030509 
iteration = 35 | loss = 0.958795 
iteration = 40 | loss = 1.053845 
iteration = 45 | loss = 1.186470 
iteration = 50 | loss = 1.437180 
iteration = 55 | loss = 1.151395 
iteration = 60 | loss = 1.142335 
iteration = 65 | loss = 1.046120 
iteration = 70 | loss = 0.877645 
iteration = 75 | loss = 1.138295 
iteration = 80 | loss = 1.302892 
iteration = 85 | loss = 1.095358 
iteration = 90 | loss = 1.226989 
iteration = 95 | loss = 1.009145 
iteration = 100 | loss = 1.218051 
iteration = 105 | loss = 1.456216 

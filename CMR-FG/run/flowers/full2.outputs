Namespace(RNN_dropout=0.0, WORKERS=8, audio_attention=None, audio_model='Davenet', batch_size=64, cfg_file='Confg/flower_train_batch.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gamma_clss=1.0, gpu_id=0, image_attention=None, image_model='VGG16', img_size=256, loss_clss=None, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=80, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='full.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/full', simtype='MISA', smooth_gamm3=10.0, smooth_imgatt1=1.0, smooth_imgatt2=1.0, start_epoch=40, tasks='extraction', topk=3, weight_decay=1e-05)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 2.836826 
iteration = 5 | loss = 2.963141 
iteration = 10 | loss = 2.850005 
iteration = 15 | loss = 3.127295 
iteration = 20 | loss = 2.709300 
iteration = 25 | loss = 3.842716 
iteration = 30 | loss = 2.585514 
iteration = 35 | loss = 3.358061 
iteration = 40 | loss = 2.989782 
iteration = 45 | loss = 3.598075 
iteration = 50 | loss = 3.212953 
iteration = 55 | loss = 2.950909 
iteration = 60 | loss = 2.709133 
iteration = 65 | loss = 3.084317 
iteration = 70 | loss = 2.833440 
iteration = 75 | loss = 2.611990 
iteration = 80 | loss = 2.808506 
iteration = 85 | loss = 3.299834 
iteration = 90 | loss = 2.724895 
iteration = 95 | loss = 2.854045 
iteration = 100 | loss = 2.927403 
iteration = 105 | loss = 2.648667 
/scratch/xinshengwang/software/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 2.900459 
iteration = 5 | loss = 2.831049 
iteration = 10 | loss = 3.338989 
iteration = 15 | loss = 2.871793 
iteration = 20 | loss = 3.004900 
iteration = 25 | loss = 3.086417 
iteration = 30 | loss = 2.904913 
iteration = 35 | loss = 2.367877 
iteration = 40 | loss = 3.203707 
iteration = 45 | loss = 3.112794 
iteration = 50 | loss = 2.521708 
iteration = 55 | loss = 2.658475 
iteration = 60 | loss = 3.174373 
iteration = 65 | loss = 3.398324 
iteration = 70 | loss = 2.583438 
iteration = 75 | loss = 3.081482 
iteration = 80 | loss = 2.868090 
iteration = 85 | loss = 2.504583 
iteration = 90 | loss = 2.932421 
iteration = 95 | loss = 3.095059 
iteration = 100 | loss = 2.448392 
iteration = 105 | loss = 2.456985 
iteration = 0 | loss = 2.967734 
iteration = 5 | loss = 2.299249 
iteration = 10 | loss = 2.160297 
iteration = 15 | loss = 3.281400 
iteration = 20 | loss = 2.957315 
iteration = 25 | loss = 3.062075 
iteration = 30 | loss = 2.530545 
iteration = 35 | loss = 3.263805 
iteration = 40 | loss = 3.251068 
iteration = 45 | loss = 2.239997 
iteration = 50 | loss = 2.952135 
iteration = 55 | loss = 2.743735 
iteration = 60 | loss = 2.501328 
iteration = 65 | loss = 2.564039 
iteration = 70 | loss = 2.983711 
iteration = 75 | loss = 2.379067 
iteration = 80 | loss = 2.112890 
iteration = 85 | loss = 3.077724 
iteration = 90 | loss = 2.476156 
iteration = 95 | loss = 2.685485 
iteration = 100 | loss = 2.600670 
iteration = 105 | loss = 2.850177 
iteration = 0 | loss = 2.566973 
iteration = 5 | loss = 2.603467 
iteration = 10 | loss = 2.908107 
iteration = 15 | loss = 2.600156 
iteration = 20 | loss = 2.734316 
iteration = 25 | loss = 2.930494 
iteration = 30 | loss = 2.685037 
iteration = 35 | loss = 2.445694 
iteration = 40 | loss = 2.555507 
iteration = 45 | loss = 2.660839 
iteration = 50 | loss = 2.946105 
iteration = 55 | loss = 2.608102 
iteration = 60 | loss = 2.903691 
iteration = 65 | loss = 2.790610 
iteration = 70 | loss = 2.537514 
iteration = 75 | loss = 2.931468 
iteration = 80 | loss = 2.320137 
iteration = 85 | loss = 2.897559 
iteration = 90 | loss = 2.354257 
iteration = 95 | loss = 2.738283 
iteration = 100 | loss = 2.585473 
iteration = 105 | loss = 2.545306 
iteration = 0 | loss = 2.499181 
iteration = 5 | loss = 2.794053 
iteration = 10 | loss = 2.053481 
iteration = 15 | loss = 2.489247 
iteration = 20 | loss = 2.673260 
iteration = 25 | loss = 2.329099 
iteration = 30 | loss = 2.484685 
iteration = 35 | loss = 2.170116 
iteration = 40 | loss = 2.963810 
iteration = 45 | loss = 3.074900 
iteration = 50 | loss = 2.856147 
iteration = 55 | loss = 2.724484 
iteration = 60 | loss = 2.585454 
iteration = 65 | loss = 2.626563 
iteration = 70 | loss = 2.683086 
iteration = 75 | loss = 2.589040 
iteration = 80 | loss = 3.334239 
iteration = 85 | loss = 3.019651 
iteration = 90 | loss = 2.697361 
iteration = 95 | loss = 2.481721 
iteration = 100 | loss = 2.678582 
iteration = 105 | loss = 2.511989 
 Epoch: [45] Loss: 2.7254  R1_I2A: 0.5957 R1_A2I: 0.4716 
                 
 Epoch: [45] Loss: 2.7254  R1_I2A: 0.5989 mAP_I2A: 0.5173  R1_A2I: 0.4716 mAP_A2I: 0.4135 
                     
iteration = 0 | loss = 3.193452 
iteration = 5 | loss = 2.457118 
iteration = 10 | loss = 2.655877 
iteration = 15 | loss = 2.597250 
iteration = 20 | loss = 3.182215 
iteration = 25 | loss = 2.657996 
iteration = 30 | loss = 2.758320 
iteration = 35 | loss = 2.447976 
iteration = 40 | loss = 2.475243 
iteration = 45 | loss = 2.399943 
iteration = 50 | loss = 2.665130 
iteration = 55 | loss = 2.903047 
iteration = 60 | loss = 2.479244 
iteration = 65 | loss = 2.955591 
iteration = 70 | loss = 2.732223 
iteration = 75 | loss = 2.898568 
iteration = 80 | loss = 2.749848 
iteration = 85 | loss = 2.613365 
iteration = 90 | loss = 2.739897 
iteration = 95 | loss = 2.983153 
iteration = 100 | loss = 2.748969 
iteration = 105 | loss = 2.908017 
iteration = 0 | loss = 2.740146 
iteration = 5 | loss = 2.435995 
iteration = 10 | loss = 2.523376 
iteration = 15 | loss = 2.571362 
iteration = 20 | loss = 2.598297 
iteration = 25 | loss = 2.726653 
iteration = 30 | loss = 2.392560 
iteration = 35 | loss = 2.712974 
iteration = 40 | loss = 2.895290 
iteration = 45 | loss = 2.436695 
iteration = 50 | loss = 2.775017 
iteration = 55 | loss = 3.251740 
iteration = 60 | loss = 2.741070 
iteration = 65 | loss = 2.414765 
iteration = 70 | loss = 2.875678 
iteration = 75 | loss = 2.733089 
iteration = 80 | loss = 3.043953 
iteration = 85 | loss = 2.168632 
iteration = 90 | loss = 1.941760 
iteration = 95 | loss = 3.058031 
iteration = 100 | loss = 2.478097 
iteration = 105 | loss = 2.747249 
iteration = 0 | loss = 2.402790 
iteration = 5 | loss = 2.621221 
iteration = 10 | loss = 2.621374 
iteration = 15 | loss = 2.582169 
iteration = 20 | loss = 3.063534 
iteration = 25 | loss = 2.612044 
iteration = 30 | loss = 2.265162 
iteration = 35 | loss = 2.632187 
iteration = 40 | loss = 2.624634 
iteration = 45 | loss = 2.921985 
iteration = 50 | loss = 2.880099 
iteration = 55 | loss = 2.712581 
iteration = 60 | loss = 2.666181 
iteration = 65 | loss = 2.527596 
iteration = 70 | loss = 2.496085 
iteration = 75 | loss = 2.300151 
iteration = 80 | loss = 2.825102 
iteration = 85 | loss = 2.793129 
iteration = 90 | loss = 2.869437 
iteration = 95 | loss = 2.729455 
iteration = 100 | loss = 2.827044 
iteration = 105 | loss = 2.891016 
iteration = 0 | loss = 2.871547 
iteration = 5 | loss = 2.366803 
iteration = 10 | loss = 3.038975 
iteration = 15 | loss = 2.357265 
iteration = 20 | loss = 2.952227 
iteration = 25 | loss = 2.359382 
iteration = 30 | loss = 2.585146 
iteration = 35 | loss = 2.720981 
iteration = 40 | loss = 2.459318 
iteration = 45 | loss = 2.669345 
iteration = 50 | loss = 2.813172 
iteration = 55 | loss = 2.645511 
iteration = 60 | loss = 2.421377 
iteration = 65 | loss = 2.751772 
iteration = 70 | loss = 2.956647 
iteration = 75 | loss = 2.500012 
iteration = 80 | loss = 2.912308 
iteration = 85 | loss = 2.403177 
iteration = 90 | loss = 2.477582 
iteration = 95 | loss = 2.705119 
iteration = 100 | loss = 2.910477 
iteration = 105 | loss = 2.824565 
iteration = 0 | loss = 2.753914 
iteration = 5 | loss = 2.826684 
iteration = 10 | loss = 2.094647 
iteration = 15 | loss = 3.277312 
iteration = 20 | loss = 2.461160 
iteration = 25 | loss = 2.243463 
iteration = 30 | loss = 2.494278 
iteration = 35 | loss = 2.395778 
iteration = 40 | loss = 2.720410 
iteration = 45 | loss = 2.862571 
iteration = 50 | loss = 2.615609 
iteration = 55 | loss = 3.078876 
iteration = 60 | loss = 2.786483 
iteration = 65 | loss = 2.777781 
iteration = 70 | loss = 2.782554 
iteration = 75 | loss = 2.149723 
iteration = 80 | loss = 2.646914 
iteration = 85 | loss = 2.429556 
iteration = 90 | loss = 2.487069 
iteration = 95 | loss = 2.720865 
iteration = 100 | loss = 2.720343 
iteration = 105 | loss = 2.409266 
 Epoch: [50] Loss: 2.2553  R1_I2A: 0.5870 R1_A2I: 0.4816 
                 
 Epoch: [50] Loss: 2.2553  R1_I2A: 0.5874 mAP_I2A: 0.5258  R1_A2I: 0.4816 mAP_A2I: 0.4254 
                     
iteration = 0 | loss = 2.257722 
iteration = 5 | loss = 2.517522 
iteration = 10 | loss = 2.415816 
iteration = 15 | loss = 2.492618 
iteration = 20 | loss = 2.325070 
iteration = 25 | loss = 2.495502 
iteration = 30 | loss = 2.261965 
iteration = 35 | loss = 2.018819 
iteration = 40 | loss = 2.058135 
iteration = 45 | loss = 1.951088 
iteration = 50 | loss = 2.267411 
iteration = 55 | loss = 2.090661 
iteration = 60 | loss = 2.620198 
iteration = 65 | loss = 2.795469 
iteration = 70 | loss = 2.911164 
iteration = 75 | loss = 2.538180 
iteration = 80 | loss = 3.112463 
iteration = 85 | loss = 2.593993 
iteration = 90 | loss = 2.679041 
iteration = 95 | loss = 2.389946 
iteration = 100 | loss = 2.499221 
iteration = 105 | loss = 2.180855 
iteration = 0 | loss = 2.333721 
iteration = 5 | loss = 2.217086 
iteration = 10 | loss = 2.741969 
iteration = 15 | loss = 2.090528 
iteration = 20 | loss = 2.795113 
iteration = 25 | loss = 2.888200 
iteration = 30 | loss = 2.526781 
iteration = 35 | loss = 3.127174 
iteration = 40 | loss = 2.928197 
iteration = 45 | loss = 2.900257 
iteration = 50 | loss = 2.268235 
iteration = 55 | loss = 2.670578 
iteration = 60 | loss = 2.500993 
iteration = 65 | loss = 2.600075 
iteration = 70 | loss = 2.460861 
iteration = 75 | loss = 2.131433 
iteration = 80 | loss = 2.344495 
iteration = 85 | loss = 2.498477 
iteration = 90 | loss = 2.575154 
iteration = 95 | loss = 2.735626 
iteration = 100 | loss = 2.312874 
iteration = 105 | loss = 2.426789 
iteration = 0 | loss = 2.112536 
iteration = 5 | loss = 2.631499 
iteration = 10 | loss = 2.658601 
iteration = 15 | loss = 2.718327 
iteration = 20 | loss = 2.144642 
iteration = 25 | loss = 2.038417 
iteration = 30 | loss = 2.176433 
iteration = 35 | loss = 2.251250 
iteration = 40 | loss = 2.577431 
iteration = 45 | loss = 2.263918 
iteration = 50 | loss = 2.840608 
iteration = 55 | loss = 2.733319 
iteration = 60 | loss = 2.652186 
iteration = 65 | loss = 2.699549 
iteration = 70 | loss = 2.748418 
iteration = 75 | loss = 2.807752 
iteration = 80 | loss = 3.023001 
iteration = 85 | loss = 2.417721 
iteration = 90 | loss = 2.642697 
iteration = 95 | loss = 2.866773 
iteration = 100 | loss = 2.710516 
iteration = 105 | loss = 2.284595 
iteration = 0 | loss = 2.578282 
iteration = 5 | loss = 2.415364 
iteration = 10 | loss = 2.127474 
iteration = 15 | loss = 2.602911 
iteration = 20 | loss = 1.842045 
iteration = 25 | loss = 2.212394 
iteration = 30 | loss = 2.307752 
iteration = 35 | loss = 2.195393 
iteration = 40 | loss = 2.334265 
iteration = 45 | loss = 2.440340 
iteration = 50 | loss = 2.714231 
iteration = 55 | loss = 1.996145 
iteration = 60 | loss = 1.627393 
iteration = 65 | loss = 2.331915 
iteration = 70 | loss = 2.296725 
iteration = 75 | loss = 2.531507 
iteration = 80 | loss = 2.479970 
iteration = 85 | loss = 2.160166 
iteration = 90 | loss = 2.381122 
iteration = 95 | loss = 2.373018 
iteration = 100 | loss = 2.656600 
iteration = 105 | loss = 2.419996 
iteration = 0 | loss = 2.649586 
iteration = 5 | loss = 2.592910 
iteration = 10 | loss = 2.191947 
iteration = 15 | loss = 2.095193 
iteration = 20 | loss = 2.166508 
iteration = 25 | loss = 2.486217 
iteration = 30 | loss = 2.477139 
iteration = 35 | loss = 2.479780 
iteration = 40 | loss = 2.326785 
iteration = 45 | loss = 2.411931 
iteration = 50 | loss = 2.287886 
iteration = 55 | loss = 2.152256 
iteration = 60 | loss = 2.643372 
iteration = 65 | loss = 2.458364 
iteration = 70 | loss = 2.853226 
iteration = 75 | loss = 2.502091 
iteration = 80 | loss = 2.491737 
iteration = 85 | loss = 2.023214 
iteration = 90 | loss = 2.800187 
iteration = 95 | loss = 1.990398 
iteration = 100 | loss = 2.291609 
iteration = 105 | loss = 2.417067 
 Epoch: [55] Loss: 2.7122  R1_I2A: 0.5905 R1_A2I: 0.4886 
                 
 Epoch: [55] Loss: 2.7122  R1_I2A: 0.5982 mAP_I2A: 0.5290  R1_A2I: 0.4886 mAP_A2I: 0.4251 
                     
iteration = 0 | loss = 2.572662 
iteration = 5 | loss = 2.466571 
iteration = 10 | loss = 2.737140 
iteration = 15 | loss = 2.856730 
iteration = 20 | loss = 2.026651 
iteration = 25 | loss = 2.502031 
iteration = 30 | loss = 2.522279 
iteration = 35 | loss = 2.568995 
iteration = 40 | loss = 2.094966 
iteration = 45 | loss = 2.221149 
iteration = 50 | loss = 2.754411 
iteration = 55 | loss = 2.618824 
iteration = 60 | loss = 2.218711 
iteration = 65 | loss = 2.488333 
iteration = 70 | loss = 2.654932 
iteration = 75 | loss = 2.261590 
iteration = 80 | loss = 2.255500 
iteration = 85 | loss = 2.365755 
iteration = 90 | loss = 2.608985 
iteration = 95 | loss = 2.167227 
iteration = 100 | loss = 2.361783 
iteration = 105 | loss = 2.711402 
iteration = 0 | loss = 2.606108 
iteration = 5 | loss = 1.870517 
iteration = 10 | loss = 2.380405 
iteration = 15 | loss = 2.642552 
iteration = 20 | loss = 2.865482 
iteration = 25 | loss = 2.321582 
iteration = 30 | loss = 2.502077 
iteration = 35 | loss = 2.556557 
iteration = 40 | loss = 2.449942 
iteration = 45 | loss = 2.342427 
iteration = 50 | loss = 2.429500 
iteration = 55 | loss = 2.752513 
iteration = 60 | loss = 2.491059 
iteration = 65 | loss = 2.603010 
iteration = 70 | loss = 1.815016 
iteration = 75 | loss = 2.264611 
iteration = 80 | loss = 2.487596 
iteration = 85 | loss = 1.964532 
iteration = 90 | loss = 2.519147 
iteration = 95 | loss = 2.531093 
iteration = 100 | loss = 2.642389 
iteration = 105 | loss = 2.235681 
iteration = 0 | loss = 2.529174 
iteration = 5 | loss = 2.511074 
iteration = 10 | loss = 2.025620 
iteration = 15 | loss = 2.569488 
iteration = 20 | loss = 2.002383 
iteration = 25 | loss = 2.097644 
iteration = 30 | loss = 2.449195 
iteration = 35 | loss = 2.334243 
iteration = 40 | loss = 2.016696 
iteration = 45 | loss = 2.548086 
iteration = 50 | loss = 2.045552 
iteration = 55 | loss = 2.424282 
iteration = 60 | loss = 2.017123 
iteration = 65 | loss = 2.385353 
iteration = 70 | loss = 2.439982 
iteration = 75 | loss = 2.137711 
iteration = 80 | loss = 2.749570 
iteration = 85 | loss = 1.842506 
iteration = 90 | loss = 2.438526 
iteration = 95 | loss = 2.688571 
iteration = 100 | loss = 1.951179 
iteration = 105 | loss = 2.711551 
iteration = 0 | loss = 2.419979 
iteration = 5 | loss = 2.342217 
iteration = 10 | loss = 2.022882 
iteration = 15 | loss = 2.697815 
iteration = 20 | loss = 2.041584 
iteration = 25 | loss = 2.126221 
iteration = 30 | loss = 2.445134 
iteration = 35 | loss = 2.589027 
iteration = 40 | loss = 2.691844 
iteration = 45 | loss = 1.833321 
iteration = 50 | loss = 2.422464 
iteration = 55 | loss = 1.988058 
iteration = 60 | loss = 2.363214 
iteration = 65 | loss = 2.674516 
iteration = 70 | loss = 2.509981 
iteration = 75 | loss = 2.428988 
iteration = 80 | loss = 2.073918 
iteration = 85 | loss = 2.357607 
iteration = 90 | loss = 2.414105 
iteration = 95 | loss = 2.472986 
iteration = 100 | loss = 2.448860 
iteration = 105 | loss = 1.825950 
iteration = 0 | loss = 2.081398 
iteration = 5 | loss = 2.044462 
iteration = 10 | loss = 1.723553 
iteration = 15 | loss = 2.435263 
iteration = 20 | loss = 2.302697 
iteration = 25 | loss = 2.001717 
iteration = 30 | loss = 2.679507 
iteration = 35 | loss = 2.561474 
iteration = 40 | loss = 2.533017 
iteration = 45 | loss = 2.664248 
iteration = 50 | loss = 2.788148 
iteration = 55 | loss = 2.299630 
iteration = 60 | loss = 2.607469 
iteration = 65 | loss = 2.261450 
iteration = 70 | loss = 2.098591 
iteration = 75 | loss = 2.591026 
iteration = 80 | loss = 2.194533 
iteration = 85 | loss = 2.442806 
iteration = 90 | loss = 2.278473 
iteration = 95 | loss = 2.467713 
iteration = 100 | loss = 2.366650 
iteration = 105 | loss = 1.839288 
 Epoch: [60] Loss: 3.0303  R1_I2A: 0.5957 R1_A2I: 0.4877 
                 
 Epoch: [60] Loss: 3.0303  R1_I2A: 0.5966 mAP_I2A: 0.5349  R1_A2I: 0.4877 mAP_A2I: 0.4253 
                     
iteration = 0 | loss = 2.193133 
iteration = 5 | loss = 2.168742 
iteration = 10 | loss = 2.878996 
iteration = 15 | loss = 2.329084 
iteration = 20 | loss = 2.170716 
iteration = 25 | loss = 2.321590 
iteration = 30 | loss = 2.137104 
iteration = 35 | loss = 2.234399 
iteration = 40 | loss = 2.987644 
iteration = 45 | loss = 1.844274 
iteration = 50 | loss = 1.974149 
iteration = 55 | loss = 2.377213 
iteration = 60 | loss = 2.769320 
iteration = 65 | loss = 2.188441 
iteration = 70 | loss = 2.672547 
iteration = 75 | loss = 2.188736 
iteration = 80 | loss = 2.667822 
iteration = 85 | loss = 2.672649 
iteration = 90 | loss = 2.454868 
iteration = 95 | loss = 2.206212 
iteration = 100 | loss = 2.105317 
iteration = 105 | loss = 2.227452 
iteration = 0 | loss = 2.422961 
iteration = 5 | loss = 2.470559 
iteration = 10 | loss = 2.156785 
iteration = 15 | loss = 2.400815 
iteration = 20 | loss = 2.634526 
iteration = 25 | loss = 2.747070 
iteration = 30 | loss = 2.444236 
iteration = 35 | loss = 2.054959 
iteration = 40 | loss = 2.269241 
iteration = 45 | loss = 2.473143 
iteration = 50 | loss = 2.165685 
iteration = 55 | loss = 2.249371 
iteration = 60 | loss = 2.048553 
iteration = 65 | loss = 1.890780 
iteration = 70 | loss = 2.044158 
iteration = 75 | loss = 2.204071 
iteration = 80 | loss = 2.326175 
iteration = 85 | loss = 1.961323 
iteration = 90 | loss = 1.996196 
iteration = 95 | loss = 2.196657 
iteration = 100 | loss = 2.308560 
iteration = 105 | loss = 2.895090 
iteration = 0 | loss = 2.040154 
iteration = 5 | loss = 2.373900 
iteration = 10 | loss = 2.235663 
iteration = 15 | loss = 2.245986 
iteration = 20 | loss = 1.982119 
iteration = 25 | loss = 2.279691 
iteration = 30 | loss = 2.714765 
iteration = 35 | loss = 2.378443 
iteration = 40 | loss = 2.009593 
iteration = 45 | loss = 2.159161 
iteration = 50 | loss = 2.329031 
iteration = 55 | loss = 1.886558 
iteration = 60 | loss = 2.310421 
iteration = 65 | loss = 2.288981 
iteration = 70 | loss = 2.016148 
iteration = 75 | loss = 2.451680 
iteration = 80 | loss = 1.699800 
iteration = 85 | loss = 2.486841 
iteration = 90 | loss = 2.387528 
iteration = 95 | loss = 2.567023 
iteration = 100 | loss = 2.298373 
iteration = 105 | loss = 2.451023 
iteration = 0 | loss = 2.282094 
iteration = 5 | loss = 2.210105 
iteration = 10 | loss = 2.029249 
iteration = 15 | loss = 2.391885 
iteration = 20 | loss = 2.075275 
iteration = 25 | loss = 2.095138 
iteration = 30 | loss = 2.489421 
iteration = 35 | loss = 1.927446 
iteration = 40 | loss = 2.698218 
iteration = 45 | loss = 1.936133 
iteration = 50 | loss = 2.007841 
iteration = 55 | loss = 2.370247 
iteration = 60 | loss = 2.075521 
iteration = 65 | loss = 2.353179 
iteration = 70 | loss = 2.382352 
iteration = 75 | loss = 2.290182 
iteration = 80 | loss = 2.684235 
iteration = 85 | loss = 2.244679 
iteration = 90 | loss = 2.139093 
iteration = 95 | loss = 2.180562 
iteration = 100 | loss = 2.623178 
iteration = 105 | loss = 2.158595 
iteration = 0 | loss = 2.053185 
iteration = 5 | loss = 2.428638 
iteration = 10 | loss = 2.615824 
iteration = 15 | loss = 1.994333 
iteration = 20 | loss = 2.281740 
iteration = 25 | loss = 1.521705 
iteration = 30 | loss = 2.458947 
iteration = 35 | loss = 1.870046 
iteration = 40 | loss = 1.814080 
iteration = 45 | loss = 1.879854 
iteration = 50 | loss = 2.142851 
iteration = 55 | loss = 2.049066 
iteration = 60 | loss = 2.283128 
iteration = 65 | loss = 2.142216 
iteration = 70 | loss = 2.049434 
iteration = 75 | loss = 1.909271 
iteration = 80 | loss = 1.907532 
iteration = 85 | loss = 1.698452 
iteration = 90 | loss = 1.797227 
iteration = 95 | loss = 2.141622 
iteration = 100 | loss = 2.192867 
iteration = 105 | loss = 2.426995 
 Epoch: [65] Loss: 1.9809  R1_I2A: 0.6026 R1_A2I: 0.4739 
                 
iteration = 0 | loss = 2.283707 
iteration = 5 | loss = 2.217392 
iteration = 10 | loss = 2.342685 
iteration = 15 | loss = 2.125437 
iteration = 20 | loss = 2.224236 
iteration = 25 | loss = 1.989911 
iteration = 30 | loss = 2.046311 
iteration = 35 | loss = 2.417065 
iteration = 40 | loss = 2.223910 
iteration = 45 | loss = 2.199294 
iteration = 50 | loss = 1.655200 
iteration = 55 | loss = 2.690844 
iteration = 60 | loss = 1.890748 
iteration = 65 | loss = 2.350008 
iteration = 70 | loss = 1.863243 
iteration = 75 | loss = 2.350534 
iteration = 80 | loss = 2.087311 
iteration = 85 | loss = 1.845506 
iteration = 90 | loss = 2.272170 
iteration = 95 | loss = 2.362695 
iteration = 100 | loss = 1.945104 
iteration = 105 | loss = 2.157299 
iteration = 0 | loss = 2.176478 
iteration = 5 | loss = 2.399211 
iteration = 10 | loss = 1.804870 
iteration = 15 | loss = 2.516918 
iteration = 20 | loss = 2.007571 
iteration = 25 | loss = 1.941893 
iteration = 30 | loss = 2.305370 
iteration = 35 | loss = 2.149009 
iteration = 40 | loss = 2.290338 
iteration = 45 | loss = 2.141537 
iteration = 50 | loss = 2.227258 
iteration = 55 | loss = 2.585560 
iteration = 60 | loss = 2.501946 
iteration = 65 | loss = 1.954694 
iteration = 70 | loss = 1.976854 
iteration = 75 | loss = 2.395828 
iteration = 80 | loss = 1.826915 
iteration = 85 | loss = 2.501805 
iteration = 90 | loss = 2.144829 
iteration = 95 | loss = 2.164770 
iteration = 100 | loss = 2.291275 
iteration = 105 | loss = 2.270725 
iteration = 0 | loss = 1.914531 
iteration = 5 | loss = 1.651932 
iteration = 10 | loss = 1.471927 
iteration = 15 | loss = 2.213368 
iteration = 20 | loss = 2.355239 
iteration = 25 | loss = 2.242375 
iteration = 30 | loss = 1.874761 
iteration = 35 | loss = 1.817057 
iteration = 40 | loss = 2.091138 
iteration = 45 | loss = 2.614575 
iteration = 50 | loss = 2.132701 
iteration = 55 | loss = 2.278049 
iteration = 60 | loss = 2.196067 
iteration = 65 | loss = 2.124366 
iteration = 70 | loss = 2.594843 
iteration = 75 | loss = 2.459264 
iteration = 80 | loss = 1.940873 
iteration = 85 | loss = 2.162038 
iteration = 90 | loss = 2.200655 
iteration = 95 | loss = 2.409652 
iteration = 100 | loss = 1.557864 
iteration = 105 | loss = 1.949581 
iteration = 0 | loss = 2.030399 
iteration = 5 | loss = 1.911564 
iteration = 10 | loss = 2.303173 
iteration = 15 | loss = 2.349334 
iteration = 20 | loss = 2.263150 
iteration = 25 | loss = 2.035936 
iteration = 30 | loss = 2.118414 
iteration = 35 | loss = 2.209942 
iteration = 40 | loss = 1.506161 
iteration = 45 | loss = 2.425508 
iteration = 50 | loss = 1.917841 
iteration = 55 | loss = 2.489970 
iteration = 60 | loss = 2.122823 
iteration = 65 | loss = 2.180571 
iteration = 70 | loss = 2.210879 
iteration = 75 | loss = 2.278208 
iteration = 80 | loss = 1.956973 
iteration = 85 | loss = 2.336403 
iteration = 90 | loss = 2.532469 
iteration = 95 | loss = 1.935889 
iteration = 100 | loss = 2.271445 
iteration = 105 | loss = 1.764954 
iteration = 0 | loss = 1.689464 
iteration = 5 | loss = 1.902230 
iteration = 10 | loss = 1.510452 
iteration = 15 | loss = 1.913486 
iteration = 20 | loss = 1.674151 
iteration = 25 | loss = 2.151251 
iteration = 30 | loss = 2.315186 
iteration = 35 | loss = 2.057952 
iteration = 40 | loss = 1.968867 
iteration = 45 | loss = 1.955369 
iteration = 50 | loss = 1.697227 
iteration = 55 | loss = 2.455019 
iteration = 60 | loss = 1.805060 
iteration = 65 | loss = 1.706714 
iteration = 70 | loss = 2.317118 
iteration = 75 | loss = 2.236501 
iteration = 80 | loss = 2.281831 
iteration = 85 | loss = 2.303663 
iteration = 90 | loss = 2.303089 
iteration = 95 | loss = 1.996834 
iteration = 100 | loss = 2.696849 
iteration = 105 | loss = 1.938131 
 Epoch: [70] Loss: 2.5419  R1_I2A: 0.5983 R1_A2I: 0.4882 
                 
 Epoch: [70] Loss: 2.5419  R1_I2A: 0.5951 mAP_I2A: 0.5224  R1_A2I: 0.4882 mAP_A2I: 0.4256 
                     
iteration = 0 | loss = 1.880756 
iteration = 5 | loss = 1.875062 
iteration = 10 | loss = 1.825423 
iteration = 15 | loss = 2.561112 
iteration = 20 | loss = 1.843595 
iteration = 25 | loss = 2.196198 
iteration = 30 | loss = 2.118254 
iteration = 35 | loss = 2.536862 
iteration = 40 | loss = 2.334212 
iteration = 45 | loss = 2.239176 
iteration = 50 | loss = 2.076826 
iteration = 55 | loss = 1.830982 
iteration = 60 | loss = 1.789265 
iteration = 65 | loss = 1.871453 
iteration = 70 | loss = 1.682612 
iteration = 75 | loss = 2.140548 
iteration = 80 | loss = 2.196156 
iteration = 85 | loss = 1.867612 
iteration = 90 | loss = 2.166023 
iteration = 95 | loss = 2.065947 
iteration = 100 | loss = 1.848023 
iteration = 105 | loss = 1.854268 
iteration = 0 | loss = 2.296396 
iteration = 5 | loss = 2.173750 
iteration = 10 | loss = 1.790243 
iteration = 15 | loss = 2.194190 
iteration = 20 | loss = 2.139832 
iteration = 25 | loss = 2.054450 
iteration = 30 | loss = 2.505633 
iteration = 35 | loss = 2.334704 
iteration = 40 | loss = 1.997233 
iteration = 45 | loss = 2.133912 
iteration = 50 | loss = 2.136833 
iteration = 55 | loss = 1.863487 
iteration = 60 | loss = 1.723210 
iteration = 65 | loss = 2.244444 
iteration = 70 | loss = 2.287219 
iteration = 75 | loss = 2.522712 
iteration = 80 | loss = 2.302467 
iteration = 85 | loss = 2.243402 
iteration = 90 | loss = 1.861302 
iteration = 95 | loss = 2.285482 
iteration = 100 | loss = 1.990728 
iteration = 105 | loss = 2.176642 
iteration = 0 | loss = 1.957163 
iteration = 5 | loss = 1.790977 
iteration = 10 | loss = 1.865847 
iteration = 15 | loss = 2.038222 
iteration = 20 | loss = 2.243204 
iteration = 25 | loss = 2.339484 
iteration = 30 | loss = 1.767707 
iteration = 35 | loss = 1.897911 
iteration = 40 | loss = 2.057899 
iteration = 45 | loss = 1.884029 
iteration = 50 | loss = 1.834992 
iteration = 55 | loss = 2.270666 
iteration = 60 | loss = 2.282481 
iteration = 65 | loss = 2.086278 
iteration = 70 | loss = 2.053737 
iteration = 75 | loss = 2.116405 
iteration = 80 | loss = 2.009305 
iteration = 85 | loss = 2.216615 
iteration = 90 | loss = 2.314800 
iteration = 95 | loss = 1.747694 
iteration = 100 | loss = 2.268463 
iteration = 105 | loss = 1.868334 
iteration = 0 | loss = 2.068249 
iteration = 5 | loss = 2.196807 
iteration = 10 | loss = 2.136578 
iteration = 15 | loss = 1.900535 
iteration = 20 | loss = 1.804216 
iteration = 25 | loss = 1.952281 
iteration = 30 | loss = 1.650753 
iteration = 35 | loss = 1.704947 
iteration = 40 | loss = 1.701342 
iteration = 45 | loss = 1.794004 
iteration = 50 | loss = 1.909439 
iteration = 55 | loss = 2.014688 
iteration = 60 | loss = 2.309629 
iteration = 65 | loss = 2.113640 
iteration = 70 | loss = 1.944155 
iteration = 75 | loss = 1.897241 
iteration = 80 | loss = 1.809436 
iteration = 85 | loss = 1.500128 
iteration = 90 | loss = 2.138407 
iteration = 95 | loss = 1.806831 
iteration = 100 | loss = 1.919272 
iteration = 105 | loss = 2.542092 
iteration = 0 | loss = 1.944328 
iteration = 5 | loss = 1.876492 
iteration = 10 | loss = 2.054460 
iteration = 15 | loss = 1.854680 
iteration = 20 | loss = 1.972854 
iteration = 25 | loss = 1.856816 
iteration = 30 | loss = 1.739517 
iteration = 35 | loss = 2.322730 
iteration = 40 | loss = 1.882116 
iteration = 45 | loss = 2.261202 
iteration = 50 | loss = 1.787082 
iteration = 55 | loss = 1.874948 
iteration = 60 | loss = 2.139730 
iteration = 65 | loss = 2.003717 
iteration = 70 | loss = 2.177088 
iteration = 75 | loss = 1.783850 
iteration = 80 | loss = 2.086498 
iteration = 85 | loss = 2.000371 
iteration = 90 | loss = 2.028120 
iteration = 95 | loss = 1.997638 
iteration = 100 | loss = 1.445380 
iteration = 105 | loss = 2.022404 
 Epoch: [75] Loss: 2.2727  R1_I2A: 0.5749 R1_A2I: 0.4730 
                 
iteration = 0 | loss = 1.911108 
iteration = 5 | loss = 1.968981 
iteration = 10 | loss = 1.979093 
iteration = 15 | loss = 2.459737 
iteration = 20 | loss = 1.969313 
iteration = 25 | loss = 2.182785 
iteration = 30 | loss = 2.270107 
iteration = 35 | loss = 1.746314 
iteration = 40 | loss = 2.407194 
iteration = 45 | loss = 1.813627 
iteration = 50 | loss = 1.617289 
iteration = 55 | loss = 1.762324 
iteration = 60 | loss = 2.250044 
iteration = 65 | loss = 1.936908 
iteration = 70 | loss = 2.142690 
iteration = 75 | loss = 1.692930 
iteration = 80 | loss = 2.390659 
iteration = 85 | loss = 2.138633 
iteration = 90 | loss = 1.988842 
iteration = 95 | loss = 1.872537 
iteration = 100 | loss = 2.178983 
iteration = 105 | loss = 1.716754 
iteration = 0 | loss = 2.236307 
iteration = 5 | loss = 1.763257 
iteration = 10 | loss = 1.695754 
iteration = 15 | loss = 1.874888 
iteration = 20 | loss = 2.201771 
iteration = 25 | loss = 1.782301 
iteration = 30 | loss = 1.846640 
iteration = 35 | loss = 2.132745 
iteration = 40 | loss = 1.381924 
iteration = 45 | loss = 1.959207 
iteration = 50 | loss = 2.093678 
iteration = 55 | loss = 1.626316 
iteration = 60 | loss = 2.124317 
iteration = 65 | loss = 1.803433 
iteration = 70 | loss = 2.229502 
iteration = 75 | loss = 1.956987 
iteration = 80 | loss = 1.872396 
iteration = 85 | loss = 1.834635 
iteration = 90 | loss = 2.141986 
iteration = 95 | loss = 1.920067 
iteration = 100 | loss = 1.938081 
iteration = 105 | loss = 2.346811 
iteration = 0 | loss = 1.760105 
iteration = 5 | loss = 2.159256 
iteration = 10 | loss = 1.981461 
iteration = 15 | loss = 1.576327 
iteration = 20 | loss = 2.017094 
iteration = 25 | loss = 1.910557 
iteration = 30 | loss = 2.727165 
iteration = 35 | loss = 1.831229 
iteration = 40 | loss = 1.330134 
iteration = 45 | loss = 1.977210 
iteration = 50 | loss = 1.655255 
iteration = 55 | loss = 1.894377 
iteration = 60 | loss = 1.694809 
iteration = 65 | loss = 2.065513 
iteration = 70 | loss = 2.044441 
iteration = 75 | loss = 1.764189 
iteration = 80 | loss = 1.803937 
iteration = 85 | loss = 2.034468 
iteration = 90 | loss = 1.771645 
iteration = 95 | loss = 1.944720 
iteration = 100 | loss = 1.868440 
iteration = 105 | loss = 1.774324 
iteration = 0 | loss = 1.961937 
iteration = 5 | loss = 1.941473 
iteration = 10 | loss = 2.058448 
iteration = 15 | loss = 2.108447 
iteration = 20 | loss = 1.920810 
iteration = 25 | loss = 1.814839 
iteration = 30 | loss = 1.989003 
iteration = 35 | loss = 1.932500 
iteration = 40 | loss = 1.751137 
iteration = 45 | loss = 2.008614 
iteration = 50 | loss = 1.813082 
iteration = 55 | loss = 1.825050 
iteration = 60 | loss = 1.670533 
iteration = 65 | loss = 2.213817 
iteration = 70 | loss = 1.451017 
iteration = 75 | loss = 1.720309 
iteration = 80 | loss = 1.907992 
iteration = 85 | loss = 2.404316 
iteration = 90 | loss = 1.964578 
iteration = 95 | loss = 1.967626 
iteration = 100 | loss = 1.892152 
iteration = 105 | loss = 2.142739 
iteration = 0 | loss = 1.757020 
iteration = 5 | loss = 1.863998 
iteration = 10 | loss = 1.683769 
iteration = 15 | loss = 1.966866 
iteration = 20 | loss = 2.207480 
iteration = 25 | loss = 1.438819 
iteration = 30 | loss = 2.031583 
iteration = 35 | loss = 1.645256 
iteration = 40 | loss = 2.236774 
iteration = 45 | loss = 1.854803 
iteration = 50 | loss = 2.368510 
iteration = 55 | loss = 1.963968 
iteration = 60 | loss = 2.236331 
iteration = 65 | loss = 2.116715 
iteration = 70 | loss = 1.911316 
iteration = 75 | loss = 2.579618 
iteration = 80 | loss = 1.578665 
iteration = 85 | loss = 1.951876 
iteration = 90 | loss = 2.156230 
iteration = 95 | loss = 2.404019 
iteration = 100 | loss = 2.121176 
iteration = 105 | loss = 2.013661 
 Epoch: [80] Loss: 1.8867  R1_I2A: 0.5974 R1_A2I: 0.4713 
                 
iteration = 0 | loss = 1.495249 
iteration = 5 | loss = 1.718352 
iteration = 10 | loss = 1.912207 
iteration = 15 | loss = 1.921558 
iteration = 20 | loss = 1.776547 
iteration = 25 | loss = 2.442208 
iteration = 30 | loss = 2.169886 
iteration = 35 | loss = 1.926438 
iteration = 40 | loss = 2.213623 
iteration = 45 | loss = 2.214408 
iteration = 50 | loss = 1.870292 
iteration = 55 | loss = 1.721201 
iteration = 60 | loss = 1.805970 
iteration = 65 | loss = 2.024547 
iteration = 70 | loss = 1.560232 
iteration = 75 | loss = 1.939564 
iteration = 80 | loss = 1.486274 
iteration = 85 | loss = 2.333746 
iteration = 90 | loss = 1.573452 
iteration = 95 | loss = 1.775382 
iteration = 100 | loss = 2.139599 
iteration = 105 | loss = 1.869217 

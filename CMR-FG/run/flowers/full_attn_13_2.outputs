64 13.0
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 2.577555 
iteration = 5 | loss = 3.461007 
iteration = 10 | loss = 2.387801 
iteration = 15 | loss = 2.894471 
iteration = 20 | loss = 2.663276 
iteration = 25 | loss = 2.954871 
iteration = 30 | loss = 2.502111 
iteration = 35 | loss = 3.454593 
iteration = 40 | loss = 2.409328 
iteration = 45 | loss = 2.768635 
iteration = 50 | loss = 2.423034 
iteration = 55 | loss = 3.035327 
iteration = 60 | loss = 2.697370 
iteration = 65 | loss = 2.417014 
iteration = 70 | loss = 3.121272 
iteration = 75 | loss = 2.206623 
iteration = 80 | loss = 2.838520 
iteration = 85 | loss = 2.450655 
iteration = 90 | loss = 2.214017 
iteration = 95 | loss = 2.593931 
iteration = 100 | loss = 2.546969 
iteration = 105 | loss = 2.128666 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 2.220803 
iteration = 5 | loss = 2.374787 
iteration = 10 | loss = 2.469104 
iteration = 15 | loss = 2.456539 
iteration = 20 | loss = 2.538828 
iteration = 25 | loss = 2.980129 
iteration = 30 | loss = 2.424315 
iteration = 35 | loss = 2.795731 
iteration = 40 | loss = 2.518020 
iteration = 45 | loss = 2.495065 
iteration = 50 | loss = 2.252239 
iteration = 55 | loss = 2.271485 
iteration = 60 | loss = 2.403335 
iteration = 65 | loss = 2.688953 
iteration = 70 | loss = 2.297099 
iteration = 75 | loss = 2.932437 
iteration = 80 | loss = 2.822462 
iteration = 85 | loss = 2.320415 
iteration = 90 | loss = 2.627090 
iteration = 95 | loss = 2.363249 
iteration = 100 | loss = 3.024389 
iteration = 105 | loss = 2.876488 
iteration = 0 | loss = 2.448958 
iteration = 5 | loss = 2.332111 
iteration = 10 | loss = 2.146915 
iteration = 15 | loss = 3.132993 
iteration = 20 | loss = 2.362418 
iteration = 25 | loss = 2.300158 
iteration = 30 | loss = 2.390497 
iteration = 35 | loss = 2.143892 
iteration = 40 | loss = 3.224041 
iteration = 45 | loss = 2.858068 
iteration = 50 | loss = 2.443153 
iteration = 55 | loss = 2.461007 
iteration = 60 | loss = 2.383419 
iteration = 65 | loss = 2.071153 
iteration = 70 | loss = 2.577850 
iteration = 75 | loss = 2.372113 
iteration = 80 | loss = 2.694363 
iteration = 85 | loss = 2.956846 
iteration = 90 | loss = 2.330369 
iteration = 95 | loss = 2.534931 
iteration = 100 | loss = 2.867332 
iteration = 105 | loss = 2.525259 
iteration = 0 | loss = 1.826428 
iteration = 5 | loss = 2.512072 
iteration = 10 | loss = 2.591959 
iteration = 15 | loss = 2.280910 
iteration = 20 | loss = 2.483741 
iteration = 25 | loss = 1.935897 
iteration = 30 | loss = 2.133599 
iteration = 35 | loss = 2.052279 
iteration = 40 | loss = 2.335605 
iteration = 45 | loss = 2.754785 
iteration = 50 | loss = 2.448426 
iteration = 55 | loss = 2.420751 
iteration = 60 | loss = 2.949051 
iteration = 65 | loss = 2.533641 
iteration = 70 | loss = 2.530437 
iteration = 75 | loss = 2.464972 
iteration = 80 | loss = 2.838337 
iteration = 85 | loss = 2.299433 
iteration = 90 | loss = 2.782133 
iteration = 95 | loss = 2.923933 
iteration = 100 | loss = 2.676590 
iteration = 105 | loss = 2.647879 
iteration = 0 | loss = 2.570415 
iteration = 5 | loss = 2.423742 
iteration = 10 | loss = 2.052066 
iteration = 15 | loss = 2.510597 
iteration = 20 | loss = 2.958469 
iteration = 25 | loss = 2.319592 
iteration = 30 | loss = 2.610495 
iteration = 35 | loss = 2.259706 
iteration = 40 | loss = 2.821775 
iteration = 45 | loss = 2.688405 
iteration = 50 | loss = 2.614393 
iteration = 55 | loss = 2.404945 
iteration = 60 | loss = 2.544740 
iteration = 65 | loss = 2.174522 
iteration = 70 | loss = 2.319115 
iteration = 75 | loss = 2.497523 
iteration = 80 | loss = 2.642764 
iteration = 85 | loss = 2.585952 
iteration = 90 | loss = 2.414285 
iteration = 95 | loss = 1.991773 
iteration = 100 | loss = 2.265943 
iteration = 105 | loss = 2.149820 
 Epoch: [45] Loss: 2.3212  R1_I2A: 0.5905 R1_A2I: 0.4700 
                 
 Epoch: [45] Loss: 2.3212  R1_I2A: 0.5897 mAP_I2A: 0.5141  R1_A2I: 0.4700 mAP_A2I: 0.4148 
                     
iteration = 0 | loss = 2.287212 
iteration = 5 | loss = 2.916745 
iteration = 10 | loss = 2.677493 
iteration = 15 | loss = 1.941496 
iteration = 20 | loss = 2.125190 
iteration = 25 | loss = 2.550775 
iteration = 30 | loss = 2.610317 
iteration = 35 | loss = 2.544714 
iteration = 40 | loss = 2.165831 
iteration = 45 | loss = 2.872730 
iteration = 50 | loss = 2.298529 
iteration = 55 | loss = 3.011619 
iteration = 60 | loss = 2.525838 
iteration = 65 | loss = 2.015233 
iteration = 70 | loss = 2.298603 
iteration = 75 | loss = 2.994174 
iteration = 80 | loss = 2.384655 
iteration = 85 | loss = 2.771603 
iteration = 90 | loss = 2.528183 
iteration = 95 | loss = 2.522910 
iteration = 100 | loss = 2.384226 
iteration = 105 | loss = 2.839733 
iteration = 0 | loss = 2.328804 
iteration = 5 | loss = 2.237848 
iteration = 10 | loss = 2.117131 
iteration = 15 | loss = 2.136935 
iteration = 20 | loss = 2.373964 
iteration = 25 | loss = 2.128140 
iteration = 30 | loss = 2.900417 
iteration = 35 | loss = 2.263763 
iteration = 40 | loss = 2.116574 
iteration = 45 | loss = 2.657357 
iteration = 50 | loss = 2.207627 
iteration = 55 | loss = 2.582282 
iteration = 60 | loss = 2.238214 
iteration = 65 | loss = 1.959633 
iteration = 70 | loss = 2.721545 
iteration = 75 | loss = 2.451670 
iteration = 80 | loss = 2.148354 
iteration = 85 | loss = 2.163049 
iteration = 90 | loss = 2.057968 
iteration = 95 | loss = 2.831569 
iteration = 100 | loss = 2.622969 
iteration = 105 | loss = 2.692886 
iteration = 0 | loss = 2.258812 
iteration = 5 | loss = 2.067360 
iteration = 10 | loss = 2.678130 
iteration = 15 | loss = 2.373681 
iteration = 20 | loss = 2.688213 
iteration = 25 | loss = 2.346592 
iteration = 30 | loss = 2.232038 
iteration = 35 | loss = 2.448524 
iteration = 40 | loss = 2.114447 
iteration = 45 | loss = 2.766459 
iteration = 50 | loss = 2.232324 
iteration = 55 | loss = 2.091954 
iteration = 60 | loss = 2.318864 
iteration = 65 | loss = 2.656812 
iteration = 70 | loss = 2.401093 
iteration = 75 | loss = 1.857738 
iteration = 80 | loss = 2.361426 
iteration = 85 | loss = 2.865151 
iteration = 90 | loss = 1.909836 
iteration = 95 | loss = 2.228616 
iteration = 100 | loss = 2.411471 
iteration = 105 | loss = 2.445072 
iteration = 0 | loss = 2.026453 
iteration = 5 | loss = 2.343563 
iteration = 10 | loss = 2.326587 
iteration = 15 | loss = 2.507846 
iteration = 20 | loss = 2.375569 
iteration = 25 | loss = 2.183780 
iteration = 30 | loss = 2.411624 
iteration = 35 | loss = 2.518023 
iteration = 40 | loss = 2.639178 
iteration = 45 | loss = 2.134385 
iteration = 50 | loss = 2.397706 
iteration = 55 | loss = 1.939407 
iteration = 60 | loss = 2.067183 
iteration = 65 | loss = 2.523551 
iteration = 70 | loss = 2.179857 
iteration = 75 | loss = 2.208482 
iteration = 80 | loss = 2.343777 
iteration = 85 | loss = 2.260397 
iteration = 90 | loss = 1.926930 
iteration = 95 | loss = 1.991266 
iteration = 100 | loss = 2.702857 
iteration = 105 | loss = 2.735323 
iteration = 0 | loss = 2.394738 
iteration = 5 | loss = 1.991763 
iteration = 10 | loss = 2.390740 
iteration = 15 | loss = 2.584498 
iteration = 20 | loss = 2.422911 
iteration = 25 | loss = 2.219232 
iteration = 30 | loss = 2.147746 
iteration = 35 | loss = 2.173834 
iteration = 40 | loss = 2.340137 
iteration = 45 | loss = 2.565267 
iteration = 50 | loss = 2.056823 
iteration = 55 | loss = 2.288271 
iteration = 60 | loss = 2.067789 
iteration = 65 | loss = 1.876780 
iteration = 70 | loss = 2.332404 
iteration = 75 | loss = 2.289154 
iteration = 80 | loss = 2.331895 
iteration = 85 | loss = 1.970614 
iteration = 90 | loss = 2.295796 
iteration = 95 | loss = 2.485895 
iteration = 100 | loss = 1.753396 
iteration = 105 | loss = 2.178354 
 Epoch: [50] Loss: 2.6069  R1_I2A: 0.5965 R1_A2I: 0.4810 
                 
 Epoch: [50] Loss: 2.6069  R1_I2A: 0.6005 mAP_I2A: 0.5171  R1_A2I: 0.4810 mAP_A2I: 0.4179 
                     
iteration = 0 | loss = 2.473107 
iteration = 5 | loss = 1.918650 
iteration = 10 | loss = 2.138258 
iteration = 15 | loss = 2.152576 
iteration = 20 | loss = 1.995021 
iteration = 25 | loss = 2.698959 
iteration = 30 | loss = 2.257793 
iteration = 35 | loss = 1.814001 
iteration = 40 | loss = 2.015500 
iteration = 45 | loss = 1.936466 
iteration = 50 | loss = 2.487023 
iteration = 55 | loss = 2.528734 
iteration = 60 | loss = 2.396760 
iteration = 65 | loss = 1.877821 
iteration = 70 | loss = 2.039901 
iteration = 75 | loss = 2.504913 
iteration = 80 | loss = 2.253107 
iteration = 85 | loss = 2.087980 
iteration = 90 | loss = 1.907771 
iteration = 95 | loss = 2.074334 
iteration = 100 | loss = 1.876221 
iteration = 105 | loss = 1.628238 
iteration = 0 | loss = 2.226103 
iteration = 5 | loss = 2.107259 
iteration = 10 | loss = 2.493092 
iteration = 15 | loss = 2.169234 
iteration = 20 | loss = 2.058497 
iteration = 25 | loss = 2.279737 
iteration = 30 | loss = 2.067266 
iteration = 35 | loss = 2.589141 
iteration = 40 | loss = 2.277548 
iteration = 45 | loss = 2.550608 
iteration = 50 | loss = 1.931726 
iteration = 55 | loss = 1.682688 
iteration = 60 | loss = 2.127930 
iteration = 65 | loss = 2.032546 
iteration = 70 | loss = 2.901393 
iteration = 75 | loss = 1.843596 
iteration = 80 | loss = 2.498918 
iteration = 85 | loss = 2.164181 
iteration = 90 | loss = 2.131392 
iteration = 95 | loss = 2.338247 
iteration = 100 | loss = 2.365988 
iteration = 105 | loss = 2.143714 
iteration = 0 | loss = 2.208092 
iteration = 5 | loss = 2.330984 
iteration = 10 | loss = 1.876368 
iteration = 15 | loss = 2.006393 
iteration = 20 | loss = 2.014359 
iteration = 25 | loss = 2.552073 
iteration = 30 | loss = 1.973522 
iteration = 35 | loss = 2.581135 
iteration = 40 | loss = 2.293297 
iteration = 45 | loss = 2.174930 
iteration = 50 | loss = 2.166290 
iteration = 55 | loss = 1.873403 
iteration = 60 | loss = 2.868609 
iteration = 65 | loss = 2.270193 
iteration = 70 | loss = 2.987703 
iteration = 75 | loss = 2.130918 
iteration = 80 | loss = 2.193066 
iteration = 85 | loss = 1.565209 
iteration = 90 | loss = 2.513281 
iteration = 95 | loss = 2.586987 
iteration = 100 | loss = 2.345153 
iteration = 105 | loss = 1.667844 
iteration = 0 | loss = 1.670254 
iteration = 5 | loss = 2.173990 
iteration = 10 | loss = 2.407244 
iteration = 15 | loss = 2.540063 
iteration = 20 | loss = 2.033588 
iteration = 25 | loss = 2.046321 
iteration = 30 | loss = 1.895607 
iteration = 35 | loss = 2.330031 
iteration = 40 | loss = 2.223935 
iteration = 45 | loss = 2.331432 
iteration = 50 | loss = 1.850784 
iteration = 55 | loss = 2.039804 
iteration = 60 | loss = 1.893565 
iteration = 65 | loss = 2.034645 
iteration = 70 | loss = 2.114258 
iteration = 75 | loss = 2.315216 
iteration = 80 | loss = 2.045446 
iteration = 85 | loss = 2.350806 
iteration = 90 | loss = 2.230196 
iteration = 95 | loss = 2.732704 
iteration = 100 | loss = 2.336505 
iteration = 105 | loss = 2.024918 
iteration = 0 | loss = 2.643613 
iteration = 5 | loss = 1.978904 
iteration = 10 | loss = 2.250339 
iteration = 15 | loss = 2.081216 
iteration = 20 | loss = 2.220367 
iteration = 25 | loss = 2.548795 
iteration = 30 | loss = 2.023079 
iteration = 35 | loss = 1.739866 
iteration = 40 | loss = 2.609951 
iteration = 45 | loss = 2.344537 
iteration = 50 | loss = 1.888762 
iteration = 55 | loss = 2.240106 
iteration = 60 | loss = 2.319969 
iteration = 65 | loss = 2.022180 
iteration = 70 | loss = 2.457458 
iteration = 75 | loss = 2.097442 
iteration = 80 | loss = 2.331983 
iteration = 85 | loss = 2.504540 
iteration = 90 | loss = 2.660890 
iteration = 95 | loss = 2.385163 
iteration = 100 | loss = 1.794073 
iteration = 105 | loss = 2.012022 
 Epoch: [55] Loss: 2.2356  R1_I2A: 0.5879 R1_A2I: 0.4789 
                 
iteration = 0 | loss = 1.807443 
iteration = 5 | loss = 2.083804 
iteration = 10 | loss = 1.913350 
iteration = 15 | loss = 1.729979 
iteration = 20 | loss = 2.024097 
iteration = 25 | loss = 1.782756 
iteration = 30 | loss = 1.933057 
iteration = 35 | loss = 2.074514 
iteration = 40 | loss = 1.932740 
iteration = 45 | loss = 1.818753 
iteration = 50 | loss = 2.608589 
iteration = 55 | loss = 1.586553 
iteration = 60 | loss = 2.268953 
iteration = 65 | loss = 1.875379 
iteration = 70 | loss = 1.806304 
iteration = 75 | loss = 2.250501 
iteration = 80 | loss = 1.981182 
iteration = 85 | loss = 2.084045 
iteration = 90 | loss = 2.064955 
iteration = 95 | loss = 1.856423 
iteration = 100 | loss = 1.910223 
iteration = 105 | loss = 2.340395 
iteration = 0 | loss = 2.409641 
iteration = 5 | loss = 1.749349 
iteration = 10 | loss = 2.083940 
iteration = 15 | loss = 2.050335 
iteration = 20 | loss = 2.220498 
iteration = 25 | loss = 1.856564 
iteration = 30 | loss = 2.081764 
iteration = 35 | loss = 2.095653 
iteration = 40 | loss = 1.428260 
iteration = 45 | loss = 2.351334 
iteration = 50 | loss = 2.222022 
iteration = 55 | loss = 1.771866 
iteration = 60 | loss = 1.878543 
iteration = 65 | loss = 1.940013 
iteration = 70 | loss = 2.141329 
iteration = 75 | loss = 2.311134 
iteration = 80 | loss = 2.190835 
iteration = 85 | loss = 1.975764 
iteration = 90 | loss = 2.268298 
iteration = 95 | loss = 1.926020 
iteration = 100 | loss = 1.943056 
iteration = 105 | loss = 1.834985 
iteration = 0 | loss = 1.702513 
iteration = 5 | loss = 1.986252 
iteration = 10 | loss = 2.183455 
iteration = 15 | loss = 1.977006 
iteration = 20 | loss = 2.545197 
iteration = 25 | loss = 1.954583 
iteration = 30 | loss = 2.242154 
iteration = 35 | loss = 2.061086 
iteration = 40 | loss = 2.082785 
iteration = 45 | loss = 2.232423 
iteration = 50 | loss = 2.080078 
iteration = 55 | loss = 2.217432 
iteration = 60 | loss = 2.819271 
iteration = 65 | loss = 1.773425 
iteration = 70 | loss = 2.092138 
iteration = 75 | loss = 2.300524 
iteration = 80 | loss = 2.188978 
iteration = 85 | loss = 2.069659 
iteration = 90 | loss = 2.103976 
iteration = 95 | loss = 2.243185 
iteration = 100 | loss = 2.310315 
iteration = 105 | loss = 2.502807 
iteration = 0 | loss = 2.388755 
iteration = 5 | loss = 2.484968 
iteration = 10 | loss = 2.348028 
iteration = 15 | loss = 2.156442 
iteration = 20 | loss = 2.164200 
iteration = 25 | loss = 2.284336 
iteration = 30 | loss = 2.078505 
iteration = 35 | loss = 2.289902 
iteration = 40 | loss = 1.670004 
iteration = 45 | loss = 1.581961 
iteration = 50 | loss = 1.475519 
iteration = 55 | loss = 1.833574 
iteration = 60 | loss = 2.169802 
iteration = 65 | loss = 2.475385 
iteration = 70 | loss = 1.652910 
iteration = 75 | loss = 1.772416 
iteration = 80 | loss = 2.246817 
iteration = 85 | loss = 1.784098 
iteration = 90 | loss = 2.375377 
iteration = 95 | loss = 1.741979 
iteration = 100 | loss = 1.883275 
iteration = 105 | loss = 1.889138 
iteration = 0 | loss = 1.733614 
iteration = 5 | loss = 1.843500 
iteration = 10 | loss = 2.160405 
iteration = 15 | loss = 2.341786 
iteration = 20 | loss = 1.868069 
iteration = 25 | loss = 1.586440 
iteration = 30 | loss = 2.019862 
iteration = 35 | loss = 2.158278 
iteration = 40 | loss = 1.908416 
iteration = 45 | loss = 1.534088 
iteration = 50 | loss = 1.776004 
iteration = 55 | loss = 2.384189 
iteration = 60 | loss = 2.182634 
iteration = 65 | loss = 2.367237 
iteration = 70 | loss = 2.084661 
iteration = 75 | loss = 1.923902 
iteration = 80 | loss = 1.949615 
iteration = 85 | loss = 2.229374 
iteration = 90 | loss = 1.704203 
iteration = 95 | loss = 1.976809 
iteration = 100 | loss = 1.870857 
iteration = 105 | loss = 2.195921 
 Epoch: [60] Loss: 1.5061  R1_I2A: 0.5784 R1_A2I: 0.4823 
                 
iteration = 0 | loss = 2.355443 
iteration = 5 | loss = 1.579385 
iteration = 10 | loss = 1.964952 
iteration = 15 | loss = 2.312079 
iteration = 20 | loss = 2.047691 
iteration = 25 | loss = 1.709616 
iteration = 30 | loss = 2.046719 
iteration = 35 | loss = 1.979970 
iteration = 40 | loss = 1.447355 
iteration = 45 | loss = 1.961898 
iteration = 50 | loss = 2.123853 
iteration = 55 | loss = 2.319585 
iteration = 60 | loss = 1.309916 
iteration = 65 | loss = 2.199076 
iteration = 70 | loss = 2.248289 
iteration = 75 | loss = 1.919984 
iteration = 80 | loss = 1.677531 
iteration = 85 | loss = 1.966275 
iteration = 90 | loss = 1.888104 
iteration = 95 | loss = 2.481194 
iteration = 100 | loss = 1.568244 
iteration = 105 | loss = 1.972814 
iteration = 0 | loss = 1.416501 
iteration = 5 | loss = 1.310882 
iteration = 10 | loss = 1.800566 
iteration = 15 | loss = 1.874829 
iteration = 20 | loss = 2.305545 
iteration = 25 | loss = 1.885708 
iteration = 30 | loss = 1.904051 
iteration = 35 | loss = 2.059730 
iteration = 40 | loss = 1.871497 
iteration = 45 | loss = 1.601773 
iteration = 50 | loss = 2.266160 
iteration = 55 | loss = 1.632971 
iteration = 60 | loss = 1.849424 
iteration = 65 | loss = 2.416944 
iteration = 70 | loss = 1.987723 
iteration = 75 | loss = 1.876709 
iteration = 80 | loss = 2.013903 
iteration = 85 | loss = 1.821535 
iteration = 90 | loss = 1.977414 
iteration = 95 | loss = 2.020575 
iteration = 100 | loss = 1.625599 
iteration = 105 | loss = 2.194981 
iteration = 0 | loss = 2.330362 
iteration = 5 | loss = 1.671316 
iteration = 10 | loss = 1.781734 
iteration = 15 | loss = 2.220369 
iteration = 20 | loss = 1.850058 
iteration = 25 | loss = 2.308646 
iteration = 30 | loss = 2.146056 
iteration = 35 | loss = 2.021450 
iteration = 40 | loss = 1.675642 
iteration = 45 | loss = 2.053973 
iteration = 50 | loss = 2.206711 
iteration = 55 | loss = 2.138464 
iteration = 60 | loss = 1.879260 
iteration = 65 | loss = 1.558311 
iteration = 70 | loss = 1.747659 
iteration = 75 | loss = 2.152411 
iteration = 80 | loss = 2.009154 
iteration = 85 | loss = 2.191497 
iteration = 90 | loss = 1.644508 
iteration = 95 | loss = 1.814487 
iteration = 100 | loss = 1.785121 
iteration = 105 | loss = 1.343374 
iteration = 0 | loss = 1.523865 
iteration = 5 | loss = 2.106427 
iteration = 10 | loss = 2.141497 
iteration = 15 | loss = 2.154449 
iteration = 20 | loss = 1.949187 
iteration = 25 | loss = 1.903117 
iteration = 30 | loss = 1.955179 
iteration = 35 | loss = 2.026603 
iteration = 40 | loss = 1.781475 
iteration = 45 | loss = 1.976635 
iteration = 50 | loss = 1.720970 
iteration = 55 | loss = 1.665150 
iteration = 60 | loss = 1.717242 
iteration = 65 | loss = 1.545239 
iteration = 70 | loss = 2.042840 
iteration = 75 | loss = 1.839128 
iteration = 80 | loss = 1.799195 
iteration = 85 | loss = 2.109208 
iteration = 90 | loss = 1.660933 
iteration = 95 | loss = 2.348198 
iteration = 100 | loss = 2.070488 
iteration = 105 | loss = 2.288446 
iteration = 0 | loss = 1.851663 
iteration = 5 | loss = 1.728553 
iteration = 10 | loss = 2.293540 
iteration = 15 | loss = 1.814161 
iteration = 20 | loss = 1.852022 
iteration = 25 | loss = 1.918418 
iteration = 30 | loss = 2.101829 
iteration = 35 | loss = 1.478314 
iteration = 40 | loss = 1.781227 
iteration = 45 | loss = 1.633841 
iteration = 50 | loss = 2.033810 
iteration = 55 | loss = 2.604116 
iteration = 60 | loss = 1.946804 
iteration = 65 | loss = 1.454465 
iteration = 70 | loss = 2.020315 
iteration = 75 | loss = 1.823971 
iteration = 80 | loss = 1.838777 
iteration = 85 | loss = 1.770505 
iteration = 90 | loss = 1.714475 
iteration = 95 | loss = 2.066631 
iteration = 100 | loss = 1.715551 
iteration = 105 | loss = 1.907948 
 Epoch: [65] Loss: 1.8118  R1_I2A: 0.5913 R1_A2I: 0.4817 
                 
iteration = 0 | loss = 1.724966 
iteration = 5 | loss = 1.972195 
iteration = 10 | loss = 1.829471 
iteration = 15 | loss = 2.021270 
iteration = 20 | loss = 1.602037 
iteration = 25 | loss = 1.762949 
iteration = 30 | loss = 1.611803 
iteration = 35 | loss = 1.552211 
iteration = 40 | loss = 2.230830 
iteration = 45 | loss = 2.117688 
iteration = 50 | loss = 1.673441 
iteration = 55 | loss = 2.040798 
iteration = 60 | loss = 1.589514 
iteration = 65 | loss = 2.030780 
iteration = 70 | loss = 2.051268 
iteration = 75 | loss = 1.864204 
iteration = 80 | loss = 1.453401 
iteration = 85 | loss = 2.375098 
iteration = 90 | loss = 1.610521 
iteration = 95 | loss = 2.090796 
iteration = 100 | loss = 2.371722 
iteration = 105 | loss = 2.001829 
iteration = 0 | loss = 2.224497 
iteration = 5 | loss = 1.770274 
iteration = 10 | loss = 1.966584 
iteration = 15 | loss = 1.579809 
iteration = 20 | loss = 1.748241 
iteration = 25 | loss = 1.800702 
iteration = 30 | loss = 1.914674 
iteration = 35 | loss = 1.959512 
iteration = 40 | loss = 1.756138 
iteration = 45 | loss = 1.985029 
iteration = 50 | loss = 1.538231 
iteration = 55 | loss = 1.939680 
iteration = 60 | loss = 2.003924 
iteration = 65 | loss = 1.936089 
iteration = 70 | loss = 1.831815 
iteration = 75 | loss = 1.760309 
iteration = 80 | loss = 1.795137 
iteration = 85 | loss = 1.860026 
iteration = 90 | loss = 2.343391 
iteration = 95 | loss = 1.992529 
iteration = 100 | loss = 2.652516 
iteration = 105 | loss = 1.801520 
iteration = 0 | loss = 1.637045 
iteration = 5 | loss = 1.816497 
iteration = 10 | loss = 2.110098 
iteration = 15 | loss = 1.600197 
iteration = 20 | loss = 2.034566 
iteration = 25 | loss = 1.916216 
iteration = 30 | loss = 1.883774 
iteration = 35 | loss = 1.815414 
iteration = 40 | loss = 1.818401 
iteration = 45 | loss = 1.759038 
iteration = 50 | loss = 1.887091 
iteration = 55 | loss = 1.941216 
iteration = 60 | loss = 2.007851 
iteration = 65 | loss = 1.908450 
iteration = 70 | loss = 1.755382 
iteration = 75 | loss = 1.947678 
iteration = 80 | loss = 2.074763 
iteration = 85 | loss = 2.431345 
iteration = 90 | loss = 2.101274 
iteration = 95 | loss = 1.918302 
iteration = 100 | loss = 1.567052 
iteration = 105 | loss = 1.922982 
iteration = 0 | loss = 1.692436 
iteration = 5 | loss = 1.679555 
iteration = 10 | loss = 1.751801 
iteration = 15 | loss = 2.047996 
iteration = 20 | loss = 1.467516 
iteration = 25 | loss = 1.599017 
iteration = 30 | loss = 1.852164 
iteration = 35 | loss = 1.834941 
iteration = 40 | loss = 1.846241 
iteration = 45 | loss = 1.545639 
iteration = 50 | loss = 1.960687 
iteration = 55 | loss = 1.914688 
iteration = 60 | loss = 1.572952 
iteration = 65 | loss = 2.301030 
iteration = 70 | loss = 1.746000 
iteration = 75 | loss = 2.233309 
iteration = 80 | loss = 1.616672 
iteration = 85 | loss = 1.660739 
iteration = 90 | loss = 1.968640 
iteration = 95 | loss = 1.907755 
iteration = 100 | loss = 1.552051 
iteration = 105 | loss = 2.279690 
iteration = 0 | loss = 2.015658 
iteration = 5 | loss = 1.944556 
iteration = 10 | loss = 2.053198 
iteration = 15 | loss = 1.716748 
iteration = 20 | loss = 2.005282 
iteration = 25 | loss = 1.664389 
iteration = 30 | loss = 1.493056 
iteration = 35 | loss = 1.728680 
iteration = 40 | loss = 2.147891 
iteration = 45 | loss = 2.082050 
iteration = 50 | loss = 1.484276 
iteration = 55 | loss = 1.327519 
iteration = 60 | loss = 1.811484 
iteration = 65 | loss = 1.521575 
iteration = 70 | loss = 1.414501 
iteration = 75 | loss = 1.941646 
iteration = 80 | loss = 1.936111 
iteration = 85 | loss = 2.079399 
iteration = 90 | loss = 1.962087 
iteration = 95 | loss = 1.700892 
iteration = 100 | loss = 1.873169 
iteration = 105 | loss = 1.778208 
 Epoch: [70] Loss: 2.2547  R1_I2A: 0.5879 R1_A2I: 0.4804 
                 
iteration = 0 | loss = 1.778965 
iteration = 5 | loss = 1.617921 
iteration = 10 | loss = 1.515558 
iteration = 15 | loss = 2.270559 
iteration = 20 | loss = 1.616713 
iteration = 25 | loss = 1.841123 
iteration = 30 | loss = 1.876757 
iteration = 35 | loss = 2.228242 
iteration = 40 | loss = 1.731512 
iteration = 45 | loss = 1.905188 
iteration = 50 | loss = 2.163752 
iteration = 55 | loss = 1.877687 
iteration = 60 | loss = 1.967304 
iteration = 65 | loss = 1.810383 
iteration = 70 | loss = 1.903537 
iteration = 75 | loss = 1.905553 
iteration = 80 | loss = 2.227540 
iteration = 85 | loss = 1.612698 
iteration = 90 | loss = 2.591788 
iteration = 95 | loss = 1.734477 
iteration = 100 | loss = 1.673258 
iteration = 105 | loss = 2.257701 
iteration = 0 | loss = 2.027630 
iteration = 5 | loss = 1.811324 
iteration = 10 | loss = 1.789152 
iteration = 15 | loss = 1.676438 
iteration = 20 | loss = 1.792090 
iteration = 25 | loss = 1.846463 
iteration = 30 | loss = 2.247733 
iteration = 35 | loss = 1.534477 
iteration = 40 | loss = 1.888053 
iteration = 45 | loss = 2.038697 
iteration = 50 | loss = 1.792290 
iteration = 55 | loss = 1.730562 
iteration = 60 | loss = 2.044981 
iteration = 65 | loss = 1.691875 
iteration = 70 | loss = 1.564024 
iteration = 75 | loss = 1.920356 
iteration = 80 | loss = 2.221425 
iteration = 85 | loss = 2.030761 
iteration = 90 | loss = 1.624349 
iteration = 95 | loss = 1.886052 
iteration = 100 | loss = 2.189775 
iteration = 105 | loss = 2.266242 
iteration = 0 | loss = 1.690283 
iteration = 5 | loss = 1.489025 
iteration = 10 | loss = 1.823048 
iteration = 15 | loss = 1.747679 
iteration = 20 | loss = 1.850561 
iteration = 25 | loss = 1.908134 
iteration = 30 | loss = 1.897393 
iteration = 35 | loss = 1.850978 
iteration = 40 | loss = 1.398307 
iteration = 45 | loss = 1.708041 
iteration = 50 | loss = 1.709679 
iteration = 55 | loss = 1.477931 
iteration = 60 | loss = 1.573572 
iteration = 65 | loss = 1.646565 
iteration = 70 | loss = 1.728862 
iteration = 75 | loss = 1.688123 
iteration = 80 | loss = 1.955374 
iteration = 85 | loss = 1.844372 
iteration = 90 | loss = 1.673556 
iteration = 95 | loss = 2.030182 
iteration = 100 | loss = 1.891329 
iteration = 105 | loss = 1.781858 
iteration = 0 | loss = 1.708160 
iteration = 5 | loss = 1.345000 
iteration = 10 | loss = 1.499021 
iteration = 15 | loss = 1.593273 
iteration = 20 | loss = 1.580874 
iteration = 25 | loss = 2.003280 
iteration = 30 | loss = 2.090542 
iteration = 35 | loss = 1.410286 
iteration = 40 | loss = 1.800467 
iteration = 45 | loss = 1.837958 
iteration = 50 | loss = 1.673003 
iteration = 55 | loss = 1.679291 
iteration = 60 | loss = 1.919741 
iteration = 65 | loss = 1.759147 
iteration = 70 | loss = 1.990847 
iteration = 75 | loss = 1.813204 
iteration = 80 | loss = 1.763192 
iteration = 85 | loss = 1.547889 
iteration = 90 | loss = 1.941211 
iteration = 95 | loss = 1.718242 
iteration = 100 | loss = 1.693519 
iteration = 105 | loss = 1.916909 
iteration = 0 | loss = 1.880223 
iteration = 5 | loss = 1.681623 
iteration = 10 | loss = 1.611998 
iteration = 15 | loss = 1.722542 
iteration = 20 | loss = 2.209602 
iteration = 25 | loss = 1.606096 
iteration = 30 | loss = 1.635910 
iteration = 35 | loss = 2.248262 
iteration = 40 | loss = 2.264809 
iteration = 45 | loss = 1.314311 
iteration = 50 | loss = 1.818050 
iteration = 55 | loss = 2.136203 
iteration = 60 | loss = 1.709971 
iteration = 65 | loss = 1.979798 
iteration = 70 | loss = 1.401001 
iteration = 75 | loss = 1.538351 
iteration = 80 | loss = 1.599126 
iteration = 85 | loss = 1.619616 
iteration = 90 | loss = 2.113137 
iteration = 95 | loss = 1.399215 
iteration = 100 | loss = 1.559153 
iteration = 105 | loss = 1.577310 
 Epoch: [75] Loss: 1.3891  R1_I2A: 0.5792 R1_A2I: 0.4787 
                 
iteration = 0 | loss = 1.700241 
iteration = 5 | loss = 1.657327 
iteration = 10 | loss = 1.352808 
iteration = 15 | loss = 1.770357 
iteration = 20 | loss = 1.533504 
iteration = 25 | loss = 1.530867 
iteration = 30 | loss = 1.631985 
iteration = 35 | loss = 1.617110 
iteration = 40 | loss = 1.373950 
iteration = 45 | loss = 1.253041 
iteration = 50 | loss = 1.413139 
iteration = 55 | loss = 1.345211 
iteration = 60 | loss = 1.341476 
iteration = 65 | loss = 1.320749 
iteration = 70 | loss = 1.697520 
iteration = 75 | loss = 1.439628 
iteration = 80 | loss = 1.382966 
iteration = 85 | loss = 1.377016 
iteration = 90 | loss = 1.523490 
iteration = 95 | loss = 1.619920 
iteration = 100 | loss = 1.546306 
iteration = 105 | loss = 1.449581 
iteration = 0 | loss = 1.365928 
iteration = 5 | loss = 1.304518 
iteration = 10 | loss = 1.425951 
iteration = 15 | loss = 1.500709 
iteration = 20 | loss = 1.316012 
iteration = 25 | loss = 1.430713 
iteration = 30 | loss = 1.657894 
iteration = 35 | loss = 1.439157 
iteration = 40 | loss = 1.357930 
iteration = 45 | loss = 1.773764 
iteration = 50 | loss = 1.569490 
iteration = 55 | loss = 1.916324 
iteration = 60 | loss = 1.199733 
iteration = 65 | loss = 1.581501 
iteration = 70 | loss = 1.221735 
iteration = 75 | loss = 1.307162 
iteration = 80 | loss = 1.405759 
iteration = 85 | loss = 1.458841 
iteration = 90 | loss = 1.065381 
iteration = 95 | loss = 1.544008 
iteration = 100 | loss = 1.928628 
iteration = 105 | loss = 1.395596 
iteration = 0 | loss = 1.120468 
iteration = 5 | loss = 1.320404 
iteration = 10 | loss = 1.532682 
iteration = 15 | loss = 1.488475 
iteration = 20 | loss = 1.318352 
iteration = 25 | loss = 1.518732 
iteration = 30 | loss = 1.080827 
iteration = 35 | loss = 1.647548 
iteration = 40 | loss = 1.523486 
iteration = 45 | loss = 1.666106 
iteration = 50 | loss = 1.379625 
iteration = 55 | loss = 1.374744 
iteration = 60 | loss = 1.287025 
iteration = 65 | loss = 1.240553 
iteration = 70 | loss = 1.318851 
iteration = 75 | loss = 1.427686 
iteration = 80 | loss = 1.390970 
iteration = 85 | loss = 1.374859 
iteration = 90 | loss = 1.284130 
iteration = 95 | loss = 1.544321 
iteration = 100 | loss = 1.451110 
iteration = 105 | loss = 1.364740 
iteration = 0 | loss = 1.434087 
iteration = 5 | loss = 1.029047 
iteration = 10 | loss = 1.412870 
iteration = 15 | loss = 1.542834 
iteration = 20 | loss = 1.216862 
iteration = 25 | loss = 1.465313 
iteration = 30 | loss = 1.506769 
iteration = 35 | loss = 1.843573 
iteration = 40 | loss = 1.765271 
iteration = 45 | loss = 1.653266 
iteration = 50 | loss = 1.685413 
iteration = 55 | loss = 1.018959 
iteration = 60 | loss = 1.174235 
iteration = 65 | loss = 1.370797 
iteration = 70 | loss = 1.213902 
iteration = 75 | loss = 1.372401 
iteration = 80 | loss = 1.451239 
iteration = 85 | loss = 1.368252 
iteration = 90 | loss = 1.479714 
iteration = 95 | loss = 1.374281 
iteration = 100 | loss = 1.514478 
iteration = 105 | loss = 1.494730 
iteration = 0 | loss = 1.498938 
iteration = 5 | loss = 1.610760 
iteration = 10 | loss = 1.870922 
iteration = 15 | loss = 1.221999 
iteration = 20 | loss = 1.451363 
iteration = 25 | loss = 1.199480 
iteration = 30 | loss = 1.461921 
iteration = 35 | loss = 1.275537 
iteration = 40 | loss = 1.590869 
iteration = 45 | loss = 1.109211 
iteration = 50 | loss = 1.586945 
iteration = 55 | loss = 1.170206 
iteration = 60 | loss = 1.508271 
iteration = 65 | loss = 1.721048 
iteration = 70 | loss = 1.449762 
iteration = 75 | loss = 1.462009 
iteration = 80 | loss = 1.583605 
iteration = 85 | loss = 1.192438 
iteration = 90 | loss = 1.624192 
iteration = 95 | loss = 1.695294 
iteration = 100 | loss = 1.839710 
iteration = 105 | loss = 1.887303 
 Epoch: [80] Loss: 1.5810  R1_I2A: 0.5697 R1_A2I: 0.4762 
                 
iteration = 0 | loss = 1.627604 
iteration = 5 | loss = 1.366794 
iteration = 10 | loss = 1.704891 
iteration = 15 | loss = 1.588839 
iteration = 20 | loss = 1.671873 
iteration = 25 | loss = 1.251787 
iteration = 30 | loss = 1.684931 
iteration = 35 | loss = 1.724040 
iteration = 40 | loss = 1.471170 
iteration = 45 | loss = 1.281207 
iteration = 50 | loss = 1.501537 
iteration = 55 | loss = 1.336648 
iteration = 60 | loss = 1.629955 
iteration = 65 | loss = 1.698267 
iteration = 70 | loss = 1.359746 
iteration = 75 | loss = 1.907867 
iteration = 80 | loss = 1.496868 
iteration = 85 | loss = 1.809620 
iteration = 90 | loss = 1.749618 
iteration = 95 | loss = 1.640354 
iteration = 100 | loss = 1.407390 
iteration = 105 | loss = 1.823874 

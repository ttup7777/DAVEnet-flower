Namespace(RNN_dropout=0.0, WORKERS=8, audio_attention=None, audio_model='Davenet', batch_size=64, cfg_file='Confg/flower_train_batch_wo_ia.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gamma_clss=1.0, gpu_id=0, image_attention=None, image_model='VGG16', img_size=256, loss_clss=None, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=40, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_ia.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/wo_ia', simtype='MISA', smooth_gamm3=10.0, smooth_imgatt1=1.0, smooth_imgatt2=1.0, start_epoch=0, tasks='extraction', topk=3, weight_decay=1e-05)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
current #steps=0, #epochs=0
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 8.311208 
iteration = 5 | loss = 8.397251 
iteration = 10 | loss = 8.313759 
iteration = 15 | loss = 8.308231 
iteration = 20 | loss = 8.314574 
iteration = 25 | loss = 8.260084 
iteration = 30 | loss = 8.217148 
iteration = 35 | loss = 8.137931 
iteration = 40 | loss = 8.155073 
iteration = 45 | loss = 7.911164 
iteration = 50 | loss = 8.127310 
iteration = 55 | loss = 7.749187 
iteration = 60 | loss = 7.695543 
iteration = 65 | loss = 7.527722 
iteration = 70 | loss = 7.625401 
iteration = 75 | loss = 7.753300 
iteration = 80 | loss = 7.158241 
iteration = 85 | loss = 7.213519 
iteration = 90 | loss = 6.952729 
iteration = 95 | loss = 6.898613 
iteration = 100 | loss = 7.323113 
iteration = 105 | loss = 7.037293 
/scratch/xinshengwang/software/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 7.125399 
iteration = 5 | loss = 7.269683 
iteration = 10 | loss = 6.952200 
iteration = 15 | loss = 6.527561 
iteration = 20 | loss = 7.006062 
iteration = 25 | loss = 6.603929 
iteration = 30 | loss = 6.781199 
iteration = 35 | loss = 6.222029 
iteration = 40 | loss = 6.622294 
iteration = 45 | loss = 6.138473 
iteration = 50 | loss = 6.745206 
iteration = 55 | loss = 6.362424 
iteration = 60 | loss = 6.764885 
iteration = 65 | loss = 6.842761 
iteration = 70 | loss = 6.228662 
iteration = 75 | loss = 6.544021 
iteration = 80 | loss = 5.810077 
iteration = 85 | loss = 6.195658 
iteration = 90 | loss = 6.126555 
iteration = 95 | loss = 6.326729 
iteration = 100 | loss = 5.771313 
iteration = 105 | loss = 5.759805 
iteration = 0 | loss = 5.855480 
iteration = 5 | loss = 5.875742 
iteration = 10 | loss = 5.838626 
iteration = 15 | loss = 6.092022 
iteration = 20 | loss = 5.889687 
iteration = 25 | loss = 5.797527 
iteration = 30 | loss = 5.806481 
iteration = 35 | loss = 5.853268 
iteration = 40 | loss = 5.859676 
iteration = 45 | loss = 5.370844 
iteration = 50 | loss = 5.750401 
iteration = 55 | loss = 5.885015 
iteration = 60 | loss = 5.456277 
iteration = 65 | loss = 5.646025 
iteration = 70 | loss = 5.393155 
iteration = 75 | loss = 5.315789 
iteration = 80 | loss = 5.412607 
iteration = 85 | loss = 6.315911 
iteration = 90 | loss = 5.343848 
iteration = 95 | loss = 5.790225 
iteration = 100 | loss = 5.996624 
iteration = 105 | loss = 6.039339 
iteration = 0 | loss = 5.573728 
iteration = 5 | loss = 5.737823 
iteration = 10 | loss = 5.328075 
iteration = 15 | loss = 5.317002 
iteration = 20 | loss = 5.415220 
iteration = 25 | loss = 5.403732 
iteration = 30 | loss = 5.556735 
iteration = 35 | loss = 4.892368 
iteration = 40 | loss = 5.576790 
iteration = 45 | loss = 5.001346 
iteration = 50 | loss = 5.433068 
iteration = 55 | loss = 5.401535 
iteration = 60 | loss = 5.003471 
iteration = 65 | loss = 4.958705 
iteration = 70 | loss = 5.582154 
iteration = 75 | loss = 5.357838 
iteration = 80 | loss = 5.246068 
iteration = 85 | loss = 5.148454 
iteration = 90 | loss = 4.449683 
iteration = 95 | loss = 5.145318 
iteration = 100 | loss = 5.422451 
iteration = 105 | loss = 5.059130 
iteration = 0 | loss = 5.069871 
iteration = 5 | loss = 5.072652 
iteration = 10 | loss = 5.093938 
iteration = 15 | loss = 5.048307 
iteration = 20 | loss = 4.654043 
iteration = 25 | loss = 4.644873 
iteration = 30 | loss = 4.884528 
iteration = 35 | loss = 4.733507 
iteration = 40 | loss = 5.255133 
iteration = 45 | loss = 4.938103 
iteration = 50 | loss = 4.887060 
iteration = 55 | loss = 5.103552 
iteration = 60 | loss = 4.778095 
iteration = 65 | loss = 5.084053 
iteration = 70 | loss = 5.576517 
iteration = 75 | loss = 5.280231 
iteration = 80 | loss = 5.389446 
iteration = 85 | loss = 4.735656 
iteration = 90 | loss = 4.965763 
iteration = 95 | loss = 4.577685 
iteration = 100 | loss = 4.725831 
iteration = 105 | loss = 5.151214 
 Epoch: [5] Loss: 5.1360  R1_I2A: 0.4632 R1_A2I: 0.3298 
                 
iteration = 0 | loss = 4.592760 
iteration = 5 | loss = 4.495350 
iteration = 10 | loss = 5.348721 
iteration = 15 | loss = 4.676598 
iteration = 20 | loss = 4.615510 
iteration = 25 | loss = 4.988404 
iteration = 30 | loss = 4.876137 
iteration = 35 | loss = 4.912944 
iteration = 40 | loss = 4.968750 
iteration = 45 | loss = 4.649237 
iteration = 50 | loss = 4.974490 
iteration = 55 | loss = 5.648356 
iteration = 60 | loss = 4.587767 
iteration = 65 | loss = 4.855594 
iteration = 70 | loss = 4.998857 
iteration = 75 | loss = 4.775841 
iteration = 80 | loss = 4.706859 
iteration = 85 | loss = 4.599379 
iteration = 90 | loss = 4.871300 
iteration = 95 | loss = 4.573968 
iteration = 100 | loss = 5.382871 
iteration = 105 | loss = 4.986814 
iteration = 0 | loss = 4.477300 
iteration = 5 | loss = 4.468588 
iteration = 10 | loss = 4.575568 
iteration = 15 | loss = 4.365900 
iteration = 20 | loss = 4.882071 
iteration = 25 | loss = 4.818151 
iteration = 30 | loss = 4.213389 
iteration = 35 | loss = 4.617995 
iteration = 40 | loss = 5.305898 
iteration = 45 | loss = 4.799303 
iteration = 50 | loss = 4.994030 
iteration = 55 | loss = 4.327123 
iteration = 60 | loss = 4.515889 
iteration = 65 | loss = 4.849844 
iteration = 70 | loss = 4.852887 
iteration = 75 | loss = 4.630838 
iteration = 80 | loss = 4.494788 
iteration = 85 | loss = 4.975194 
iteration = 90 | loss = 5.183003 
iteration = 95 | loss = 4.971066 
iteration = 100 | loss = 4.515660 
iteration = 105 | loss = 5.028148 
iteration = 0 | loss = 4.319450 
iteration = 5 | loss = 4.507804 
iteration = 10 | loss = 4.924270 
iteration = 15 | loss = 4.395229 
iteration = 20 | loss = 4.249539 
iteration = 25 | loss = 4.681279 
iteration = 30 | loss = 4.519462 
iteration = 35 | loss = 4.772109 
iteration = 40 | loss = 4.376575 
iteration = 45 | loss = 4.700569 
iteration = 50 | loss = 4.719261 
iteration = 55 | loss = 4.953497 
iteration = 60 | loss = 4.066691 
iteration = 65 | loss = 4.282865 
iteration = 70 | loss = 4.528485 
iteration = 75 | loss = 4.873004 
iteration = 80 | loss = 4.588952 
iteration = 85 | loss = 4.447659 
iteration = 90 | loss = 4.480046 
iteration = 95 | loss = 4.640276 
iteration = 100 | loss = 4.476041 
iteration = 105 | loss = 4.280290 
iteration = 0 | loss = 4.467370 
iteration = 5 | loss = 4.307215 
iteration = 10 | loss = 4.172169 
iteration = 15 | loss = 4.529541 
iteration = 20 | loss = 4.476179 
iteration = 25 | loss = 4.942469 
iteration = 30 | loss = 4.280906 
iteration = 35 | loss = 4.638086 
iteration = 40 | loss = 4.100764 
iteration = 45 | loss = 3.997705 
iteration = 50 | loss = 4.475870 
iteration = 55 | loss = 4.358457 
iteration = 60 | loss = 4.854343 
iteration = 65 | loss = 4.577911 
iteration = 70 | loss = 5.042854 
iteration = 75 | loss = 4.016643 
iteration = 80 | loss = 4.773056 
iteration = 85 | loss = 4.760402 
iteration = 90 | loss = 4.505782 
iteration = 95 | loss = 4.406950 
iteration = 100 | loss = 4.433323 
iteration = 105 | loss = 3.926342 
iteration = 0 | loss = 3.795151 
iteration = 5 | loss = 4.907148 
iteration = 10 | loss = 4.622880 
iteration = 15 | loss = 4.050218 
iteration = 20 | loss = 4.226511 
iteration = 25 | loss = 3.783184 
iteration = 30 | loss = 4.603792 
iteration = 35 | loss = 4.314511 
iteration = 40 | loss = 4.460007 
iteration = 45 | loss = 4.820493 
iteration = 50 | loss = 4.143580 
iteration = 55 | loss = 4.696085 
iteration = 60 | loss = 4.293417 
iteration = 65 | loss = 4.616648 
iteration = 70 | loss = 4.700036 
iteration = 75 | loss = 3.822894 
iteration = 80 | loss = 4.528113 
iteration = 85 | loss = 4.669371 
iteration = 90 | loss = 4.647600 
iteration = 95 | loss = 4.516541 
iteration = 100 | loss = 4.548399 
iteration = 105 | loss = 4.179342 
 Epoch: [10] Loss: 4.5374  R1_I2A: 0.5463 R1_A2I: 0.3986 
                 
iteration = 0 | loss = 4.522189 
iteration = 5 | loss = 4.107228 
iteration = 10 | loss = 4.663538 
iteration = 15 | loss = 4.857201 
iteration = 20 | loss = 4.388391 
iteration = 25 | loss = 4.431749 
iteration = 30 | loss = 3.860492 
iteration = 35 | loss = 3.824081 
iteration = 40 | loss = 4.322771 
iteration = 45 | loss = 4.505086 
iteration = 50 | loss = 4.168120 
iteration = 55 | loss = 4.330255 
iteration = 60 | loss = 4.501029 
iteration = 65 | loss = 4.321590 
iteration = 70 | loss = 4.180880 
iteration = 75 | loss = 3.813738 
iteration = 80 | loss = 4.634274 
iteration = 85 | loss = 4.130148 
iteration = 90 | loss = 3.992540 
iteration = 95 | loss = 4.052189 
iteration = 100 | loss = 4.030765 
iteration = 105 | loss = 4.138933 
iteration = 0 | loss = 4.521529 
iteration = 5 | loss = 4.461450 
iteration = 10 | loss = 4.253214 
iteration = 15 | loss = 4.289966 
iteration = 20 | loss = 4.337938 
iteration = 25 | loss = 4.480076 
iteration = 30 | loss = 4.494659 
iteration = 35 | loss = 3.801653 
iteration = 40 | loss = 4.636757 
iteration = 45 | loss = 4.592112 
iteration = 50 | loss = 4.185748 
iteration = 55 | loss = 3.981109 
iteration = 60 | loss = 3.739160 
iteration = 65 | loss = 3.982114 
iteration = 70 | loss = 4.014462 
iteration = 75 | loss = 4.309409 
iteration = 80 | loss = 4.204202 
iteration = 85 | loss = 3.815735 
iteration = 90 | loss = 3.563058 
iteration = 95 | loss = 3.998811 
iteration = 100 | loss = 4.297388 
iteration = 105 | loss = 4.234930 
iteration = 0 | loss = 4.536667 
iteration = 5 | loss = 3.842349 
iteration = 10 | loss = 4.451593 
iteration = 15 | loss = 3.699477 
iteration = 20 | loss = 3.801437 
iteration = 25 | loss = 3.873322 
iteration = 30 | loss = 4.286579 
iteration = 35 | loss = 4.688958 
iteration = 40 | loss = 3.912321 
iteration = 45 | loss = 4.318975 
iteration = 50 | loss = 4.156345 
iteration = 55 | loss = 4.222580 
iteration = 60 | loss = 3.813987 
iteration = 65 | loss = 4.034510 
iteration = 70 | loss = 3.859675 
iteration = 75 | loss = 3.798582 
iteration = 80 | loss = 4.791133 
iteration = 85 | loss = 4.118725 
iteration = 90 | loss = 4.066840 
iteration = 95 | loss = 3.723982 
iteration = 100 | loss = 4.277968 
iteration = 105 | loss = 3.449573 
iteration = 0 | loss = 4.449019 
iteration = 5 | loss = 3.597224 
iteration = 10 | loss = 4.454040 
iteration = 15 | loss = 4.274796 
iteration = 20 | loss = 4.049823 
iteration = 25 | loss = 3.990028 
iteration = 30 | loss = 4.198325 
iteration = 35 | loss = 3.808775 
iteration = 40 | loss = 4.068329 
iteration = 45 | loss = 3.649008 
iteration = 50 | loss = 3.568627 
iteration = 55 | loss = 3.659057 
iteration = 60 | loss = 4.739533 
iteration = 65 | loss = 4.075183 
iteration = 70 | loss = 3.842280 
iteration = 75 | loss = 4.123273 
iteration = 80 | loss = 4.259244 
iteration = 85 | loss = 3.857756 
iteration = 90 | loss = 4.226520 
iteration = 95 | loss = 4.297284 
iteration = 100 | loss = 3.524577 
iteration = 105 | loss = 3.682159 
iteration = 0 | loss = 4.428214 
iteration = 5 | loss = 3.586584 
iteration = 10 | loss = 4.217635 
iteration = 15 | loss = 3.831483 
iteration = 20 | loss = 4.243366 
iteration = 25 | loss = 4.371314 
iteration = 30 | loss = 3.705595 
iteration = 35 | loss = 3.794739 
iteration = 40 | loss = 3.797568 
iteration = 45 | loss = 4.146723 
iteration = 50 | loss = 4.293033 
iteration = 55 | loss = 3.571153 
iteration = 60 | loss = 4.139251 
iteration = 65 | loss = 3.968352 
iteration = 70 | loss = 4.002566 
iteration = 75 | loss = 4.659132 
iteration = 80 | loss = 4.285058 
iteration = 85 | loss = 3.530056 
iteration = 90 | loss = 3.420328 
iteration = 95 | loss = 3.917492 
iteration = 100 | loss = 4.073524 
iteration = 105 | loss = 4.275826 
 Epoch: [15] Loss: 4.4315  R1_I2A: 0.5420 R1_A2I: 0.4176 
                 
iteration = 0 | loss = 4.497448 
iteration = 5 | loss = 4.255024 
iteration = 10 | loss = 3.888292 
iteration = 15 | loss = 3.911505 
iteration = 20 | loss = 3.483495 
iteration = 25 | loss = 3.927744 
iteration = 30 | loss = 3.815088 
iteration = 35 | loss = 4.403522 
iteration = 40 | loss = 3.796103 
iteration = 45 | loss = 4.214561 
iteration = 50 | loss = 4.138244 
iteration = 55 | loss = 3.859856 
iteration = 60 | loss = 4.182977 
iteration = 65 | loss = 4.297371 
iteration = 70 | loss = 3.922681 
iteration = 75 | loss = 4.136243 
iteration = 80 | loss = 3.489846 
iteration = 85 | loss = 3.891459 
iteration = 90 | loss = 3.509192 
iteration = 95 | loss = 3.878468 
iteration = 100 | loss = 3.849099 
iteration = 105 | loss = 3.468566 
iteration = 0 | loss = 3.507423 
iteration = 5 | loss = 4.526781 
iteration = 10 | loss = 3.349862 
iteration = 15 | loss = 3.594152 
iteration = 20 | loss = 3.787622 
iteration = 25 | loss = 3.865024 
iteration = 30 | loss = 4.144087 
iteration = 35 | loss = 3.911120 
iteration = 40 | loss = 4.142888 
iteration = 45 | loss = 3.536452 
iteration = 50 | loss = 3.537847 
iteration = 55 | loss = 3.506588 
iteration = 60 | loss = 4.309978 
iteration = 65 | loss = 3.529234 
iteration = 70 | loss = 3.664244 
iteration = 75 | loss = 4.087333 
iteration = 80 | loss = 3.355974 
iteration = 85 | loss = 4.099181 
iteration = 90 | loss = 3.732772 
iteration = 95 | loss = 3.659885 
iteration = 100 | loss = 4.045680 
iteration = 105 | loss = 3.717973 
iteration = 0 | loss = 3.203618 
iteration = 5 | loss = 3.340277 
iteration = 10 | loss = 3.562404 
iteration = 15 | loss = 3.910012 
iteration = 20 | loss = 3.531691 
iteration = 25 | loss = 4.112462 
iteration = 30 | loss = 3.906963 
iteration = 35 | loss = 4.628954 
iteration = 40 | loss = 4.005816 
iteration = 45 | loss = 3.499905 
iteration = 50 | loss = 4.091540 
iteration = 55 | loss = 4.144872 
iteration = 60 | loss = 3.934501 
iteration = 65 | loss = 3.580976 
iteration = 70 | loss = 3.503079 
iteration = 75 | loss = 3.878614 
iteration = 80 | loss = 4.003564 
iteration = 85 | loss = 3.572260 
iteration = 90 | loss = 4.007217 
iteration = 95 | loss = 3.465703 
iteration = 100 | loss = 3.694457 
iteration = 105 | loss = 3.373591 
iteration = 0 | loss = 3.678107 
iteration = 5 | loss = 3.614228 
iteration = 10 | loss = 3.616547 
iteration = 15 | loss = 4.236144 
iteration = 20 | loss = 3.814991 
iteration = 25 | loss = 3.866219 
iteration = 30 | loss = 3.512246 
iteration = 35 | loss = 4.235045 
iteration = 40 | loss = 4.583927 
iteration = 45 | loss = 3.358845 
iteration = 50 | loss = 3.348253 
iteration = 55 | loss = 3.607013 
iteration = 60 | loss = 3.681494 
iteration = 65 | loss = 3.197750 
iteration = 70 | loss = 3.064142 
iteration = 75 | loss = 3.940062 
iteration = 80 | loss = 4.045515 
iteration = 85 | loss = 3.717610 
iteration = 90 | loss = 4.138107 
iteration = 95 | loss = 3.679638 
iteration = 100 | loss = 3.893864 
iteration = 105 | loss = 3.523556 
iteration = 0 | loss = 3.737650 
iteration = 5 | loss = 3.901628 
iteration = 10 | loss = 3.728147 
iteration = 15 | loss = 3.826865 
iteration = 20 | loss = 3.914400 
iteration = 25 | loss = 3.781150 
iteration = 30 | loss = 3.492102 
iteration = 35 | loss = 3.208533 
iteration = 40 | loss = 3.229177 
iteration = 45 | loss = 3.977287 
iteration = 50 | loss = 3.678634 
iteration = 55 | loss = 3.688568 
iteration = 60 | loss = 3.401309 
iteration = 65 | loss = 3.655769 
iteration = 70 | loss = 3.873957 
iteration = 75 | loss = 3.579866 
iteration = 80 | loss = 3.728098 
iteration = 85 | loss = 3.443202 
iteration = 90 | loss = 3.683497 
iteration = 95 | loss = 3.863685 
iteration = 100 | loss = 3.444483 
iteration = 105 | loss = 3.606163 
 Epoch: [20] Loss: 3.6985  R1_I2A: 0.5697 R1_A2I: 0.4459 
                 
iteration = 0 | loss = 3.726377 
iteration = 5 | loss = 4.184607 
iteration = 10 | loss = 3.867944 
iteration = 15 | loss = 4.270034 
iteration = 20 | loss = 3.712497 
iteration = 25 | loss = 3.911726 
iteration = 30 | loss = 3.866129 
iteration = 35 | loss = 3.315579 
iteration = 40 | loss = 3.710731 
iteration = 45 | loss = 4.188027 
iteration = 50 | loss = 3.593979 
iteration = 55 | loss = 3.626155 
iteration = 60 | loss = 3.255788 
iteration = 65 | loss = 3.996022 
iteration = 70 | loss = 3.457611 
iteration = 75 | loss = 3.809103 
iteration = 80 | loss = 3.371627 
iteration = 85 | loss = 3.106884 
iteration = 90 | loss = 3.685953 
iteration = 95 | loss = 3.770349 
iteration = 100 | loss = 3.229589 
iteration = 105 | loss = 3.873055 
iteration = 0 | loss = 3.472716 
iteration = 5 | loss = 3.819105 
iteration = 10 | loss = 3.359040 
iteration = 15 | loss = 3.762036 
iteration = 20 | loss = 3.412989 
iteration = 25 | loss = 3.598198 
iteration = 30 | loss = 3.529958 
iteration = 35 | loss = 3.254334 
iteration = 40 | loss = 3.316706 
iteration = 45 | loss = 3.520132 
iteration = 50 | loss = 3.905984 
iteration = 55 | loss = 3.698699 
iteration = 60 | loss = 3.528057 
iteration = 65 | loss = 3.739543 
iteration = 70 | loss = 3.950855 
iteration = 75 | loss = 3.550147 
iteration = 80 | loss = 3.662698 
iteration = 85 | loss = 3.291399 
iteration = 90 | loss = 3.136310 
iteration = 95 | loss = 3.367894 
iteration = 100 | loss = 3.861028 
iteration = 105 | loss = 3.415943 
iteration = 0 | loss = 3.807356 
iteration = 5 | loss = 3.182497 
iteration = 10 | loss = 3.696939 
iteration = 15 | loss = 3.615693 
iteration = 20 | loss = 3.387439 
iteration = 25 | loss = 2.873321 
iteration = 30 | loss = 3.292789 
iteration = 35 | loss = 3.935748 
iteration = 40 | loss = 3.672818 
iteration = 45 | loss = 3.430759 
iteration = 50 | loss = 3.499196 
iteration = 55 | loss = 3.719768 
iteration = 60 | loss = 3.640275 
iteration = 65 | loss = 3.607841 
iteration = 70 | loss = 3.755480 
iteration = 75 | loss = 3.395522 
iteration = 80 | loss = 3.153352 
iteration = 85 | loss = 3.479846 
iteration = 90 | loss = 3.723104 
iteration = 95 | loss = 3.230195 
iteration = 100 | loss = 4.117217 
iteration = 105 | loss = 3.085583 
iteration = 0 | loss = 3.674943 
iteration = 5 | loss = 3.587030 
iteration = 10 | loss = 3.639061 
iteration = 15 | loss = 3.134660 
iteration = 20 | loss = 3.553198 
iteration = 25 | loss = 3.679023 
iteration = 30 | loss = 3.586270 
iteration = 35 | loss = 3.507016 
iteration = 40 | loss = 3.210122 
iteration = 45 | loss = 3.348901 
iteration = 50 | loss = 3.663105 
iteration = 55 | loss = 3.187412 
iteration = 60 | loss = 3.127514 
iteration = 65 | loss = 3.392692 
iteration = 70 | loss = 3.631939 
iteration = 75 | loss = 3.552055 
iteration = 80 | loss = 3.858839 
iteration = 85 | loss = 3.868180 
iteration = 90 | loss = 3.881414 
iteration = 95 | loss = 3.081162 
iteration = 100 | loss = 3.696843 
iteration = 105 | loss = 3.280603 
iteration = 0 | loss = 3.660895 
iteration = 5 | loss = 3.635294 
iteration = 10 | loss = 3.339491 
iteration = 15 | loss = 3.361256 
iteration = 20 | loss = 3.585736 
iteration = 25 | loss = 3.540633 
iteration = 30 | loss = 3.760377 
iteration = 35 | loss = 3.708263 
iteration = 40 | loss = 3.430005 
iteration = 45 | loss = 3.826924 
iteration = 50 | loss = 3.219301 
iteration = 55 | loss = 3.983963 
iteration = 60 | loss = 3.526147 
iteration = 65 | loss = 3.414713 
iteration = 70 | loss = 3.384403 
iteration = 75 | loss = 3.464007 
iteration = 80 | loss = 3.583432 
iteration = 85 | loss = 3.703597 
iteration = 90 | loss = 3.478351 
iteration = 95 | loss = 3.772956 
iteration = 100 | loss = 3.525764 
iteration = 105 | loss = 3.271737 
 Epoch: [25] Loss: 3.6727  R1_I2A: 0.5662 R1_A2I: 0.4447 
                 
iteration = 0 | loss = 3.505628 
iteration = 5 | loss = 3.521193 
iteration = 10 | loss = 3.644125 
iteration = 15 | loss = 3.372589 
iteration = 20 | loss = 3.391457 
iteration = 25 | loss = 3.712383 
iteration = 30 | loss = 3.667065 
iteration = 35 | loss = 3.433038 
iteration = 40 | loss = 3.211217 
iteration = 45 | loss = 3.316307 
iteration = 50 | loss = 3.589035 
iteration = 55 | loss = 3.816092 
iteration = 60 | loss = 3.440074 
iteration = 65 | loss = 3.658421 
iteration = 70 | loss = 3.338319 
iteration = 75 | loss = 3.321925 
iteration = 80 | loss = 3.245547 
iteration = 85 | loss = 3.604289 
iteration = 90 | loss = 3.589601 
iteration = 95 | loss = 3.477635 
iteration = 100 | loss = 3.504431 
iteration = 105 | loss = 3.384228 
iteration = 0 | loss = 3.686029 
iteration = 5 | loss = 3.730637 
iteration = 10 | loss = 3.141973 
iteration = 15 | loss = 3.777392 
iteration = 20 | loss = 3.498184 
iteration = 25 | loss = 3.281588 
iteration = 30 | loss = 3.141769 
iteration = 35 | loss = 3.427281 
iteration = 40 | loss = 3.656183 
iteration = 45 | loss = 3.250428 
iteration = 50 | loss = 3.955201 
iteration = 55 | loss = 3.073355 
iteration = 60 | loss = 2.662257 
iteration = 65 | loss = 3.468871 
iteration = 70 | loss = 3.194187 
iteration = 75 | loss = 3.352234 
iteration = 80 | loss = 3.656454 
iteration = 85 | loss = 3.535226 
iteration = 90 | loss = 3.428265 
iteration = 95 | loss = 4.110239 
iteration = 100 | loss = 3.318310 
iteration = 105 | loss = 3.248491 
iteration = 0 | loss = 2.973427 
iteration = 5 | loss = 2.741029 
iteration = 10 | loss = 2.854878 
iteration = 15 | loss = 3.786767 
iteration = 20 | loss = 3.150862 
iteration = 25 | loss = 3.543821 
iteration = 30 | loss = 3.215508 
iteration = 35 | loss = 3.345987 
iteration = 40 | loss = 3.512764 
iteration = 45 | loss = 3.548625 
iteration = 50 | loss = 3.467951 
iteration = 55 | loss = 2.961590 
iteration = 60 | loss = 3.402820 
iteration = 65 | loss = 3.401663 
iteration = 70 | loss = 3.699430 
iteration = 75 | loss = 3.269379 
iteration = 80 | loss = 3.132293 
iteration = 85 | loss = 3.135252 
iteration = 90 | loss = 3.429482 
iteration = 95 | loss = 3.715629 
iteration = 100 | loss = 2.786926 
iteration = 105 | loss = 3.456132 
iteration = 0 | loss = 3.290422 
iteration = 5 | loss = 3.672554 
iteration = 10 | loss = 3.627369 
iteration = 15 | loss = 3.374438 
iteration = 20 | loss = 3.828696 
iteration = 25 | loss = 3.335994 
iteration = 30 | loss = 3.425676 
iteration = 35 | loss = 3.042518 
iteration = 40 | loss = 4.104029 
iteration = 45 | loss = 3.893085 
iteration = 50 | loss = 3.657609 
iteration = 55 | loss = 3.695353 
iteration = 60 | loss = 2.963253 
iteration = 65 | loss = 3.602294 
iteration = 70 | loss = 3.758857 
iteration = 75 | loss = 3.747642 
iteration = 80 | loss = 3.239181 
iteration = 85 | loss = 2.861894 
iteration = 90 | loss = 3.317015 
iteration = 95 | loss = 3.250044 
iteration = 100 | loss = 3.337710 
iteration = 105 | loss = 3.477380 
iteration = 0 | loss = 3.384871 
iteration = 5 | loss = 3.694470 
iteration = 10 | loss = 3.455430 
iteration = 15 | loss = 3.737139 
iteration = 20 | loss = 3.243942 
iteration = 25 | loss = 4.078444 
iteration = 30 | loss = 3.386936 
iteration = 35 | loss = 3.222334 
iteration = 40 | loss = 3.438222 
iteration = 45 | loss = 3.188170 
iteration = 50 | loss = 3.478362 
iteration = 55 | loss = 4.240773 
iteration = 60 | loss = 3.404594 
iteration = 65 | loss = 3.377772 
iteration = 70 | loss = 3.799159 
iteration = 75 | loss = 2.741694 
iteration = 80 | loss = 3.367769 
iteration = 85 | loss = 3.356555 
iteration = 90 | loss = 3.277292 
iteration = 95 | loss = 3.369028 
iteration = 100 | loss = 3.280666 
iteration = 105 | loss = 3.534381 
 Epoch: [30] Loss: 3.4923  R1_I2A: 0.5662 R1_A2I: 0.4610 
                 
 Epoch: [30] Loss: 3.4923  R1_I2A: 0.5658 mAP_I2A: 0.5077  R1_A2I: 0.4610 mAP_A2I: 0.4016 
                     
iteration = 0 | loss = 3.223682 
iteration = 5 | loss = 3.146384 
iteration = 10 | loss = 3.468656 
iteration = 15 | loss = 2.982426 
iteration = 20 | loss = 3.469559 
iteration = 25 | loss = 3.617337 
iteration = 30 | loss = 3.307199 
iteration = 35 | loss = 3.278086 
iteration = 40 | loss = 3.092188 
iteration = 45 | loss = 3.250936 
iteration = 50 | loss = 2.862685 
iteration = 55 | loss = 3.417617 
iteration = 60 | loss = 3.812712 
iteration = 65 | loss = 3.286158 
iteration = 70 | loss = 3.228920 
iteration = 75 | loss = 3.281624 
iteration = 80 | loss = 3.242495 
iteration = 85 | loss = 3.230521 
iteration = 90 | loss = 3.579655 
iteration = 95 | loss = 3.358199 
iteration = 100 | loss = 3.616010 
iteration = 105 | loss = 3.614070 
iteration = 0 | loss = 3.472167 
iteration = 5 | loss = 3.300133 
iteration = 10 | loss = 4.081753 
iteration = 15 | loss = 3.386630 
iteration = 20 | loss = 3.264787 
iteration = 25 | loss = 3.446417 
iteration = 30 | loss = 3.486565 
iteration = 35 | loss = 4.022972 
iteration = 40 | loss = 3.080973 
iteration = 45 | loss = 2.926203 
iteration = 50 | loss = 3.119345 
iteration = 55 | loss = 3.307583 
iteration = 60 | loss = 3.168433 
iteration = 65 | loss = 3.759598 
iteration = 70 | loss = 3.502613 
iteration = 75 | loss = 3.290586 
iteration = 80 | loss = 3.452076 
iteration = 85 | loss = 2.772679 
iteration = 90 | loss = 3.234691 
iteration = 95 | loss = 3.552599 
iteration = 100 | loss = 3.122478 
iteration = 105 | loss = 3.432619 
iteration = 0 | loss = 3.651999 
iteration = 5 | loss = 3.637669 
iteration = 10 | loss = 3.497095 
iteration = 15 | loss = 3.568760 
iteration = 20 | loss = 3.172128 
iteration = 25 | loss = 3.094525 
iteration = 30 | loss = 3.236233 
iteration = 35 | loss = 3.248073 
iteration = 40 | loss = 2.948396 
iteration = 45 | loss = 3.140812 
iteration = 50 | loss = 3.317576 
iteration = 55 | loss = 3.677535 
iteration = 60 | loss = 3.190315 
iteration = 65 | loss = 3.465282 
iteration = 70 | loss = 3.648316 
iteration = 75 | loss = 3.484775 
iteration = 80 | loss = 3.231956 
iteration = 85 | loss = 3.647674 
iteration = 90 | loss = 3.604808 
iteration = 95 | loss = 3.351301 
iteration = 100 | loss = 3.031693 
iteration = 105 | loss = 3.235750 
iteration = 0 | loss = 3.205094 
iteration = 5 | loss = 3.128440 
iteration = 10 | loss = 2.816932 
iteration = 15 | loss = 2.864189 
iteration = 20 | loss = 3.761259 
iteration = 25 | loss = 2.950532 
iteration = 30 | loss = 3.176934 
iteration = 35 | loss = 3.161511 
iteration = 40 | loss = 3.079705 
iteration = 45 | loss = 3.009065 
iteration = 50 | loss = 3.888101 
iteration = 55 | loss = 3.116133 
iteration = 60 | loss = 3.505306 
iteration = 65 | loss = 3.104811 
iteration = 70 | loss = 3.331423 
iteration = 75 | loss = 2.499608 
iteration = 80 | loss = 3.635946 
iteration = 85 | loss = 3.255722 
iteration = 90 | loss = 3.136704 
iteration = 95 | loss = 3.941616 
iteration = 100 | loss = 3.464839 
iteration = 105 | loss = 3.571026 
iteration = 0 | loss = 3.420539 
iteration = 5 | loss = 3.005875 
iteration = 10 | loss = 3.093423 
iteration = 15 | loss = 3.144820 
iteration = 20 | loss = 3.278198 
iteration = 25 | loss = 3.089258 
iteration = 30 | loss = 3.345704 
iteration = 35 | loss = 3.686203 
iteration = 40 | loss = 2.930793 
iteration = 45 | loss = 3.239697 
iteration = 50 | loss = 2.797107 
iteration = 55 | loss = 3.277184 
iteration = 60 | loss = 3.014729 
iteration = 65 | loss = 2.816181 
iteration = 70 | loss = 3.090430 
iteration = 75 | loss = 2.789938 
iteration = 80 | loss = 2.983246 
iteration = 85 | loss = 3.040401 
iteration = 90 | loss = 2.969703 
iteration = 95 | loss = 3.013461 
iteration = 100 | loss = 3.264563 
iteration = 105 | loss = 3.507291 
 Epoch: [35] Loss: 3.1760  R1_I2A: 0.5671 R1_A2I: 0.4644 
                 
 Epoch: [35] Loss: 3.1760  R1_I2A: 0.5697 mAP_I2A: 0.5058  R1_A2I: 0.4644 mAP_A2I: 0.4037 
                     
iteration = 0 | loss = 3.674486 
iteration = 5 | loss = 3.473554 
iteration = 10 | loss = 3.226401 
iteration = 15 | loss = 3.613426 
iteration = 20 | loss = 2.876577 
iteration = 25 | loss = 3.221731 
iteration = 30 | loss = 3.075712 
iteration = 35 | loss = 2.442253 
iteration = 40 | loss = 2.939044 
iteration = 45 | loss = 3.032466 
iteration = 50 | loss = 3.221855 
iteration = 55 | loss = 2.849562 
iteration = 60 | loss = 3.643031 
iteration = 65 | loss = 3.224505 
iteration = 70 | loss = 3.185185 
iteration = 75 | loss = 3.334985 
iteration = 80 | loss = 2.848537 
iteration = 85 | loss = 2.715656 
iteration = 90 | loss = 3.085372 
iteration = 95 | loss = 3.050900 
iteration = 100 | loss = 3.531633 
iteration = 105 | loss = 3.305851 
iteration = 0 | loss = 3.131042 
iteration = 5 | loss = 3.750292 
iteration = 10 | loss = 3.301463 
iteration = 15 | loss = 2.676574 
iteration = 20 | loss = 3.099690 
iteration = 25 | loss = 2.655182 
iteration = 30 | loss = 3.023997 
iteration = 35 | loss = 2.952044 
iteration = 40 | loss = 3.428544 
iteration = 45 | loss = 2.889238 
iteration = 50 | loss = 3.388983 
iteration = 55 | loss = 3.008867 
iteration = 60 | loss = 2.871418 
iteration = 65 | loss = 3.052726 
iteration = 70 | loss = 3.307991 
iteration = 75 | loss = 2.791764 
iteration = 80 | loss = 2.917361 
iteration = 85 | loss = 3.090324 
iteration = 90 | loss = 2.844338 
iteration = 95 | loss = 2.841636 
iteration = 100 | loss = 2.873482 
iteration = 105 | loss = 3.235325 
iteration = 0 | loss = 3.256440 
iteration = 5 | loss = 3.128035 
iteration = 10 | loss = 3.106387 
iteration = 15 | loss = 2.872046 
iteration = 20 | loss = 3.017322 
iteration = 25 | loss = 3.034962 
iteration = 30 | loss = 3.295844 
iteration = 35 | loss = 2.780631 
iteration = 40 | loss = 2.625902 
iteration = 45 | loss = 2.941131 
iteration = 50 | loss = 2.806643 
iteration = 55 | loss = 3.328902 
iteration = 60 | loss = 3.079998 
iteration = 65 | loss = 3.298621 
iteration = 70 | loss = 3.189625 
iteration = 75 | loss = 2.993762 
iteration = 80 | loss = 2.850595 
iteration = 85 | loss = 3.345343 
iteration = 90 | loss = 3.302710 
iteration = 95 | loss = 3.240706 
iteration = 100 | loss = 3.035570 
iteration = 105 | loss = 3.037769 
iteration = 0 | loss = 3.400046 
iteration = 5 | loss = 2.854667 
iteration = 10 | loss = 2.527064 
iteration = 15 | loss = 3.626243 
iteration = 20 | loss = 2.808938 
iteration = 25 | loss = 3.395742 
iteration = 30 | loss = 3.617448 
iteration = 35 | loss = 2.844057 
iteration = 40 | loss = 3.391390 
iteration = 45 | loss = 3.097892 
iteration = 50 | loss = 3.357358 
iteration = 55 | loss = 3.399571 
iteration = 60 | loss = 3.506667 
iteration = 65 | loss = 2.680265 
iteration = 70 | loss = 3.048747 
iteration = 75 | loss = 2.737844 
iteration = 80 | loss = 2.724491 
iteration = 85 | loss = 3.554473 
iteration = 90 | loss = 3.008613 
iteration = 95 | loss = 2.870073 
iteration = 100 | loss = 3.088079 
iteration = 105 | loss = 3.347440 
iteration = 0 | loss = 2.748311 
iteration = 5 | loss = 3.310779 
iteration = 10 | loss = 3.271599 
iteration = 15 | loss = 3.422997 
iteration = 20 | loss = 3.125668 
iteration = 25 | loss = 3.089941 
iteration = 30 | loss = 3.086251 
iteration = 35 | loss = 2.798158 
iteration = 40 | loss = 2.855066 
iteration = 45 | loss = 3.260271 
iteration = 50 | loss = 3.065533 
iteration = 55 | loss = 3.179912 
iteration = 60 | loss = 3.772398 
iteration = 65 | loss = 3.094505 
iteration = 70 | loss = 3.346744 
iteration = 75 | loss = 2.962817 
iteration = 80 | loss = 2.993169 
iteration = 85 | loss = 2.879193 
iteration = 90 | loss = 3.287167 
iteration = 95 | loss = 3.053074 
iteration = 100 | loss = 3.131026 
iteration = 105 | loss = 3.141499 
 Epoch: [40] Loss: 2.9784  R1_I2A: 0.5602 R1_A2I: 0.4643 
                 
iteration = 0 | loss = 2.939512 
iteration = 5 | loss = 3.303745 
iteration = 10 | loss = 3.066768 
iteration = 15 | loss = 2.907089 
iteration = 20 | loss = 2.628969 
iteration = 25 | loss = 2.662905 
iteration = 30 | loss = 3.239301 
iteration = 35 | loss = 3.163334 
iteration = 40 | loss = 3.036637 
iteration = 45 | loss = 3.165313 
iteration = 50 | loss = 3.151339 
iteration = 55 | loss = 2.904700 
iteration = 60 | loss = 2.672672 
iteration = 65 | loss = 3.352500 
iteration = 70 | loss = 2.649433 
iteration = 75 | loss = 2.990107 
iteration = 80 | loss = 3.399764 
iteration = 85 | loss = 3.032924 
iteration = 90 | loss = 2.985020 
iteration = 95 | loss = 2.934371 
iteration = 100 | loss = 3.199655 
iteration = 105 | loss = 2.667740 

Namespace(RNN_dropout=0.0, WORKERS=8, audio_attention=None, audio_model='Davenet', batch_size=64, cfg_file='Confg/flower_train_batch_wo_ia.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gamma_clss=1.0, gpu_id=0, image_attention=None, image_model='VGG16', img_size=256, loss_clss=None, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=80, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_ia.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/wo_ia', simtype='MISA', smooth_gamm3=10.0, smooth_imgatt1=1.0, smooth_imgatt2=1.0, start_epoch=40, tasks='extraction', topk=3, weight_decay=1e-05)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/MSc/Tiant/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 3.278045 
iteration = 5 | loss = 3.135833 
iteration = 10 | loss = 2.980708 
iteration = 15 | loss = 2.961676 
iteration = 20 | loss = 2.959743 
iteration = 25 | loss = 4.027200 
iteration = 30 | loss = 2.762658 
iteration = 35 | loss = 3.483690 
iteration = 40 | loss = 3.106270 
iteration = 45 | loss = 4.003025 
iteration = 50 | loss = 3.291532 
iteration = 55 | loss = 3.053915 
iteration = 60 | loss = 2.694612 
iteration = 65 | loss = 3.118681 
iteration = 70 | loss = 3.020270 
iteration = 75 | loss = 2.882390 
iteration = 80 | loss = 3.010728 
iteration = 85 | loss = 3.418150 
iteration = 90 | loss = 3.155249 
iteration = 95 | loss = 3.019128 
iteration = 100 | loss = 3.365759 
iteration = 105 | loss = 2.850942 
/scratch/xinshengwang/software/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 2.946826 
iteration = 5 | loss = 2.983550 
iteration = 10 | loss = 3.336730 
iteration = 15 | loss = 2.962415 
iteration = 20 | loss = 3.339027 
iteration = 25 | loss = 3.042232 
iteration = 30 | loss = 3.078316 
iteration = 35 | loss = 2.592275 
iteration = 40 | loss = 3.172320 
iteration = 45 | loss = 3.383784 
iteration = 50 | loss = 2.685281 
iteration = 55 | loss = 2.925823 
iteration = 60 | loss = 3.367803 
iteration = 65 | loss = 3.347610 
iteration = 70 | loss = 2.806060 
iteration = 75 | loss = 3.237729 
iteration = 80 | loss = 3.004660 
iteration = 85 | loss = 2.506884 
iteration = 90 | loss = 3.419058 
iteration = 95 | loss = 3.170273 
iteration = 100 | loss = 2.681179 
iteration = 105 | loss = 2.769634 
iteration = 0 | loss = 3.144085 
iteration = 5 | loss = 2.478066 
iteration = 10 | loss = 2.314633 
iteration = 15 | loss = 3.525647 
iteration = 20 | loss = 3.023136 
iteration = 25 | loss = 3.321285 
iteration = 30 | loss = 2.574016 
iteration = 35 | loss = 3.441687 
iteration = 40 | loss = 3.211858 
iteration = 45 | loss = 2.481958 
iteration = 50 | loss = 3.037258 
iteration = 55 | loss = 2.845074 
iteration = 60 | loss = 2.746256 
iteration = 65 | loss = 2.868370 
iteration = 70 | loss = 3.003284 
iteration = 75 | loss = 2.402933 
iteration = 80 | loss = 2.219876 
iteration = 85 | loss = 3.497413 
iteration = 90 | loss = 2.694250 
iteration = 95 | loss = 3.136457 
iteration = 100 | loss = 2.726058 
iteration = 105 | loss = 3.360395 
iteration = 0 | loss = 2.691110 
iteration = 5 | loss = 2.872656 
iteration = 10 | loss = 3.131813 
iteration = 15 | loss = 2.593279 
iteration = 20 | loss = 2.942827 
iteration = 25 | loss = 3.154705 
iteration = 30 | loss = 3.084858 
iteration = 35 | loss = 2.678837 
iteration = 40 | loss = 2.889205 
iteration = 45 | loss = 2.768685 
iteration = 50 | loss = 3.155257 
iteration = 55 | loss = 2.947755 
iteration = 60 | loss = 2.987007 
iteration = 65 | loss = 2.637242 
iteration = 70 | loss = 2.576181 
iteration = 75 | loss = 3.139578 
iteration = 80 | loss = 2.369220 
iteration = 85 | loss = 2.920926 
iteration = 90 | loss = 2.256360 
iteration = 95 | loss = 2.974835 
iteration = 100 | loss = 2.723120 
iteration = 105 | loss = 2.775109 
iteration = 0 | loss = 2.857994 
iteration = 5 | loss = 2.859528 
iteration = 10 | loss = 2.255933 
iteration = 15 | loss = 2.783064 
iteration = 20 | loss = 2.752863 
iteration = 25 | loss = 2.618908 
iteration = 30 | loss = 2.620713 
iteration = 35 | loss = 2.609932 
iteration = 40 | loss = 3.111165 
iteration = 45 | loss = 3.085532 
iteration = 50 | loss = 2.939605 
iteration = 55 | loss = 2.785368 
iteration = 60 | loss = 2.671897 
iteration = 65 | loss = 2.888285 
iteration = 70 | loss = 3.069951 
iteration = 75 | loss = 2.801391 
iteration = 80 | loss = 3.300662 
iteration = 85 | loss = 3.232127 
iteration = 90 | loss = 2.787806 
iteration = 95 | loss = 2.596425 
iteration = 100 | loss = 2.904338 
iteration = 105 | loss = 2.881027 
 Epoch: [45] Loss: 2.9299  R1_I2A: 0.5723 R1_A2I: 0.4695 
                 
 Epoch: [45] Loss: 2.9299  R1_I2A: 0.5751 mAP_I2A: 0.5051  R1_A2I: 0.4695 mAP_A2I: 0.4098 
                     
iteration = 0 | loss = 3.314492 
iteration = 5 | loss = 2.717796 
iteration = 10 | loss = 2.865379 
iteration = 15 | loss = 2.923905 
iteration = 20 | loss = 3.469314 
iteration = 25 | loss = 3.108756 
iteration = 30 | loss = 2.848166 
iteration = 35 | loss = 2.543390 
iteration = 40 | loss = 2.552993 
iteration = 45 | loss = 2.615098 
iteration = 50 | loss = 2.908082 
iteration = 55 | loss = 3.069510 
iteration = 60 | loss = 2.553611 
iteration = 65 | loss = 3.023297 
iteration = 70 | loss = 2.958786 
iteration = 75 | loss = 3.432519 
iteration = 80 | loss = 2.813977 
iteration = 85 | loss = 2.806048 
iteration = 90 | loss = 2.848216 
iteration = 95 | loss = 3.108478 
iteration = 100 | loss = 3.046080 
iteration = 105 | loss = 3.116793 
iteration = 0 | loss = 2.976798 
iteration = 5 | loss = 2.557428 
iteration = 10 | loss = 2.675659 
iteration = 15 | loss = 2.756371 
iteration = 20 | loss = 2.894663 
iteration = 25 | loss = 2.828293 
iteration = 30 | loss = 2.620303 
iteration = 35 | loss = 2.861877 
iteration = 40 | loss = 2.908051 
iteration = 45 | loss = 2.603060 
iteration = 50 | loss = 2.982822 
iteration = 55 | loss = 3.506190 
iteration = 60 | loss = 2.868159 
iteration = 65 | loss = 2.555961 
iteration = 70 | loss = 3.053874 
iteration = 75 | loss = 3.118863 
iteration = 80 | loss = 3.288410 
iteration = 85 | loss = 2.180835 
iteration = 90 | loss = 2.126930 
iteration = 95 | loss = 3.189264 
iteration = 100 | loss = 2.894299 
iteration = 105 | loss = 2.999867 
iteration = 0 | loss = 2.424201 
iteration = 5 | loss = 2.624342 
iteration = 10 | loss = 2.858133 
iteration = 15 | loss = 2.743571 
iteration = 20 | loss = 3.392328 
iteration = 25 | loss = 2.817942 
iteration = 30 | loss = 2.396273 
iteration = 35 | loss = 2.680224 
iteration = 40 | loss = 2.763757 
iteration = 45 | loss = 3.116765 
iteration = 50 | loss = 2.949797 
iteration = 55 | loss = 2.814443 
iteration = 60 | loss = 2.939794 
iteration = 65 | loss = 2.666490 
iteration = 70 | loss = 2.569323 
iteration = 75 | loss = 2.640566 
iteration = 80 | loss = 2.992648 
iteration = 85 | loss = 3.155401 
iteration = 90 | loss = 2.790815 
iteration = 95 | loss = 3.004796 
iteration = 100 | loss = 3.095372 
iteration = 105 | loss = 3.054124 
iteration = 0 | loss = 2.999756 
iteration = 5 | loss = 2.447749 
iteration = 10 | loss = 3.140155 
iteration = 15 | loss = 2.561011 
iteration = 20 | loss = 3.100487 
iteration = 25 | loss = 2.528578 
iteration = 30 | loss = 2.791038 
iteration = 35 | loss = 2.893354 
iteration = 40 | loss = 2.771969 
iteration = 45 | loss = 2.840448 
iteration = 50 | loss = 3.005953 
iteration = 55 | loss = 2.882822 
iteration = 60 | loss = 2.637208 
iteration = 65 | loss = 2.875257 
iteration = 70 | loss = 3.062567 
iteration = 75 | loss = 2.759954 
iteration = 80 | loss = 3.133775 
iteration = 85 | loss = 2.484960 
iteration = 90 | loss = 2.779167 
iteration = 95 | loss = 2.954537 
iteration = 100 | loss = 2.932780 
iteration = 105 | loss = 2.962643 
iteration = 0 | loss = 2.838409 
iteration = 5 | loss = 2.801343 
iteration = 10 | loss = 2.352235 
iteration = 15 | loss = 3.423000 
iteration = 20 | loss = 2.724667 
iteration = 25 | loss = 2.508300 
iteration = 30 | loss = 2.734871 
iteration = 35 | loss = 2.531502 
iteration = 40 | loss = 3.016292 
iteration = 45 | loss = 2.990412 
iteration = 50 | loss = 2.778190 
iteration = 55 | loss = 3.214251 
iteration = 60 | loss = 2.915565 
iteration = 65 | loss = 3.027729 
iteration = 70 | loss = 2.971040 
iteration = 75 | loss = 2.425088 
iteration = 80 | loss = 2.774046 
iteration = 85 | loss = 2.663801 
iteration = 90 | loss = 2.589899 
iteration = 95 | loss = 2.764462 
iteration = 100 | loss = 3.099236 
iteration = 105 | loss = 2.544069 
 Epoch: [50] Loss: 2.4730  R1_I2A: 0.5688 R1_A2I: 0.4815 
                 
 Epoch: [50] Loss: 2.4730  R1_I2A: 0.5712 mAP_I2A: 0.5212  R1_A2I: 0.4815 mAP_A2I: 0.4198 
                     
iteration = 0 | loss = 2.437681 
iteration = 5 | loss = 2.640317 
iteration = 10 | loss = 2.638571 
iteration = 15 | loss = 2.465856 
iteration = 20 | loss = 2.217796 
iteration = 25 | loss = 2.665122 
iteration = 30 | loss = 2.315477 
iteration = 35 | loss = 2.375307 
iteration = 40 | loss = 2.363325 
iteration = 45 | loss = 2.176956 
iteration = 50 | loss = 2.506183 
iteration = 55 | loss = 2.183012 
iteration = 60 | loss = 2.737256 
iteration = 65 | loss = 2.923585 
iteration = 70 | loss = 2.879093 
iteration = 75 | loss = 2.691093 
iteration = 80 | loss = 3.300180 
iteration = 85 | loss = 2.497458 
iteration = 90 | loss = 2.738070 
iteration = 95 | loss = 2.606261 
iteration = 100 | loss = 2.808016 
iteration = 105 | loss = 2.188323 
iteration = 0 | loss = 2.509060 
iteration = 5 | loss = 2.470825 
iteration = 10 | loss = 2.881464 
iteration = 15 | loss = 2.424862 
iteration = 20 | loss = 2.991918 
iteration = 25 | loss = 2.966240 
iteration = 30 | loss = 2.784712 
iteration = 35 | loss = 3.074415 
iteration = 40 | loss = 3.048829 
iteration = 45 | loss = 3.144391 
iteration = 50 | loss = 2.523549 
iteration = 55 | loss = 2.907892 
iteration = 60 | loss = 2.614381 
iteration = 65 | loss = 2.469934 
iteration = 70 | loss = 2.624410 
iteration = 75 | loss = 2.317944 
iteration = 80 | loss = 2.316463 
iteration = 85 | loss = 2.691350 
iteration = 90 | loss = 2.629729 
iteration = 95 | loss = 2.810403 
iteration = 100 | loss = 2.406347 
iteration = 105 | loss = 2.569331 
iteration = 0 | loss = 2.190676 
iteration = 5 | loss = 2.871763 
iteration = 10 | loss = 2.819094 
iteration = 15 | loss = 2.926134 
iteration = 20 | loss = 2.316804 
iteration = 25 | loss = 2.237756 
iteration = 30 | loss = 2.322279 
iteration = 35 | loss = 2.311424 
iteration = 40 | loss = 2.543645 
iteration = 45 | loss = 2.301878 
iteration = 50 | loss = 2.913514 
iteration = 55 | loss = 3.010216 
iteration = 60 | loss = 2.874262 
iteration = 65 | loss = 2.982719 
iteration = 70 | loss = 2.900504 
iteration = 75 | loss = 2.963726 
iteration = 80 | loss = 3.046750 
iteration = 85 | loss = 2.532298 
iteration = 90 | loss = 2.681953 
iteration = 95 | loss = 3.024269 
iteration = 100 | loss = 2.916749 
iteration = 105 | loss = 2.503053 
iteration = 0 | loss = 2.645168 
iteration = 5 | loss = 2.656495 
iteration = 10 | loss = 2.316339 
iteration = 15 | loss = 2.638112 
iteration = 20 | loss = 2.024893 
iteration = 25 | loss = 2.408834 
iteration = 30 | loss = 2.560878 
iteration = 35 | loss = 2.523465 
iteration = 40 | loss = 2.460677 
iteration = 45 | loss = 2.661660 
iteration = 50 | loss = 3.098439 
iteration = 55 | loss = 2.271253 
iteration = 60 | loss = 1.894953 
iteration = 65 | loss = 2.499326 
iteration = 70 | loss = 2.595353 
iteration = 75 | loss = 2.663592 
iteration = 80 | loss = 2.703185 
iteration = 85 | loss = 2.474090 
iteration = 90 | loss = 2.435769 
iteration = 95 | loss = 2.777023 
iteration = 100 | loss = 2.831056 
iteration = 105 | loss = 2.481962 
iteration = 0 | loss = 2.821294 
iteration = 5 | loss = 2.730728 
iteration = 10 | loss = 2.340978 
iteration = 15 | loss = 2.241100 
iteration = 20 | loss = 2.352163 
iteration = 25 | loss = 2.739563 
iteration = 30 | loss = 2.542740 
iteration = 35 | loss = 2.681980 
iteration = 40 | loss = 2.675546 
iteration = 45 | loss = 2.741253 
iteration = 50 | loss = 2.340682 
iteration = 55 | loss = 2.400430 
iteration = 60 | loss = 2.909009 
iteration = 65 | loss = 2.569372 
iteration = 70 | loss = 3.057715 
iteration = 75 | loss = 2.701303 
iteration = 80 | loss = 2.605966 
iteration = 85 | loss = 2.229708 
iteration = 90 | loss = 2.831850 
iteration = 95 | loss = 2.166438 
iteration = 100 | loss = 2.488600 
iteration = 105 | loss = 2.568304 
 Epoch: [55] Loss: 2.6819  R1_I2A: 0.5887 R1_A2I: 0.4768 
                 
 Epoch: [55] Loss: 2.6819  R1_I2A: 0.5920 mAP_I2A: 0.5261  R1_A2I: 0.4768 mAP_A2I: 0.4155 
                     
iteration = 0 | loss = 2.654662 
iteration = 5 | loss = 2.544552 
iteration = 10 | loss = 2.899737 
iteration = 15 | loss = 3.223529 
iteration = 20 | loss = 2.097046 
iteration = 25 | loss = 2.644516 
iteration = 30 | loss = 2.639609 
iteration = 35 | loss = 2.734372 
iteration = 40 | loss = 2.133344 
iteration = 45 | loss = 2.364426 
iteration = 50 | loss = 2.966967 
iteration = 55 | loss = 2.839916 
iteration = 60 | loss = 2.360633 
iteration = 65 | loss = 2.852983 
iteration = 70 | loss = 2.785691 
iteration = 75 | loss = 2.542486 
iteration = 80 | loss = 2.431819 
iteration = 85 | loss = 2.509437 
iteration = 90 | loss = 2.643705 
iteration = 95 | loss = 2.303874 
iteration = 100 | loss = 2.478107 
iteration = 105 | loss = 2.795019 
iteration = 0 | loss = 2.636955 
iteration = 5 | loss = 2.037068 
iteration = 10 | loss = 2.544455 
iteration = 15 | loss = 2.820842 
iteration = 20 | loss = 3.055801 
iteration = 25 | loss = 2.508378 
iteration = 30 | loss = 2.648705 
iteration = 35 | loss = 2.867984 
iteration = 40 | loss = 2.688256 
iteration = 45 | loss = 2.509362 
iteration = 50 | loss = 2.643051 
iteration = 55 | loss = 2.877092 
iteration = 60 | loss = 2.600464 
iteration = 65 | loss = 2.643872 
iteration = 70 | loss = 2.022957 
iteration = 75 | loss = 2.394768 
iteration = 80 | loss = 2.536880 
iteration = 85 | loss = 2.069239 
iteration = 90 | loss = 2.731567 
iteration = 95 | loss = 2.667386 
iteration = 100 | loss = 2.656643 
iteration = 105 | loss = 2.425187 
iteration = 0 | loss = 2.719390 
iteration = 5 | loss = 2.977190 
iteration = 10 | loss = 2.260781 
iteration = 15 | loss = 2.575028 
iteration = 20 | loss = 2.051966 
iteration = 25 | loss = 2.256439 
iteration = 30 | loss = 2.707459 
iteration = 35 | loss = 2.530789 
iteration = 40 | loss = 2.246866 
iteration = 45 | loss = 2.786057 
iteration = 50 | loss = 2.190938 
iteration = 55 | loss = 2.624331 
iteration = 60 | loss = 2.066580 
iteration = 65 | loss = 2.469914 
iteration = 70 | loss = 2.647969 
iteration = 75 | loss = 2.532039 
iteration = 80 | loss = 2.772562 
iteration = 85 | loss = 2.033133 
iteration = 90 | loss = 2.688011 
iteration = 95 | loss = 2.930614 
iteration = 100 | loss = 2.364801 
iteration = 105 | loss = 2.591885 
iteration = 0 | loss = 2.520809 
iteration = 5 | loss = 2.553440 
iteration = 10 | loss = 2.257162 
iteration = 15 | loss = 2.981215 
iteration = 20 | loss = 2.060785 
iteration = 25 | loss = 2.339637 
iteration = 30 | loss = 2.596316 
iteration = 35 | loss = 2.720201 
iteration = 40 | loss = 2.731723 
iteration = 45 | loss = 1.963811 
iteration = 50 | loss = 2.719456 
iteration = 55 | loss = 2.146880 
iteration = 60 | loss = 2.479605 
iteration = 65 | loss = 2.946944 
iteration = 70 | loss = 2.661639 
iteration = 75 | loss = 2.571702 
iteration = 80 | loss = 2.389070 
iteration = 85 | loss = 2.529016 
iteration = 90 | loss = 2.304505 
iteration = 95 | loss = 2.713002 
iteration = 100 | loss = 2.583916 
iteration = 105 | loss = 1.999408 
iteration = 0 | loss = 2.228481 
iteration = 5 | loss = 2.012174 
iteration = 10 | loss = 1.766526 
iteration = 15 | loss = 2.600308 
iteration = 20 | loss = 2.486654 
iteration = 25 | loss = 2.223539 
iteration = 30 | loss = 2.819742 
iteration = 35 | loss = 2.623501 
iteration = 40 | loss = 2.648475 
iteration = 45 | loss = 2.789149 
iteration = 50 | loss = 2.758020 
iteration = 55 | loss = 2.610254 
iteration = 60 | loss = 2.686818 
iteration = 65 | loss = 2.435968 
iteration = 70 | loss = 2.220601 
iteration = 75 | loss = 2.770445 
iteration = 80 | loss = 2.486212 
iteration = 85 | loss = 2.476324 
iteration = 90 | loss = 2.513188 
iteration = 95 | loss = 2.599638 
iteration = 100 | loss = 2.544473 
iteration = 105 | loss = 2.075194 
 Epoch: [60] Loss: 3.2203  R1_I2A: 0.5801 R1_A2I: 0.4811 
                 
iteration = 0 | loss = 2.312681 
iteration = 5 | loss = 2.130048 
iteration = 10 | loss = 2.317358 
iteration = 15 | loss = 2.391296 
iteration = 20 | loss = 2.313036 
iteration = 25 | loss = 2.427019 
iteration = 30 | loss = 2.528396 
iteration = 35 | loss = 2.708601 
iteration = 40 | loss = 3.117860 
iteration = 45 | loss = 2.384280 
iteration = 50 | loss = 2.461080 
iteration = 55 | loss = 2.759317 
iteration = 60 | loss = 2.297660 
iteration = 65 | loss = 2.503724 
iteration = 70 | loss = 2.422807 
iteration = 75 | loss = 2.952305 
iteration = 80 | loss = 2.799540 
iteration = 85 | loss = 2.439842 
iteration = 90 | loss = 2.461933 
iteration = 95 | loss = 2.592595 
iteration = 100 | loss = 2.278301 
iteration = 105 | loss = 2.399593 
iteration = 0 | loss = 2.692779 
iteration = 5 | loss = 2.664901 
iteration = 10 | loss = 2.553344 
iteration = 15 | loss = 2.210413 
iteration = 20 | loss = 2.117941 
iteration = 25 | loss = 2.359794 
iteration = 30 | loss = 2.265220 
iteration = 35 | loss = 2.008591 
iteration = 40 | loss = 2.400467 
iteration = 45 | loss = 1.929352 
iteration = 50 | loss = 2.322410 
iteration = 55 | loss = 2.255608 
iteration = 60 | loss = 2.353687 
iteration = 65 | loss = 3.014863 
iteration = 70 | loss = 2.093714 
iteration = 75 | loss = 2.197258 
iteration = 80 | loss = 2.308339 
iteration = 85 | loss = 2.488423 
iteration = 90 | loss = 2.410561 
iteration = 95 | loss = 2.344226 
iteration = 100 | loss = 2.663533 
iteration = 105 | loss = 2.406689 
iteration = 0 | loss = 2.851871 
iteration = 5 | loss = 2.408582 
iteration = 10 | loss = 2.503429 
iteration = 15 | loss = 2.175502 
iteration = 20 | loss = 2.798642 
iteration = 25 | loss = 1.705783 
iteration = 30 | loss = 2.630138 
iteration = 35 | loss = 2.512832 
iteration = 40 | loss = 2.226451 
iteration = 45 | loss = 2.369967 
iteration = 50 | loss = 2.060365 
iteration = 55 | loss = 2.808218 
iteration = 60 | loss = 2.096912 
iteration = 65 | loss = 2.535768 
iteration = 70 | loss = 2.094724 
iteration = 75 | loss = 2.313277 
iteration = 80 | loss = 2.153492 
iteration = 85 | loss = 2.592044 
iteration = 90 | loss = 2.610359 
iteration = 95 | loss = 2.276650 
iteration = 100 | loss = 2.411749 
iteration = 105 | loss = 2.405619 
iteration = 0 | loss = 2.139723 
iteration = 5 | loss = 2.508147 
iteration = 10 | loss = 2.368937 
iteration = 15 | loss = 2.815454 
iteration = 20 | loss = 2.233388 
iteration = 25 | loss = 1.692993 
iteration = 30 | loss = 2.595468 
iteration = 35 | loss = 2.610019 
iteration = 40 | loss = 2.469962 
iteration = 45 | loss = 2.265678 
iteration = 50 | loss = 2.435748 
iteration = 55 | loss = 2.391717 
iteration = 60 | loss = 2.573525 
iteration = 65 | loss = 2.103298 
iteration = 70 | loss = 2.558541 
iteration = 75 | loss = 2.144747 
iteration = 80 | loss = 2.016133 
iteration = 85 | loss = 2.384228 
iteration = 90 | loss = 2.724998 
iteration = 95 | loss = 2.047822 
iteration = 100 | loss = 1.806839 
iteration = 105 | loss = 2.193430 
iteration = 0 | loss = 2.262322 
iteration = 5 | loss = 2.201834 
iteration = 10 | loss = 1.982029 
iteration = 15 | loss = 2.557789 
iteration = 20 | loss = 2.483912 
iteration = 25 | loss = 2.560075 
iteration = 30 | loss = 2.359699 
iteration = 35 | loss = 2.355492 
iteration = 40 | loss = 2.241952 
iteration = 45 | loss = 2.194718 
iteration = 50 | loss = 2.403948 
iteration = 55 | loss = 2.171375 
iteration = 60 | loss = 2.276549 
iteration = 65 | loss = 2.067686 
iteration = 70 | loss = 2.374584 
iteration = 75 | loss = 2.381776 
iteration = 80 | loss = 2.444374 
iteration = 85 | loss = 2.306535 
iteration = 90 | loss = 2.517121 
iteration = 95 | loss = 2.568055 
iteration = 100 | loss = 2.498163 
iteration = 105 | loss = 2.252746 
 Epoch: [65] Loss: 2.5784  R1_I2A: 0.5740 R1_A2I: 0.4719 
                 
iteration = 0 | loss = 2.293567 
iteration = 5 | loss = 2.576804 
iteration = 10 | loss = 2.484287 
iteration = 15 | loss = 2.228047 
iteration = 20 | loss = 2.029933 
iteration = 25 | loss = 2.861701 
iteration = 30 | loss = 2.597759 
iteration = 35 | loss = 2.519584 
iteration = 40 | loss = 2.016221 
iteration = 45 | loss = 2.382562 
iteration = 50 | loss = 2.356932 
iteration = 55 | loss = 2.619386 
iteration = 60 | loss = 2.116668 
iteration = 65 | loss = 2.502809 
iteration = 70 | loss = 2.138907 
iteration = 75 | loss = 1.970893 
iteration = 80 | loss = 2.524844 
iteration = 85 | loss = 2.289969 
iteration = 90 | loss = 2.450520 
iteration = 95 | loss = 2.205920 
iteration = 100 | loss = 2.933211 
iteration = 105 | loss = 2.137163 
iteration = 0 | loss = 1.881993 
iteration = 5 | loss = 2.312844 
iteration = 10 | loss = 2.474362 
iteration = 15 | loss = 2.388633 
iteration = 20 | loss = 2.083153 
iteration = 25 | loss = 2.498854 
iteration = 30 | loss = 2.184986 
iteration = 35 | loss = 2.418625 
iteration = 40 | loss = 1.977642 
iteration = 45 | loss = 2.084924 
iteration = 50 | loss = 2.135623 
iteration = 55 | loss = 2.659032 
iteration = 60 | loss = 1.982197 
iteration = 65 | loss = 2.055639 
iteration = 70 | loss = 2.397702 
iteration = 75 | loss = 2.747616 
iteration = 80 | loss = 2.103291 
iteration = 85 | loss = 2.276016 
iteration = 90 | loss = 2.591573 
iteration = 95 | loss = 2.367214 
iteration = 100 | loss = 2.587210 
iteration = 105 | loss = 2.225863 
iteration = 0 | loss = 2.242668 
iteration = 5 | loss = 2.037123 
iteration = 10 | loss = 2.238583 
iteration = 15 | loss = 2.427560 
iteration = 20 | loss = 2.545163 
iteration = 25 | loss = 2.389987 
iteration = 30 | loss = 2.153522 
iteration = 35 | loss = 2.276861 
iteration = 40 | loss = 2.085215 
iteration = 45 | loss = 2.444115 
iteration = 50 | loss = 2.556366 
iteration = 55 | loss = 2.218210 
iteration = 60 | loss = 1.984997 
iteration = 65 | loss = 2.205750 
iteration = 70 | loss = 2.319062 
iteration = 75 | loss = 2.101861 
iteration = 80 | loss = 2.509415 
iteration = 85 | loss = 2.520591 
iteration = 90 | loss = 2.195547 
iteration = 95 | loss = 2.090836 
iteration = 100 | loss = 2.709139 
iteration = 105 | loss = 2.608757 
iteration = 0 | loss = 2.021394 
iteration = 5 | loss = 2.356766 
iteration = 10 | loss = 2.855199 
iteration = 15 | loss = 2.238869 
iteration = 20 | loss = 2.043224 
iteration = 25 | loss = 2.066635 
iteration = 30 | loss = 2.675204 
iteration = 35 | loss = 2.260684 
iteration = 40 | loss = 2.534350 
iteration = 45 | loss = 2.236861 
iteration = 50 | loss = 2.359314 
iteration = 55 | loss = 2.292981 
iteration = 60 | loss = 2.033764 
iteration = 65 | loss = 2.177471 
iteration = 70 | loss = 2.133070 
iteration = 75 | loss = 1.963755 
iteration = 80 | loss = 2.271187 
iteration = 85 | loss = 1.989593 
iteration = 90 | loss = 2.097620 
iteration = 95 | loss = 1.881188 
iteration = 100 | loss = 2.582069 
iteration = 105 | loss = 2.571723 
iteration = 0 | loss = 2.041350 
iteration = 5 | loss = 2.363775 
iteration = 10 | loss = 2.210682 
iteration = 15 | loss = 2.420147 
iteration = 20 | loss = 2.282164 
iteration = 25 | loss = 2.501405 
iteration = 30 | loss = 2.606291 
iteration = 35 | loss = 2.519729 
iteration = 40 | loss = 2.406244 
iteration = 45 | loss = 2.221026 
iteration = 50 | loss = 2.395722 
iteration = 55 | loss = 2.254306 
iteration = 60 | loss = 2.612007 
iteration = 65 | loss = 2.056337 
iteration = 70 | loss = 2.046520 
iteration = 75 | loss = 2.452205 
iteration = 80 | loss = 2.235177 
iteration = 85 | loss = 2.213265 
iteration = 90 | loss = 2.480287 
iteration = 95 | loss = 2.049684 
iteration = 100 | loss = 2.177235 
iteration = 105 | loss = 2.525203 
 Epoch: [70] Loss: 2.3484  R1_I2A: 0.5766 R1_A2I: 0.4687 
                 
iteration = 0 | loss = 2.591437 
iteration = 5 | loss = 2.322615 
iteration = 10 | loss = 2.731129 
iteration = 15 | loss = 2.301529 
iteration = 20 | loss = 1.976458 
iteration = 25 | loss = 1.782740 
iteration = 30 | loss = 2.239671 
iteration = 35 | loss = 2.444059 
iteration = 40 | loss = 2.331643 
iteration = 45 | loss = 2.215786 
iteration = 50 | loss = 2.573400 
iteration = 55 | loss = 1.833090 
iteration = 60 | loss = 2.484148 
iteration = 65 | loss = 2.307691 
iteration = 70 | loss = 2.021032 
iteration = 75 | loss = 2.141902 
iteration = 80 | loss = 2.146039 
iteration = 85 | loss = 2.016368 
iteration = 90 | loss = 2.046826 
iteration = 95 | loss = 2.332682 
iteration = 100 | loss = 2.251178 
iteration = 105 | loss = 2.608181 
iteration = 0 | loss = 1.953535 
iteration = 5 | loss = 2.156136 
iteration = 10 | loss = 2.341781 
iteration = 15 | loss = 2.312245 
iteration = 20 | loss = 2.343929 
iteration = 25 | loss = 2.491697 
iteration = 30 | loss = 2.127020 
iteration = 35 | loss = 2.135842 
iteration = 40 | loss = 2.531175 
iteration = 45 | loss = 1.993964 
iteration = 50 | loss = 2.032445 
iteration = 55 | loss = 2.372884 
iteration = 60 | loss = 2.188770 
iteration = 65 | loss = 2.314995 
iteration = 70 | loss = 2.476860 
iteration = 75 | loss = 2.032019 
iteration = 80 | loss = 2.321004 
iteration = 85 | loss = 2.376275 
iteration = 90 | loss = 2.052019 
iteration = 95 | loss = 1.964601 
iteration = 100 | loss = 2.427687 
iteration = 105 | loss = 2.113382 
iteration = 0 | loss = 1.779743 
iteration = 5 | loss = 2.773312 
iteration = 10 | loss = 2.324610 
iteration = 15 | loss = 2.537328 
iteration = 20 | loss = 2.633242 
iteration = 25 | loss = 2.187644 
iteration = 30 | loss = 1.801869 
iteration = 35 | loss = 2.685678 
iteration = 40 | loss = 2.570550 
iteration = 45 | loss = 2.487224 
iteration = 50 | loss = 2.205622 
iteration = 55 | loss = 2.211407 
iteration = 60 | loss = 2.101920 
iteration = 65 | loss = 1.974867 
iteration = 70 | loss = 2.503998 
iteration = 75 | loss = 2.181651 
iteration = 80 | loss = 2.338312 
iteration = 85 | loss = 2.448636 
iteration = 90 | loss = 1.956832 
iteration = 95 | loss = 2.184602 
iteration = 100 | loss = 2.286026 
iteration = 105 | loss = 2.504729 
iteration = 0 | loss = 2.479581 
iteration = 5 | loss = 2.328956 
iteration = 10 | loss = 2.534858 
iteration = 15 | loss = 1.890819 
iteration = 20 | loss = 2.041650 
iteration = 25 | loss = 2.397117 
iteration = 30 | loss = 2.130187 
iteration = 35 | loss = 1.905581 
iteration = 40 | loss = 2.436586 
iteration = 45 | loss = 1.945852 
iteration = 50 | loss = 2.590916 
iteration = 55 | loss = 2.464854 
iteration = 60 | loss = 2.141920 
iteration = 65 | loss = 2.038200 
iteration = 70 | loss = 2.233398 
iteration = 75 | loss = 2.126741 
iteration = 80 | loss = 2.070528 
iteration = 85 | loss = 2.310227 
iteration = 90 | loss = 2.145360 
iteration = 95 | loss = 1.891893 
iteration = 100 | loss = 2.011095 
iteration = 105 | loss = 2.141114 
iteration = 0 | loss = 1.800138 
iteration = 5 | loss = 2.236012 
iteration = 10 | loss = 2.237864 
iteration = 15 | loss = 2.255074 
iteration = 20 | loss = 2.163268 
iteration = 25 | loss = 1.950001 
iteration = 30 | loss = 1.847371 
iteration = 35 | loss = 2.222104 
iteration = 40 | loss = 1.918613 
iteration = 45 | loss = 1.833694 
iteration = 50 | loss = 1.981838 
iteration = 55 | loss = 2.206926 
iteration = 60 | loss = 2.163425 
iteration = 65 | loss = 2.465038 
iteration = 70 | loss = 2.482438 
iteration = 75 | loss = 2.228070 
iteration = 80 | loss = 1.954009 
iteration = 85 | loss = 2.040430 
iteration = 90 | loss = 2.554756 
iteration = 95 | loss = 2.428225 
iteration = 100 | loss = 2.223982 
iteration = 105 | loss = 2.395447 
 Epoch: [75] Loss: 2.7046  R1_I2A: 0.5827 R1_A2I: 0.4570 
                 
iteration = 0 | loss = 2.072952 
iteration = 5 | loss = 2.020308 
iteration = 10 | loss = 2.259921 
iteration = 15 | loss = 2.161387 
iteration = 20 | loss = 1.956004 
iteration = 25 | loss = 1.892028 
iteration = 30 | loss = 1.950096 
iteration = 35 | loss = 2.060826 
iteration = 40 | loss = 2.269934 
iteration = 45 | loss = 2.230333 
iteration = 50 | loss = 2.092638 
iteration = 55 | loss = 2.126880 
iteration = 60 | loss = 2.198579 
iteration = 65 | loss = 2.414725 
iteration = 70 | loss = 2.476383 
iteration = 75 | loss = 2.196064 
iteration = 80 | loss = 2.214331 
iteration = 85 | loss = 2.099370 
iteration = 90 | loss = 2.041677 
iteration = 95 | loss = 2.459145 
iteration = 100 | loss = 2.142538 
iteration = 105 | loss = 2.080121 
iteration = 0 | loss = 2.095176 
iteration = 5 | loss = 1.845676 
iteration = 10 | loss = 1.838388 
iteration = 15 | loss = 2.178668 
iteration = 20 | loss = 1.730100 
iteration = 25 | loss = 2.277397 
iteration = 30 | loss = 1.906024 
iteration = 35 | loss = 2.290536 
iteration = 40 | loss = 2.581312 
iteration = 45 | loss = 1.831624 
iteration = 50 | loss = 2.211077 
iteration = 55 | loss = 2.282557 
iteration = 60 | loss = 1.977997 
iteration = 65 | loss = 2.235016 
iteration = 70 | loss = 1.969773 
iteration = 75 | loss = 2.210558 
iteration = 80 | loss = 1.952404 
iteration = 85 | loss = 2.072692 
iteration = 90 | loss = 1.952098 
iteration = 95 | loss = 2.117005 
iteration = 100 | loss = 2.168537 
iteration = 105 | loss = 2.199732 
iteration = 0 | loss = 2.062857 
iteration = 5 | loss = 1.882311 
iteration = 10 | loss = 2.011071 
iteration = 15 | loss = 2.037872 
iteration = 20 | loss = 1.935264 
iteration = 25 | loss = 1.741205 
iteration = 30 | loss = 2.378171 
iteration = 35 | loss = 1.682095 
iteration = 40 | loss = 2.171805 
iteration = 45 | loss = 1.721912 
iteration = 50 | loss = 2.323225 
iteration = 55 | loss = 1.924970 
iteration = 60 | loss = 1.928929 
iteration = 65 | loss = 2.016189 
iteration = 70 | loss = 1.907898 
iteration = 75 | loss = 2.383954 
iteration = 80 | loss = 1.822750 
iteration = 85 | loss = 2.013429 
iteration = 90 | loss = 2.041527 
iteration = 95 | loss = 2.299016 
iteration = 100 | loss = 1.887318 
iteration = 105 | loss = 2.078742 
iteration = 0 | loss = 1.808851 
iteration = 5 | loss = 2.674702 
iteration = 10 | loss = 2.239351 
iteration = 15 | loss = 1.801094 
iteration = 20 | loss = 2.196262 
iteration = 25 | loss = 1.977795 
iteration = 30 | loss = 1.960709 
iteration = 35 | loss = 2.014812 
iteration = 40 | loss = 1.670051 
iteration = 45 | loss = 1.891612 
iteration = 50 | loss = 2.087420 
iteration = 55 | loss = 2.258755 
iteration = 60 | loss = 1.884892 
iteration = 65 | loss = 2.398200 
iteration = 70 | loss = 1.863545 
iteration = 75 | loss = 2.119037 
iteration = 80 | loss = 2.351398 
iteration = 85 | loss = 1.964798 
iteration = 90 | loss = 2.259399 
iteration = 95 | loss = 1.833371 
iteration = 100 | loss = 2.103324 
iteration = 105 | loss = 1.879382 
iteration = 0 | loss = 2.055038 
iteration = 5 | loss = 1.839092 
iteration = 10 | loss = 2.158173 
iteration = 15 | loss = 2.259297 
iteration = 20 | loss = 1.866293 
iteration = 25 | loss = 2.369075 
iteration = 30 | loss = 1.999026 
iteration = 35 | loss = 2.040232 
iteration = 40 | loss = 2.055725 
iteration = 45 | loss = 1.575397 
iteration = 50 | loss = 1.772847 
iteration = 55 | loss = 2.146767 
iteration = 60 | loss = 2.401669 
iteration = 65 | loss = 2.007757 
iteration = 70 | loss = 1.696509 
iteration = 75 | loss = 2.042397 
iteration = 80 | loss = 2.040087 
iteration = 85 | loss = 2.519372 
iteration = 90 | loss = 2.024362 
iteration = 95 | loss = 1.699089 
iteration = 100 | loss = 2.052015 
iteration = 105 | loss = 2.044406 
 Epoch: [80] Loss: 2.1606  R1_I2A: 0.5567 R1_A2I: 0.4632 
                 
iteration = 0 | loss = 1.998425 
iteration = 5 | loss = 1.922850 
iteration = 10 | loss = 1.964608 
iteration = 15 | loss = 2.419209 
iteration = 20 | loss = 1.932210 
iteration = 25 | loss = 2.619634 
iteration = 30 | loss = 1.974524 
iteration = 35 | loss = 1.903130 
iteration = 40 | loss = 1.564657 
iteration = 45 | loss = 1.834440 
iteration = 50 | loss = 1.806066 
iteration = 55 | loss = 1.935645 
iteration = 60 | loss = 2.017363 
iteration = 65 | loss = 2.206317 
iteration = 70 | loss = 1.719043 
iteration = 75 | loss = 1.824291 
iteration = 80 | loss = 2.216084 
iteration = 85 | loss = 2.395871 
iteration = 90 | loss = 2.240959 
iteration = 95 | loss = 1.716383 
iteration = 100 | loss = 2.040404 
iteration = 105 | loss = 2.134786 

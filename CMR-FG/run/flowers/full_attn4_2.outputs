64 10.0
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 2.794710 
iteration = 5 | loss = 3.487799 
iteration = 10 | loss = 2.570541 
iteration = 15 | loss = 3.247008 
iteration = 20 | loss = 2.695296 
iteration = 25 | loss = 3.085892 
iteration = 30 | loss = 2.799789 
iteration = 35 | loss = 3.753383 
iteration = 40 | loss = 2.568929 
iteration = 45 | loss = 3.025880 
iteration = 50 | loss = 2.544536 
iteration = 55 | loss = 3.077692 
iteration = 60 | loss = 2.844289 
iteration = 65 | loss = 2.744257 
iteration = 70 | loss = 3.236146 
iteration = 75 | loss = 2.509915 
iteration = 80 | loss = 3.235467 
iteration = 85 | loss = 2.698512 
iteration = 90 | loss = 2.329656 
iteration = 95 | loss = 2.740193 
iteration = 100 | loss = 2.679401 
iteration = 105 | loss = 2.279315 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 2.426031 
iteration = 5 | loss = 2.635011 
iteration = 10 | loss = 2.589928 
iteration = 15 | loss = 2.630764 
iteration = 20 | loss = 2.773808 
iteration = 25 | loss = 3.072368 
iteration = 30 | loss = 2.666716 
iteration = 35 | loss = 3.048248 
iteration = 40 | loss = 2.791064 
iteration = 45 | loss = 2.751701 
iteration = 50 | loss = 2.450732 
iteration = 55 | loss = 2.432778 
iteration = 60 | loss = 2.546866 
iteration = 65 | loss = 2.871204 
iteration = 70 | loss = 2.574001 
iteration = 75 | loss = 3.133281 
iteration = 80 | loss = 3.013696 
iteration = 85 | loss = 2.521948 
iteration = 90 | loss = 2.849357 
iteration = 95 | loss = 2.527634 
iteration = 100 | loss = 3.164148 
iteration = 105 | loss = 3.168230 
iteration = 0 | loss = 2.690583 
iteration = 5 | loss = 2.558904 
iteration = 10 | loss = 2.348315 
iteration = 15 | loss = 3.248285 
iteration = 20 | loss = 2.578229 
iteration = 25 | loss = 2.480221 
iteration = 30 | loss = 2.643071 
iteration = 35 | loss = 2.301168 
iteration = 40 | loss = 3.477092 
iteration = 45 | loss = 3.046395 
iteration = 50 | loss = 2.658321 
iteration = 55 | loss = 2.761941 
iteration = 60 | loss = 2.634060 
iteration = 65 | loss = 2.363825 
iteration = 70 | loss = 2.917377 
iteration = 75 | loss = 2.667956 
iteration = 80 | loss = 2.854271 
iteration = 85 | loss = 3.239437 
iteration = 90 | loss = 2.511109 
iteration = 95 | loss = 2.697083 
iteration = 100 | loss = 3.072499 
iteration = 105 | loss = 2.672115 
iteration = 0 | loss = 2.082203 
iteration = 5 | loss = 2.708378 
iteration = 10 | loss = 2.740748 
iteration = 15 | loss = 2.549112 
iteration = 20 | loss = 2.828488 
iteration = 25 | loss = 2.115317 
iteration = 30 | loss = 2.412739 
iteration = 35 | loss = 2.295220 
iteration = 40 | loss = 2.567809 
iteration = 45 | loss = 3.084649 
iteration = 50 | loss = 2.682458 
iteration = 55 | loss = 2.726193 
iteration = 60 | loss = 3.121472 
iteration = 65 | loss = 2.803598 
iteration = 70 | loss = 2.779946 
iteration = 75 | loss = 2.739350 
iteration = 80 | loss = 3.052602 
iteration = 85 | loss = 2.494538 
iteration = 90 | loss = 3.090794 
iteration = 95 | loss = 3.100829 
iteration = 100 | loss = 2.922443 
iteration = 105 | loss = 2.875793 
iteration = 0 | loss = 2.766856 
iteration = 5 | loss = 2.641783 
iteration = 10 | loss = 2.231309 
iteration = 15 | loss = 2.790672 
iteration = 20 | loss = 3.258966 
iteration = 25 | loss = 2.548259 
iteration = 30 | loss = 2.888089 
iteration = 35 | loss = 2.541603 
iteration = 40 | loss = 3.054941 
iteration = 45 | loss = 2.900671 
iteration = 50 | loss = 2.917673 
iteration = 55 | loss = 2.760796 
iteration = 60 | loss = 2.833940 
iteration = 65 | loss = 2.345920 
iteration = 70 | loss = 2.488111 
iteration = 75 | loss = 2.700103 
iteration = 80 | loss = 2.882377 
iteration = 85 | loss = 2.886367 
iteration = 90 | loss = 2.509642 
iteration = 95 | loss = 2.285903 
iteration = 100 | loss = 2.505257 
iteration = 105 | loss = 2.257500 
 Epoch: [45] Loss: 2.5140  R1_I2A: 0.5991 R1_A2I: 0.4700 
                 
 Epoch: [45] Loss: 2.5140  R1_I2A: 0.6035 mAP_I2A: 0.5191  R1_A2I: 0.4700 mAP_A2I: 0.4139 
                     
iteration = 0 | loss = 2.569836 
iteration = 5 | loss = 3.050762 
iteration = 10 | loss = 2.814340 
iteration = 15 | loss = 2.200859 
iteration = 20 | loss = 2.241327 
iteration = 25 | loss = 2.630808 
iteration = 30 | loss = 2.842600 
iteration = 35 | loss = 2.810627 
iteration = 40 | loss = 2.337478 
iteration = 45 | loss = 3.020129 
iteration = 50 | loss = 2.468937 
iteration = 55 | loss = 3.310927 
iteration = 60 | loss = 2.781858 
iteration = 65 | loss = 2.290729 
iteration = 70 | loss = 2.526109 
iteration = 75 | loss = 3.199909 
iteration = 80 | loss = 2.513518 
iteration = 85 | loss = 2.908926 
iteration = 90 | loss = 2.704181 
iteration = 95 | loss = 2.612694 
iteration = 100 | loss = 2.642744 
iteration = 105 | loss = 3.045874 
iteration = 0 | loss = 2.564696 
iteration = 5 | loss = 2.488055 
iteration = 10 | loss = 2.256326 
iteration = 15 | loss = 2.307605 
iteration = 20 | loss = 2.538965 
iteration = 25 | loss = 2.365471 
iteration = 30 | loss = 3.055479 
iteration = 35 | loss = 2.476784 
iteration = 40 | loss = 2.304489 
iteration = 45 | loss = 2.824022 
iteration = 50 | loss = 2.416623 
iteration = 55 | loss = 2.775152 
iteration = 60 | loss = 2.391307 
iteration = 65 | loss = 2.134213 
iteration = 70 | loss = 3.016327 
iteration = 75 | loss = 2.685686 
iteration = 80 | loss = 2.300650 
iteration = 85 | loss = 2.350326 
iteration = 90 | loss = 2.283995 
iteration = 95 | loss = 3.017871 
iteration = 100 | loss = 2.721371 
iteration = 105 | loss = 3.008636 
iteration = 0 | loss = 2.371089 
iteration = 5 | loss = 2.368010 
iteration = 10 | loss = 2.716131 
iteration = 15 | loss = 2.605455 
iteration = 20 | loss = 2.898051 
iteration = 25 | loss = 2.669249 
iteration = 30 | loss = 2.383971 
iteration = 35 | loss = 2.674348 
iteration = 40 | loss = 2.308212 
iteration = 45 | loss = 2.900732 
iteration = 50 | loss = 2.463531 
iteration = 55 | loss = 2.226277 
iteration = 60 | loss = 2.435443 
iteration = 65 | loss = 2.963276 
iteration = 70 | loss = 2.747120 
iteration = 75 | loss = 2.167387 
iteration = 80 | loss = 2.600276 
iteration = 85 | loss = 3.204173 
iteration = 90 | loss = 2.182146 
iteration = 95 | loss = 2.512444 
iteration = 100 | loss = 2.447443 
iteration = 105 | loss = 2.803046 
iteration = 0 | loss = 2.298384 
iteration = 5 | loss = 2.551645 
iteration = 10 | loss = 2.544217 
iteration = 15 | loss = 2.778369 
iteration = 20 | loss = 2.633518 
iteration = 25 | loss = 2.359008 
iteration = 30 | loss = 2.580014 
iteration = 35 | loss = 2.830162 
iteration = 40 | loss = 2.841647 
iteration = 45 | loss = 2.199905 
iteration = 50 | loss = 2.640525 
iteration = 55 | loss = 2.195446 
iteration = 60 | loss = 2.384898 
iteration = 65 | loss = 2.847520 
iteration = 70 | loss = 2.414955 
iteration = 75 | loss = 2.427340 
iteration = 80 | loss = 2.451873 
iteration = 85 | loss = 2.413632 
iteration = 90 | loss = 2.180691 
iteration = 95 | loss = 2.238823 
iteration = 100 | loss = 2.956408 
iteration = 105 | loss = 2.921071 
iteration = 0 | loss = 2.664330 
iteration = 5 | loss = 2.183270 
iteration = 10 | loss = 2.641614 
iteration = 15 | loss = 2.719060 
iteration = 20 | loss = 2.644511 
iteration = 25 | loss = 2.408064 
iteration = 30 | loss = 2.479166 
iteration = 35 | loss = 2.413676 
iteration = 40 | loss = 2.597195 
iteration = 45 | loss = 2.754524 
iteration = 50 | loss = 2.251136 
iteration = 55 | loss = 2.535456 
iteration = 60 | loss = 2.276538 
iteration = 65 | loss = 2.175660 
iteration = 70 | loss = 2.469361 
iteration = 75 | loss = 2.438686 
iteration = 80 | loss = 2.507358 
iteration = 85 | loss = 2.207464 
iteration = 90 | loss = 2.423741 
iteration = 95 | loss = 2.694616 
iteration = 100 | loss = 2.030234 
iteration = 105 | loss = 2.369402 
 Epoch: [50] Loss: 2.8311  R1_I2A: 0.5835 R1_A2I: 0.4747 
                 
iteration = 0 | loss = 2.857158 
iteration = 5 | loss = 2.739660 
iteration = 10 | loss = 2.561246 
iteration = 15 | loss = 2.764889 
iteration = 20 | loss = 2.249655 
iteration = 25 | loss = 2.345049 
iteration = 30 | loss = 2.077513 
iteration = 35 | loss = 2.406860 
iteration = 40 | loss = 2.773055 
iteration = 45 | loss = 2.674405 
iteration = 50 | loss = 1.964703 
iteration = 55 | loss = 2.250257 
iteration = 60 | loss = 2.323519 
iteration = 65 | loss = 2.719305 
iteration = 70 | loss = 2.473898 
iteration = 75 | loss = 1.907197 
iteration = 80 | loss = 1.991097 
iteration = 85 | loss = 2.855351 
iteration = 90 | loss = 2.586342 
iteration = 95 | loss = 2.414216 
iteration = 100 | loss = 2.123471 
iteration = 105 | loss = 2.720766 
iteration = 0 | loss = 1.995535 
iteration = 5 | loss = 2.444251 
iteration = 10 | loss = 3.009764 
iteration = 15 | loss = 2.416024 
iteration = 20 | loss = 2.287837 
iteration = 25 | loss = 2.497083 
iteration = 30 | loss = 2.588987 
iteration = 35 | loss = 2.409020 
iteration = 40 | loss = 2.092979 
iteration = 45 | loss = 2.171690 
iteration = 50 | loss = 1.901397 
iteration = 55 | loss = 2.408218 
iteration = 60 | loss = 2.683505 
iteration = 65 | loss = 2.607983 
iteration = 70 | loss = 2.680658 
iteration = 75 | loss = 2.158262 
iteration = 80 | loss = 2.122115 
iteration = 85 | loss = 2.152272 
iteration = 90 | loss = 2.664953 
iteration = 95 | loss = 3.229370 
iteration = 100 | loss = 2.402948 
iteration = 105 | loss = 2.323841 
iteration = 0 | loss = 2.491903 
iteration = 5 | loss = 2.324017 
iteration = 10 | loss = 2.033142 
iteration = 15 | loss = 1.953506 
iteration = 20 | loss = 2.130929 
iteration = 25 | loss = 2.455984 
iteration = 30 | loss = 2.391804 
iteration = 35 | loss = 2.411203 
iteration = 40 | loss = 2.043117 
iteration = 45 | loss = 2.324756 
iteration = 50 | loss = 1.872253 
iteration = 55 | loss = 2.568895 
iteration = 60 | loss = 2.251999 
iteration = 65 | loss = 2.403107 
iteration = 70 | loss = 2.506492 
iteration = 75 | loss = 1.980490 
iteration = 80 | loss = 1.819189 
iteration = 85 | loss = 2.316316 
iteration = 90 | loss = 2.861091 
iteration = 95 | loss = 2.620406 
iteration = 100 | loss = 3.156875 
iteration = 105 | loss = 2.451130 
iteration = 0 | loss = 2.469251 
iteration = 5 | loss = 2.043221 
iteration = 10 | loss = 2.641381 
iteration = 15 | loss = 2.754440 
iteration = 20 | loss = 2.446644 
iteration = 25 | loss = 2.202426 
iteration = 30 | loss = 2.427029 
iteration = 35 | loss = 2.406675 
iteration = 40 | loss = 2.358399 
iteration = 45 | loss = 2.455340 
iteration = 50 | loss = 2.106251 
iteration = 55 | loss = 2.308027 
iteration = 60 | loss = 2.530650 
iteration = 65 | loss = 2.220389 
iteration = 70 | loss = 2.861824 
iteration = 75 | loss = 1.946827 
iteration = 80 | loss = 2.469752 
iteration = 85 | loss = 2.628207 
iteration = 90 | loss = 2.475782 
iteration = 95 | loss = 2.042737 
iteration = 100 | loss = 2.037177 
iteration = 105 | loss = 2.658927 
iteration = 0 | loss = 2.230403 
iteration = 5 | loss = 2.468693 
iteration = 10 | loss = 2.472517 
iteration = 15 | loss = 2.838041 
iteration = 20 | loss = 2.227107 
iteration = 25 | loss = 1.878107 
iteration = 30 | loss = 1.829788 
iteration = 35 | loss = 2.632790 
iteration = 40 | loss = 1.948127 
iteration = 45 | loss = 2.578204 
iteration = 50 | loss = 2.467428 
iteration = 55 | loss = 2.200203 
iteration = 60 | loss = 2.474910 
iteration = 65 | loss = 2.782064 
iteration = 70 | loss = 2.605689 
iteration = 75 | loss = 2.478768 
iteration = 80 | loss = 2.077420 
iteration = 85 | loss = 2.422057 
iteration = 90 | loss = 2.612870 
iteration = 95 | loss = 2.561762 
iteration = 100 | loss = 2.511902 
iteration = 105 | loss = 1.900228 
 Epoch: [55] Loss: 2.2655  R1_I2A: 0.5810 R1_A2I: 0.4745 
                 
iteration = 0 | loss = 2.535863 
iteration = 5 | loss = 1.855243 
iteration = 10 | loss = 2.472173 
iteration = 15 | loss = 1.927447 
iteration = 20 | loss = 2.053948 
iteration = 25 | loss = 1.973804 
iteration = 30 | loss = 2.789879 
iteration = 35 | loss = 2.506729 
iteration = 40 | loss = 2.249258 
iteration = 45 | loss = 2.137801 
iteration = 50 | loss = 2.750988 
iteration = 55 | loss = 2.542533 
iteration = 60 | loss = 2.333122 
iteration = 65 | loss = 2.079950 
iteration = 70 | loss = 2.398204 
iteration = 75 | loss = 2.503652 
iteration = 80 | loss = 2.010254 
iteration = 85 | loss = 2.824183 
iteration = 90 | loss = 2.667766 
iteration = 95 | loss = 2.345631 
iteration = 100 | loss = 2.599946 
iteration = 105 | loss = 1.976443 
iteration = 0 | loss = 2.215015 
iteration = 5 | loss = 2.231945 
iteration = 10 | loss = 2.282281 
iteration = 15 | loss = 2.026244 
iteration = 20 | loss = 2.291189 
iteration = 25 | loss = 2.480401 
iteration = 30 | loss = 2.261146 
iteration = 35 | loss = 2.170034 
iteration = 40 | loss = 2.008728 
iteration = 45 | loss = 2.462526 
iteration = 50 | loss = 2.383152 
iteration = 55 | loss = 2.422856 
iteration = 60 | loss = 1.972048 
iteration = 65 | loss = 2.377349 
iteration = 70 | loss = 2.345860 
iteration = 75 | loss = 2.308302 
iteration = 80 | loss = 2.169186 
iteration = 85 | loss = 2.326955 
iteration = 90 | loss = 2.805889 
iteration = 95 | loss = 2.184818 
iteration = 100 | loss = 1.950684 
iteration = 105 | loss = 2.277978 
iteration = 0 | loss = 2.151018 
iteration = 5 | loss = 2.411359 
iteration = 10 | loss = 2.128066 
iteration = 15 | loss = 2.140017 
iteration = 20 | loss = 2.386145 
iteration = 25 | loss = 2.392116 
iteration = 30 | loss = 2.016111 
iteration = 35 | loss = 2.111572 
iteration = 40 | loss = 2.538683 
iteration = 45 | loss = 2.885306 
iteration = 50 | loss = 2.637093 
iteration = 55 | loss = 2.888627 
iteration = 60 | loss = 2.361869 
iteration = 65 | loss = 1.841511 
iteration = 70 | loss = 2.294580 
iteration = 75 | loss = 2.017561 
iteration = 80 | loss = 3.152495 
iteration = 85 | loss = 2.482416 
iteration = 90 | loss = 2.271815 
iteration = 95 | loss = 1.917836 
iteration = 100 | loss = 2.587020 
iteration = 105 | loss = 1.775348 
iteration = 0 | loss = 2.513853 
iteration = 5 | loss = 1.911121 
iteration = 10 | loss = 2.676443 
iteration = 15 | loss = 2.486290 
iteration = 20 | loss = 2.651233 
iteration = 25 | loss = 2.059512 
iteration = 30 | loss = 2.199872 
iteration = 35 | loss = 2.466028 
iteration = 40 | loss = 2.212182 
iteration = 45 | loss = 2.298903 
iteration = 50 | loss = 2.193877 
iteration = 55 | loss = 1.978003 
iteration = 60 | loss = 1.743653 
iteration = 65 | loss = 1.881483 
iteration = 70 | loss = 2.077054 
iteration = 75 | loss = 2.211585 
iteration = 80 | loss = 2.680504 
iteration = 85 | loss = 2.494691 
iteration = 90 | loss = 2.268680 
iteration = 95 | loss = 2.473047 
iteration = 100 | loss = 2.290759 
iteration = 105 | loss = 2.008348 
iteration = 0 | loss = 2.271019 
iteration = 5 | loss = 2.321366 
iteration = 10 | loss = 2.342189 
iteration = 15 | loss = 2.396530 
iteration = 20 | loss = 1.930462 
iteration = 25 | loss = 1.900099 
iteration = 30 | loss = 2.018829 
iteration = 35 | loss = 2.260342 
iteration = 40 | loss = 1.898368 
iteration = 45 | loss = 2.185828 
iteration = 50 | loss = 2.089695 
iteration = 55 | loss = 2.695817 
iteration = 60 | loss = 1.983229 
iteration = 65 | loss = 2.651038 
iteration = 70 | loss = 2.186293 
iteration = 75 | loss = 2.076891 
iteration = 80 | loss = 2.042764 
iteration = 85 | loss = 1.640974 
iteration = 90 | loss = 2.399613 
iteration = 95 | loss = 2.523778 
iteration = 100 | loss = 2.535599 
iteration = 105 | loss = 2.046789 
 Epoch: [60] Loss: 2.4086  R1_I2A: 0.5766 R1_A2I: 0.4777 
                 
iteration = 0 | loss = 2.477074 
iteration = 5 | loss = 2.362874 
iteration = 10 | loss = 1.876885 
iteration = 15 | loss = 2.017989 
iteration = 20 | loss = 2.052111 
iteration = 25 | loss = 2.137091 
iteration = 30 | loss = 2.428895 
iteration = 35 | loss = 2.311146 
iteration = 40 | loss = 2.300241 
iteration = 45 | loss = 1.917894 
iteration = 50 | loss = 2.197080 
iteration = 55 | loss = 2.547047 
iteration = 60 | loss = 2.311716 
iteration = 65 | loss = 2.099536 
iteration = 70 | loss = 2.060460 
iteration = 75 | loss = 1.722990 
iteration = 80 | loss = 2.079032 
iteration = 85 | loss = 2.262652 
iteration = 90 | loss = 2.463580 
iteration = 95 | loss = 2.380532 
iteration = 100 | loss = 2.306699 
iteration = 105 | loss = 1.912379 
iteration = 0 | loss = 1.904358 
iteration = 5 | loss = 2.285024 
iteration = 10 | loss = 2.577926 
iteration = 15 | loss = 1.795450 
iteration = 20 | loss = 2.137990 
iteration = 25 | loss = 1.915314 
iteration = 30 | loss = 1.746830 
iteration = 35 | loss = 2.211704 
iteration = 40 | loss = 1.980510 
iteration = 45 | loss = 1.878042 
iteration = 50 | loss = 1.791028 
iteration = 55 | loss = 1.653305 
iteration = 60 | loss = 2.111627 
iteration = 65 | loss = 2.263859 
iteration = 70 | loss = 1.987895 
iteration = 75 | loss = 2.483190 
iteration = 80 | loss = 2.237887 
iteration = 85 | loss = 2.515355 
iteration = 90 | loss = 2.689774 
iteration = 95 | loss = 1.984976 
iteration = 100 | loss = 2.299814 
iteration = 105 | loss = 2.433470 
iteration = 0 | loss = 1.827707 
iteration = 5 | loss = 2.425220 
iteration = 10 | loss = 1.886936 
iteration = 15 | loss = 2.440009 
iteration = 20 | loss = 1.944579 
iteration = 25 | loss = 2.155332 
iteration = 30 | loss = 2.008082 
iteration = 35 | loss = 2.691848 
iteration = 40 | loss = 2.225702 
iteration = 45 | loss = 2.190049 
iteration = 50 | loss = 2.443738 
iteration = 55 | loss = 2.210582 
iteration = 60 | loss = 1.725994 
iteration = 65 | loss = 2.058785 
iteration = 70 | loss = 2.516034 
iteration = 75 | loss = 2.191606 
iteration = 80 | loss = 2.018290 
iteration = 85 | loss = 2.264463 
iteration = 90 | loss = 2.049653 
iteration = 95 | loss = 1.875890 
iteration = 100 | loss = 2.449523 
iteration = 105 | loss = 1.865555 
iteration = 0 | loss = 1.862551 
iteration = 5 | loss = 1.935979 
iteration = 10 | loss = 2.746220 
iteration = 15 | loss = 1.409750 
iteration = 20 | loss = 1.959629 
iteration = 25 | loss = 2.254468 
iteration = 30 | loss = 1.584599 
iteration = 35 | loss = 1.964752 
iteration = 40 | loss = 1.661521 
iteration = 45 | loss = 2.171676 
iteration = 50 | loss = 2.463948 
iteration = 55 | loss = 2.100367 
iteration = 60 | loss = 1.654005 
iteration = 65 | loss = 1.945260 
iteration = 70 | loss = 2.205389 
iteration = 75 | loss = 2.415988 
iteration = 80 | loss = 2.530230 
iteration = 85 | loss = 2.247551 
iteration = 90 | loss = 2.641429 
iteration = 95 | loss = 2.241300 
iteration = 100 | loss = 2.281618 
iteration = 105 | loss = 1.838884 
iteration = 0 | loss = 1.942878 
iteration = 5 | loss = 2.329475 
iteration = 10 | loss = 2.129381 
iteration = 15 | loss = 2.412652 
iteration = 20 | loss = 2.386569 
iteration = 25 | loss = 2.268048 
iteration = 30 | loss = 1.728970 
iteration = 35 | loss = 2.055844 
iteration = 40 | loss = 1.931945 
iteration = 45 | loss = 2.295923 
iteration = 50 | loss = 1.934490 
iteration = 55 | loss = 1.750765 
iteration = 60 | loss = 1.867951 
iteration = 65 | loss = 2.125331 
iteration = 70 | loss = 2.206066 
iteration = 75 | loss = 2.301197 
iteration = 80 | loss = 2.096890 
iteration = 85 | loss = 1.967641 
iteration = 90 | loss = 2.049248 
iteration = 95 | loss = 2.060648 
iteration = 100 | loss = 2.161726 
iteration = 105 | loss = 2.137891 
 Epoch: [65] Loss: 1.9916  R1_I2A: 0.5723 R1_A2I: 0.4693 
                 
iteration = 0 | loss = 1.829874 
iteration = 5 | loss = 2.018513 
iteration = 10 | loss = 2.438590 
iteration = 15 | loss = 1.772084 
iteration = 20 | loss = 1.632323 
iteration = 25 | loss = 2.141678 
iteration = 30 | loss = 2.107665 
iteration = 35 | loss = 2.246304 
iteration = 40 | loss = 1.523932 
iteration = 45 | loss = 2.276675 
iteration = 50 | loss = 1.947878 
iteration = 55 | loss = 2.132127 
iteration = 60 | loss = 1.923324 
iteration = 65 | loss = 2.308825 
iteration = 70 | loss = 2.160959 
iteration = 75 | loss = 2.221942 
iteration = 80 | loss = 2.201421 
iteration = 85 | loss = 1.885872 
iteration = 90 | loss = 2.029400 
iteration = 95 | loss = 2.250513 
iteration = 100 | loss = 1.713948 
iteration = 105 | loss = 1.709973 
iteration = 0 | loss = 1.767973 
iteration = 5 | loss = 2.033475 
iteration = 10 | loss = 1.968820 
iteration = 15 | loss = 1.998436 
iteration = 20 | loss = 2.073907 
iteration = 25 | loss = 1.951722 
iteration = 30 | loss = 2.141165 
iteration = 35 | loss = 2.145796 
iteration = 40 | loss = 1.618236 
iteration = 45 | loss = 1.593914 
iteration = 50 | loss = 1.828298 
iteration = 55 | loss = 2.165990 
iteration = 60 | loss = 1.961028 
iteration = 65 | loss = 1.631648 
iteration = 70 | loss = 1.907901 
iteration = 75 | loss = 2.333281 
iteration = 80 | loss = 1.983267 
iteration = 85 | loss = 1.598856 
iteration = 90 | loss = 2.562482 
iteration = 95 | loss = 2.065767 
iteration = 100 | loss = 1.394009 
iteration = 105 | loss = 2.469428 
iteration = 0 | loss = 2.022124 
iteration = 5 | loss = 2.136068 
iteration = 10 | loss = 1.738168 
iteration = 15 | loss = 1.977889 
iteration = 20 | loss = 2.185998 
iteration = 25 | loss = 1.712863 
iteration = 30 | loss = 1.867181 
iteration = 35 | loss = 2.418159 
iteration = 40 | loss = 2.115296 
iteration = 45 | loss = 2.245432 
iteration = 50 | loss = 2.141525 
iteration = 55 | loss = 1.747165 
iteration = 60 | loss = 1.851671 
iteration = 65 | loss = 1.783525 
iteration = 70 | loss = 1.913833 
iteration = 75 | loss = 1.793099 
iteration = 80 | loss = 1.838535 
iteration = 85 | loss = 2.046429 
iteration = 90 | loss = 1.838960 
iteration = 95 | loss = 1.937179 
iteration = 100 | loss = 1.899536 
iteration = 105 | loss = 2.060387 
iteration = 0 | loss = 1.864820 
iteration = 5 | loss = 2.031260 
iteration = 10 | loss = 1.621992 
iteration = 15 | loss = 1.885911 
iteration = 20 | loss = 1.881089 
iteration = 25 | loss = 1.739991 
iteration = 30 | loss = 1.659262 
iteration = 35 | loss = 2.069675 
iteration = 40 | loss = 1.958812 
iteration = 45 | loss = 2.050398 
iteration = 50 | loss = 1.840472 
iteration = 55 | loss = 1.724083 
iteration = 60 | loss = 1.992711 
iteration = 65 | loss = 1.926634 
iteration = 70 | loss = 1.939479 
iteration = 75 | loss = 1.837574 
iteration = 80 | loss = 1.533457 
iteration = 85 | loss = 2.049350 
iteration = 90 | loss = 1.628736 
iteration = 95 | loss = 2.121626 
iteration = 100 | loss = 1.568671 
iteration = 105 | loss = 1.729239 
iteration = 0 | loss = 1.684702 
iteration = 5 | loss = 1.999417 
iteration = 10 | loss = 1.839816 
iteration = 15 | loss = 1.867992 
iteration = 20 | loss = 1.870321 
iteration = 25 | loss = 1.784508 
iteration = 30 | loss = 1.750817 
iteration = 35 | loss = 1.957641 
iteration = 40 | loss = 1.504193 
iteration = 45 | loss = 1.625160 
iteration = 50 | loss = 1.748921 
iteration = 55 | loss = 2.039099 
iteration = 60 | loss = 2.028437 
iteration = 65 | loss = 2.091367 
iteration = 70 | loss = 1.671780 
iteration = 75 | loss = 1.746768 
iteration = 80 | loss = 1.584663 
iteration = 85 | loss = 1.872785 
iteration = 90 | loss = 1.861360 
iteration = 95 | loss = 1.762010 
iteration = 100 | loss = 1.707047 
iteration = 105 | loss = 1.837482 
 Epoch: [70] Loss: 2.2068  R1_I2A: 0.5723 R1_A2I: 0.4690 
                 
iteration = 0 | loss = 1.745121 
iteration = 5 | loss = 2.046458 
iteration = 10 | loss = 1.475589 
iteration = 15 | loss = 1.715592 
iteration = 20 | loss = 2.041586 
iteration = 25 | loss = 1.803958 
iteration = 30 | loss = 1.555036 
iteration = 35 | loss = 1.871323 
iteration = 40 | loss = 1.782467 
iteration = 45 | loss = 1.882811 
iteration = 50 | loss = 1.763986 
iteration = 55 | loss = 2.111897 
iteration = 60 | loss = 2.036928 
iteration = 65 | loss = 1.898002 
iteration = 70 | loss = 1.534929 
iteration = 75 | loss = 2.261256 
iteration = 80 | loss = 1.773657 
iteration = 85 | loss = 2.053379 
iteration = 90 | loss = 2.015174 
iteration = 95 | loss = 1.647927 
iteration = 100 | loss = 1.945288 
iteration = 105 | loss = 1.661561 
iteration = 0 | loss = 1.875935 
iteration = 5 | loss = 1.941468 
iteration = 10 | loss = 1.910374 
iteration = 15 | loss = 1.969997 
iteration = 20 | loss = 1.888263 
iteration = 25 | loss = 1.990630 
iteration = 30 | loss = 1.915131 
iteration = 35 | loss = 1.910383 
iteration = 40 | loss = 2.084985 
iteration = 45 | loss = 1.893066 
iteration = 50 | loss = 1.709273 
iteration = 55 | loss = 1.675853 
iteration = 60 | loss = 1.773624 
iteration = 65 | loss = 1.487222 
iteration = 70 | loss = 1.560300 
iteration = 75 | loss = 1.649655 
iteration = 80 | loss = 1.735866 
iteration = 85 | loss = 1.528750 
iteration = 90 | loss = 2.111119 
iteration = 95 | loss = 2.030933 
iteration = 100 | loss = 1.797492 
iteration = 105 | loss = 1.856785 
iteration = 0 | loss = 2.014858 
iteration = 5 | loss = 1.984051 
iteration = 10 | loss = 1.714860 
iteration = 15 | loss = 2.105470 
iteration = 20 | loss = 1.593152 
iteration = 25 | loss = 1.788603 
iteration = 30 | loss = 2.037011 
iteration = 35 | loss = 1.453649 
iteration = 40 | loss = 1.842859 
iteration = 45 | loss = 1.793851 
iteration = 50 | loss = 2.153307 
iteration = 55 | loss = 1.895934 
iteration = 60 | loss = 1.381534 
iteration = 65 | loss = 1.673940 
iteration = 70 | loss = 2.428331 
iteration = 75 | loss = 2.071900 
iteration = 80 | loss = 1.794824 
iteration = 85 | loss = 1.636193 
iteration = 90 | loss = 1.712355 
iteration = 95 | loss = 1.801226 
iteration = 100 | loss = 1.959817 
iteration = 105 | loss = 1.686069 
iteration = 0 | loss = 1.978174 
iteration = 5 | loss = 1.627165 
iteration = 10 | loss = 2.187088 
iteration = 15 | loss = 2.226849 
iteration = 20 | loss = 1.912752 
iteration = 25 | loss = 1.618306 
iteration = 30 | loss = 1.580556 
iteration = 35 | loss = 1.879036 
iteration = 40 | loss = 1.920257 
iteration = 45 | loss = 1.940912 
iteration = 50 | loss = 1.698756 
iteration = 55 | loss = 1.204849 
iteration = 60 | loss = 1.726552 
iteration = 65 | loss = 1.753813 
iteration = 70 | loss = 1.425933 
iteration = 75 | loss = 1.463034 
iteration = 80 | loss = 1.910276 
iteration = 85 | loss = 1.603237 
iteration = 90 | loss = 1.963490 
iteration = 95 | loss = 2.140361 
iteration = 100 | loss = 1.670247 
iteration = 105 | loss = 1.993845 
iteration = 0 | loss = 1.779009 
iteration = 5 | loss = 1.656442 
iteration = 10 | loss = 1.751417 
iteration = 15 | loss = 2.003417 
iteration = 20 | loss = 2.200198 
iteration = 25 | loss = 1.685701 
iteration = 30 | loss = 1.727834 
iteration = 35 | loss = 1.643304 
iteration = 40 | loss = 1.701506 
iteration = 45 | loss = 1.768393 
iteration = 50 | loss = 1.848551 
iteration = 55 | loss = 1.887484 
iteration = 60 | loss = 1.675166 
iteration = 65 | loss = 1.683211 
iteration = 70 | loss = 2.018600 
iteration = 75 | loss = 1.842751 
iteration = 80 | loss = 1.655849 
iteration = 85 | loss = 1.364956 
iteration = 90 | loss = 1.798482 
iteration = 95 | loss = 2.514090 
iteration = 100 | loss = 1.776681 
iteration = 105 | loss = 1.824788 
 Epoch: [75] Loss: 1.4640  R1_I2A: 0.5740 R1_A2I: 0.4611 
                 
iteration = 0 | loss = 2.066039 
iteration = 5 | loss = 1.907218 
iteration = 10 | loss = 2.113514 
iteration = 15 | loss = 1.845769 
iteration = 20 | loss = 2.116319 
iteration = 25 | loss = 1.781064 
iteration = 30 | loss = 1.891125 
iteration = 35 | loss = 1.835288 
iteration = 40 | loss = 1.564259 
iteration = 45 | loss = 2.027224 
iteration = 50 | loss = 1.542818 
iteration = 55 | loss = 1.959579 
iteration = 60 | loss = 1.664088 
iteration = 65 | loss = 1.871961 
iteration = 70 | loss = 1.872522 
iteration = 75 | loss = 2.048447 
iteration = 80 | loss = 1.961292 
iteration = 85 | loss = 2.217726 
iteration = 90 | loss = 1.607012 
iteration = 95 | loss = 2.319096 
iteration = 100 | loss = 1.714725 
iteration = 105 | loss = 2.142782 
iteration = 0 | loss = 2.198242 
iteration = 5 | loss = 2.010035 
iteration = 10 | loss = 1.836163 
iteration = 15 | loss = 2.166399 
iteration = 20 | loss = 2.128924 
iteration = 25 | loss = 1.741181 
iteration = 30 | loss = 1.947845 
iteration = 35 | loss = 2.079533 
iteration = 40 | loss = 1.735398 
iteration = 45 | loss = 2.115469 
iteration = 50 | loss = 1.710163 
iteration = 55 | loss = 2.168710 
iteration = 60 | loss = 2.120563 
iteration = 65 | loss = 2.292494 
iteration = 70 | loss = 1.875983 
iteration = 75 | loss = 2.084135 
iteration = 80 | loss = 2.114355 
iteration = 85 | loss = 2.316870 
iteration = 90 | loss = 2.068054 
iteration = 95 | loss = 2.141706 
iteration = 100 | loss = 1.622426 
iteration = 105 | loss = 2.057325 
iteration = 0 | loss = 1.887565 
iteration = 5 | loss = 2.193412 
iteration = 10 | loss = 2.300159 
iteration = 15 | loss = 1.922270 
iteration = 20 | loss = 1.979445 
iteration = 25 | loss = 1.989075 
iteration = 30 | loss = 1.944255 
iteration = 35 | loss = 2.269532 
iteration = 40 | loss = 1.878552 
iteration = 45 | loss = 2.250532 
iteration = 50 | loss = 1.643802 
iteration = 55 | loss = 2.052388 
iteration = 60 | loss = 2.047329 
iteration = 65 | loss = 1.585398 
iteration = 70 | loss = 1.802768 
iteration = 75 | loss = 1.893867 
iteration = 80 | loss = 2.003468 
iteration = 85 | loss = 1.841885 
iteration = 90 | loss = 1.508036 
iteration = 95 | loss = 1.951537 
iteration = 100 | loss = 1.994161 
iteration = 105 | loss = 1.653098 
iteration = 0 | loss = 1.900116 
iteration = 5 | loss = 2.358435 
iteration = 10 | loss = 1.725243 
iteration = 15 | loss = 1.870736 
iteration = 20 | loss = 1.516600 
iteration = 25 | loss = 1.939554 
iteration = 30 | loss = 1.722769 
iteration = 35 | loss = 2.029539 
iteration = 40 | loss = 1.937460 
iteration = 45 | loss = 1.824422 
iteration = 50 | loss = 1.671337 
iteration = 55 | loss = 1.733350 
iteration = 60 | loss = 1.583313 
iteration = 65 | loss = 2.030932 
iteration = 70 | loss = 2.009637 
iteration = 75 | loss = 2.310215 
iteration = 80 | loss = 1.890444 
iteration = 85 | loss = 1.892664 
iteration = 90 | loss = 1.942045 
iteration = 95 | loss = 1.679052 
iteration = 100 | loss = 1.565017 
iteration = 105 | loss = 1.751554 
iteration = 0 | loss = 1.633803 
iteration = 5 | loss = 1.703646 
iteration = 10 | loss = 2.133920 
iteration = 15 | loss = 1.810707 
iteration = 20 | loss = 1.925541 
iteration = 25 | loss = 1.700327 
iteration = 30 | loss = 2.228890 
iteration = 35 | loss = 1.543382 
iteration = 40 | loss = 1.791143 
iteration = 45 | loss = 1.874096 
iteration = 50 | loss = 2.118572 
iteration = 55 | loss = 1.960161 
iteration = 60 | loss = 1.857577 
iteration = 65 | loss = 2.439574 
iteration = 70 | loss = 1.988845 
iteration = 75 | loss = 1.664340 
iteration = 80 | loss = 2.047961 
iteration = 85 | loss = 1.742303 
iteration = 90 | loss = 1.299448 
iteration = 95 | loss = 1.499360 
iteration = 100 | loss = 1.955031 
iteration = 105 | loss = 2.028691 
 Epoch: [80] Loss: 2.1958  R1_I2A: 0.5922 R1_A2I: 0.4649 
                 
iteration = 0 | loss = 2.023323 
iteration = 5 | loss = 1.764746 
iteration = 10 | loss = 1.791144 
iteration = 15 | loss = 2.014424 
iteration = 20 | loss = 2.138106 
iteration = 25 | loss = 1.887584 
iteration = 30 | loss = 1.996608 
iteration = 35 | loss = 1.697796 
iteration = 40 | loss = 1.564045 
iteration = 45 | loss = 2.305071 
iteration = 50 | loss = 1.894651 
iteration = 55 | loss = 1.840837 
iteration = 60 | loss = 1.837124 
iteration = 65 | loss = 2.004992 
iteration = 70 | loss = 1.802019 
iteration = 75 | loss = 2.284300 
iteration = 80 | loss = 1.826480 
iteration = 85 | loss = 2.083994 
iteration = 90 | loss = 1.768581 
iteration = 95 | loss = 1.756979 
iteration = 100 | loss = 1.741087 
iteration = 105 | loss = 2.188591 

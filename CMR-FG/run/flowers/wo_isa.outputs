Namespace(RNN_dropout=0.0, WORKERS=8, audio_model='Davenet', batch_size=128, cfg_file='Confg/flower_train_batch_wo_isa.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers', exp_dir='', gpu_id=0, image_model='VGG16', img_size=256, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=120, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_isa.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/flowers/wo_isa', simtype='MISA', smooth_gamm3=10.0, start_epoch=60, tasks='extraction', topk=3, weight_decay=0.0001)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/102flowers/test/filenames.pickle (1155)
loaded parameters from epoch 60
current #steps=0, #epochs=60
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:78: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:80: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
iteration = 0 | loss = 6.158903 
iteration = 5 | loss = 5.709422 
iteration = 10 | loss = 5.734076 
iteration = 15 | loss = 6.433946 
iteration = 20 | loss = 6.339969 
iteration = 25 | loss = 5.622661 
iteration = 30 | loss = 5.873401 
iteration = 35 | loss = 5.659101 
iteration = 40 | loss = 6.585930 
iteration = 45 | loss = 6.208135 
iteration = 50 | loss = 6.694721 
/scratch/xinsheng/software/anaconda/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
iteration = 0 | loss = 6.383703 
iteration = 5 | loss = 6.338706 
iteration = 10 | loss = 5.642344 
iteration = 15 | loss = 6.397965 
iteration = 20 | loss = 5.814045 
iteration = 25 | loss = 6.158678 
iteration = 30 | loss = 6.842005 
iteration = 35 | loss = 6.458373 
iteration = 40 | loss = 6.007362 
iteration = 45 | loss = 6.326184 
iteration = 50 | loss = 5.865324 
iteration = 0 | loss = 6.816602 
iteration = 5 | loss = 6.203134 
iteration = 10 | loss = 5.672997 
iteration = 15 | loss = 5.750410 
iteration = 20 | loss = 6.366674 
iteration = 25 | loss = 6.251406 
iteration = 30 | loss = 6.184648 
iteration = 35 | loss = 6.356186 
iteration = 40 | loss = 5.920369 
iteration = 45 | loss = 5.872076 
iteration = 50 | loss = 6.245670 
iteration = 0 | loss = 5.395303 
iteration = 5 | loss = 5.938288 
iteration = 10 | loss = 5.504571 
iteration = 15 | loss = 6.370472 
iteration = 20 | loss = 5.973251 
iteration = 25 | loss = 6.143836 
iteration = 30 | loss = 5.882154 
iteration = 35 | loss = 5.891855 
iteration = 40 | loss = 5.426933 
iteration = 45 | loss = 6.721142 
iteration = 50 | loss = 6.200337 
iteration = 0 | loss = 6.041965 
iteration = 5 | loss = 5.617045 
iteration = 10 | loss = 5.571288 
iteration = 15 | loss = 6.171166 
iteration = 20 | loss = 5.872665 
iteration = 25 | loss = 6.195003 
iteration = 30 | loss = 5.842634 
iteration = 35 | loss = 5.860113 
iteration = 40 | loss = 5.773146 
iteration = 45 | loss = 6.140717 
iteration = 50 | loss = 5.753701 
 Epoch: [65] Loss: 6.3473  R1_I2A: 0.5177 R1_A2I: 0.3974 
                 
 Epoch: [65] Loss: 6.3473  R1_I2A: 0.5697 mAP_I2A: 0.4825  R1_A2I: 0.4100 mAP_A2I: 0.3667 
                     
iteration = 0 | loss = 6.344044 
iteration = 5 | loss = 5.786492 
iteration = 10 | loss = 6.132223 
iteration = 15 | loss = 6.121018 
iteration = 20 | loss = 5.327926 
iteration = 25 | loss = 6.454944 
iteration = 30 | loss = 5.663791 
iteration = 35 | loss = 5.630972 
iteration = 40 | loss = 6.065474 
iteration = 45 | loss = 5.918921 
iteration = 50 | loss = 6.313789 
iteration = 0 | loss = 5.633482 
iteration = 5 | loss = 5.842886 
iteration = 10 | loss = 5.725351 
iteration = 15 | loss = 6.197268 
iteration = 20 | loss = 5.615912 
iteration = 25 | loss = 6.555059 
iteration = 30 | loss = 6.150685 
iteration = 35 | loss = 5.685000 
iteration = 40 | loss = 6.126305 
iteration = 45 | loss = 6.366140 
iteration = 50 | loss = 5.725830 
iteration = 0 | loss = 5.729207 
iteration = 5 | loss = 5.793882 
iteration = 10 | loss = 6.217433 
iteration = 15 | loss = 5.830088 
iteration = 20 | loss = 6.079129 
iteration = 25 | loss = 6.460166 
iteration = 30 | loss = 5.486236 
iteration = 35 | loss = 6.281840 
iteration = 40 | loss = 6.134458 
iteration = 45 | loss = 5.784167 
iteration = 50 | loss = 6.324450 
iteration = 0 | loss = 6.011465 
iteration = 5 | loss = 5.802212 
iteration = 10 | loss = 6.347761 
iteration = 15 | loss = 5.729984 
iteration = 20 | loss = 5.716903 
iteration = 25 | loss = 6.200346 
iteration = 30 | loss = 5.620936 
iteration = 35 | loss = 6.238524 
iteration = 40 | loss = 6.041512 
iteration = 45 | loss = 6.220327 
iteration = 50 | loss = 5.753541 
iteration = 0 | loss = 6.509621 
iteration = 5 | loss = 6.170838 
iteration = 10 | loss = 6.238482 
iteration = 15 | loss = 5.514312 
iteration = 20 | loss = 5.779237 
iteration = 25 | loss = 5.822166 
iteration = 30 | loss = 5.699316 
iteration = 35 | loss = 6.183669 
iteration = 40 | loss = 5.746678 
iteration = 45 | loss = 5.896902 
iteration = 50 | loss = 5.727744 
 Epoch: [70] Loss: 6.0016  R1_I2A: 0.5065 R1_A2I: 0.3818 
                 
iteration = 0 | loss = 6.177481 
iteration = 5 | loss = 5.857748 
iteration = 10 | loss = 5.668269 
iteration = 15 | loss = 6.006174 
iteration = 20 | loss = 5.479503 
iteration = 25 | loss = 6.504319 
iteration = 30 | loss = 5.650568 
iteration = 35 | loss = 5.948431 
iteration = 40 | loss = 5.466686 
iteration = 45 | loss = 5.942418 
iteration = 50 | loss = 6.216822 
iteration = 0 | loss = 6.156487 
iteration = 5 | loss = 5.713054 
iteration = 10 | loss = 5.526397 
iteration = 15 | loss = 6.116751 
iteration = 20 | loss = 5.364038 
iteration = 25 | loss = 6.413040 
iteration = 30 | loss = 6.137998 
iteration = 35 | loss = 5.849863 
iteration = 40 | loss = 5.709301 
iteration = 45 | loss = 5.828833 
iteration = 50 | loss = 6.582137 
iteration = 0 | loss = 5.754522 
iteration = 5 | loss = 5.821659 
iteration = 10 | loss = 5.395547 
iteration = 15 | loss = 6.001538 
iteration = 20 | loss = 5.767928 
iteration = 25 | loss = 5.674170 
iteration = 30 | loss = 6.398076 
iteration = 35 | loss = 5.936118 
iteration = 40 | loss = 5.296142 
iteration = 45 | loss = 5.873605 
iteration = 50 | loss = 6.266873 
iteration = 0 | loss = 6.505923 
iteration = 5 | loss = 5.633564 
iteration = 10 | loss = 5.609710 
iteration = 15 | loss = 5.993372 
iteration = 20 | loss = 6.146499 
iteration = 25 | loss = 6.449760 
iteration = 30 | loss = 6.023187 
iteration = 35 | loss = 6.228658 
iteration = 40 | loss = 5.228906 
iteration = 45 | loss = 5.872665 
iteration = 50 | loss = 5.673710 
iteration = 0 | loss = 5.070336 
iteration = 5 | loss = 5.842013 
iteration = 10 | loss = 5.656740 
iteration = 15 | loss = 5.439407 
iteration = 20 | loss = 6.223673 
iteration = 25 | loss = 6.044072 
iteration = 30 | loss = 5.724737 
iteration = 35 | loss = 5.798793 
iteration = 40 | loss = 5.949917 
iteration = 45 | loss = 5.789684 
iteration = 50 | loss = 6.058608 
 Epoch: [75] Loss: 5.7948  R1_I2A: 0.4952 R1_A2I: 0.3887 
                 
iteration = 0 | loss = 5.513972 
iteration = 5 | loss = 6.273155 
iteration = 10 | loss = 5.654008 
iteration = 15 | loss = 5.717968 
iteration = 20 | loss = 6.123353 
iteration = 25 | loss = 5.708468 
iteration = 30 | loss = 5.654602 
iteration = 35 | loss = 6.597101 
iteration = 40 | loss = 6.123103 
iteration = 45 | loss = 5.416553 
iteration = 50 | loss = 5.055061 
iteration = 0 | loss = 5.615852 
iteration = 5 | loss = 5.588383 
iteration = 10 | loss = 5.717489 
iteration = 15 | loss = 6.063330 
iteration = 20 | loss = 5.558226 
iteration = 25 | loss = 5.716479 
iteration = 30 | loss = 5.767447 
iteration = 35 | loss = 5.505894 
iteration = 40 | loss = 6.033357 
iteration = 45 | loss = 6.202632 
iteration = 50 | loss = 5.578598 
iteration = 0 | loss = 5.979625 
iteration = 5 | loss = 5.285366 
iteration = 10 | loss = 5.724446 
iteration = 15 | loss = 5.635772 
iteration = 20 | loss = 5.413388 
iteration = 25 | loss = 6.146928 
iteration = 30 | loss = 5.281108 
iteration = 35 | loss = 5.692417 
iteration = 40 | loss = 6.005762 
iteration = 45 | loss = 5.442156 
iteration = 50 | loss = 5.667674 
iteration = 0 | loss = 5.827452 
iteration = 5 | loss = 5.766948 
iteration = 10 | loss = 5.109067 
iteration = 15 | loss = 5.656561 
iteration = 20 | loss = 6.210960 
iteration = 25 | loss = 5.589741 
iteration = 30 | loss = 5.888009 
iteration = 35 | loss = 5.776933 
iteration = 40 | loss = 5.553268 
iteration = 45 | loss = 5.391530 
iteration = 50 | loss = 5.684980 
iteration = 0 | loss = 5.460122 
iteration = 5 | loss = 6.372028 
iteration = 10 | loss = 5.519410 
iteration = 15 | loss = 5.498768 
iteration = 20 | loss = 5.275821 
iteration = 25 | loss = 5.538440 
iteration = 30 | loss = 5.533635 
iteration = 35 | loss = 5.525711 
iteration = 40 | loss = 7.012857 
iteration = 45 | loss = 5.654703 
iteration = 50 | loss = 5.687386 
 Epoch: [80] Loss: 5.4444  R1_I2A: 0.4996 R1_A2I: 0.3818 
                 
iteration = 0 | loss = 5.519578 
iteration = 5 | loss = 5.260879 
iteration = 10 | loss = 6.119712 
iteration = 15 | loss = 5.715391 
iteration = 20 | loss = 6.041588 
iteration = 25 | loss = 5.413479 
iteration = 30 | loss = 5.316789 
iteration = 35 | loss = 5.099611 
iteration = 40 | loss = 6.413440 
iteration = 45 | loss = 6.307188 
iteration = 50 | loss = 5.299491 
iteration = 0 | loss = 6.037233 
iteration = 5 | loss = 6.013728 
iteration = 10 | loss = 6.169857 
iteration = 15 | loss = 5.257140 
iteration = 20 | loss = 5.603129 
iteration = 25 | loss = 5.886564 
iteration = 30 | loss = 5.395518 
iteration = 35 | loss = 5.790222 
iteration = 40 | loss = 5.320234 
iteration = 45 | loss = 5.641928 
iteration = 50 | loss = 5.302441 
iteration = 0 | loss = 5.326616 
iteration = 5 | loss = 5.281587 
iteration = 10 | loss = 5.702154 
iteration = 15 | loss = 5.402278 
iteration = 20 | loss = 5.198912 
iteration = 25 | loss = 6.061233 
iteration = 30 | loss = 5.886317 
iteration = 35 | loss = 4.936260 
iteration = 40 | loss = 5.985894 
iteration = 45 | loss = 5.476121 
iteration = 50 | loss = 5.969778 
iteration = 0 | loss = 5.792643 
iteration = 5 | loss = 5.544616 
iteration = 10 | loss = 5.028700 
iteration = 15 | loss = 5.308809 
iteration = 20 | loss = 5.156541 
iteration = 25 | loss = 5.735776 
iteration = 30 | loss = 5.728392 
iteration = 35 | loss = 5.618609 
iteration = 40 | loss = 5.811259 
iteration = 45 | loss = 5.561409 
iteration = 50 | loss = 5.028717 
iteration = 0 | loss = 5.408867 
iteration = 5 | loss = 5.294045 
iteration = 10 | loss = 5.523003 
iteration = 15 | loss = 5.658698 
iteration = 20 | loss = 5.213821 
iteration = 25 | loss = 5.821145 
iteration = 30 | loss = 5.651599 
iteration = 35 | loss = 6.080875 
iteration = 40 | loss = 5.530951 
iteration = 45 | loss = 5.313414 
iteration = 50 | loss = 4.901932 
 Epoch: [85] Loss: 5.1998  R1_I2A: 0.4970 R1_A2I: 0.3801 
                 
iteration = 0 | loss = 5.558621 
iteration = 5 | loss = 5.770634 
iteration = 10 | loss = 5.540184 
iteration = 15 | loss = 5.459806 
iteration = 20 | loss = 5.799708 
iteration = 25 | loss = 5.662095 
iteration = 30 | loss = 6.213636 
iteration = 35 | loss = 5.896420 
iteration = 40 | loss = 6.075203 
iteration = 45 | loss = 5.520528 
iteration = 50 | loss = 5.826081 
iteration = 0 | loss = 5.498199 
iteration = 5 | loss = 4.938850 
iteration = 10 | loss = 6.017592 
iteration = 15 | loss = 5.521475 
iteration = 20 | loss = 5.492486 
iteration = 25 | loss = 5.138654 
iteration = 30 | loss = 5.405373 
iteration = 35 | loss = 5.439286 
iteration = 40 | loss = 6.019494 
iteration = 45 | loss = 5.416581 
iteration = 50 | loss = 5.600678 
iteration = 0 | loss = 4.922608 
iteration = 5 | loss = 5.810280 
iteration = 10 | loss = 5.376070 
iteration = 15 | loss = 5.412923 
iteration = 20 | loss = 5.333805 
iteration = 25 | loss = 5.229698 
iteration = 30 | loss = 5.267667 
iteration = 35 | loss = 5.941302 
iteration = 40 | loss = 5.280221 
iteration = 45 | loss = 5.515030 
iteration = 50 | loss = 5.264570 
iteration = 0 | loss = 5.798293 
iteration = 5 | loss = 5.974237 
iteration = 10 | loss = 5.155364 
iteration = 15 | loss = 5.607651 
iteration = 20 | loss = 5.688849 
iteration = 25 | loss = 4.913458 
iteration = 30 | loss = 5.989889 
iteration = 35 | loss = 5.246567 
iteration = 40 | loss = 5.338725 
iteration = 45 | loss = 5.830034 
iteration = 50 | loss = 5.506363 
iteration = 0 | loss = 4.726458 
iteration = 5 | loss = 5.520655 
iteration = 10 | loss = 5.703639 
iteration = 15 | loss = 5.301715 
iteration = 20 | loss = 6.215550 
iteration = 25 | loss = 5.862233 
iteration = 30 | loss = 5.471154 
iteration = 35 | loss = 5.306881 
iteration = 40 | loss = 5.893732 
iteration = 45 | loss = 5.439305 
iteration = 50 | loss = 5.905592 
 Epoch: [90] Loss: 5.3708  R1_I2A: 0.5013 R1_A2I: 0.3749 
                 
iteration = 0 | loss = 5.110923 
iteration = 5 | loss = 5.527280 
iteration = 10 | loss = 5.758937 
iteration = 15 | loss = 5.431235 
iteration = 20 | loss = 5.919088 
iteration = 25 | loss = 5.378553 
iteration = 30 | loss = 5.712622 
iteration = 35 | loss = 5.400297 
iteration = 40 | loss = 5.013285 
iteration = 45 | loss = 5.304595 
iteration = 50 | loss = 5.040815 
iteration = 0 | loss = 5.510433 
iteration = 5 | loss = 5.433132 
iteration = 10 | loss = 5.047556 
iteration = 15 | loss = 5.290730 
iteration = 20 | loss = 6.157812 
iteration = 25 | loss = 5.598969 
iteration = 30 | loss = 4.996479 
iteration = 35 | loss = 5.792938 
iteration = 40 | loss = 5.685600 
iteration = 45 | loss = 5.728909 
iteration = 50 | loss = 5.729437 
iteration = 0 | loss = 5.321470 
iteration = 5 | loss = 5.360651 
iteration = 10 | loss = 5.576912 
iteration = 15 | loss = 6.002073 
iteration = 20 | loss = 5.021850 
iteration = 25 | loss = 6.069098 
iteration = 30 | loss = 6.447192 
iteration = 35 | loss = 5.532398 
iteration = 40 | loss = 5.292005 
iteration = 45 | loss = 5.893913 
iteration = 50 | loss = 5.357422 
iteration = 0 | loss = 5.625198 
iteration = 5 | loss = 5.128956 
iteration = 10 | loss = 5.970099 
iteration = 15 | loss = 5.491227 
iteration = 20 | loss = 5.512701 
iteration = 25 | loss = 6.028536 
iteration = 30 | loss = 5.702292 
iteration = 35 | loss = 5.985445 
iteration = 40 | loss = 5.613330 
iteration = 45 | loss = 5.850443 
iteration = 50 | loss = 6.039195 
iteration = 0 | loss = 5.011293 
iteration = 5 | loss = 5.142152 
iteration = 10 | loss = 5.951128 
iteration = 15 | loss = 5.404085 
iteration = 20 | loss = 4.957587 
iteration = 25 | loss = 5.921151 
iteration = 30 | loss = 5.263387 
iteration = 35 | loss = 5.154685 
iteration = 40 | loss = 4.587945 
iteration = 45 | loss = 5.909985 
iteration = 50 | loss = 5.157164 
 Epoch: [95] Loss: 4.9376  R1_I2A: 0.4866 R1_A2I: 0.3905 
                 
iteration = 0 | loss = 5.405080 
iteration = 5 | loss = 5.042305 
iteration = 10 | loss = 5.703349 
iteration = 15 | loss = 4.924273 
iteration = 20 | loss = 4.961531 
iteration = 25 | loss = 5.186848 
iteration = 30 | loss = 5.170798 
iteration = 35 | loss = 4.765865 
iteration = 40 | loss = 5.517728 
iteration = 45 | loss = 5.142103 
iteration = 50 | loss = 5.349789 
iteration = 0 | loss = 5.731591 
iteration = 5 | loss = 5.030007 
iteration = 10 | loss = 5.065211 
iteration = 15 | loss = 5.023507 
iteration = 20 | loss = 5.585780 
iteration = 25 | loss = 5.321156 
iteration = 30 | loss = 5.258595 
iteration = 35 | loss = 5.308419 
iteration = 40 | loss = 5.087362 
iteration = 45 | loss = 5.200645 
iteration = 50 | loss = 5.052332 
iteration = 0 | loss = 5.189080 
iteration = 5 | loss = 5.026357 
iteration = 10 | loss = 5.236422 
iteration = 15 | loss = 5.054012 
iteration = 20 | loss = 5.503429 
iteration = 25 | loss = 5.460323 
iteration = 30 | loss = 5.169174 
iteration = 35 | loss = 4.748118 
iteration = 40 | loss = 5.067447 
iteration = 45 | loss = 5.712605 
iteration = 50 | loss = 5.188080 
iteration = 0 | loss = 4.939014 
iteration = 5 | loss = 5.078019 
iteration = 10 | loss = 5.234361 
iteration = 15 | loss = 4.749558 
iteration = 20 | loss = 5.949840 
iteration = 25 | loss = 5.065387 
iteration = 30 | loss = 5.041729 
iteration = 35 | loss = 5.385685 
iteration = 40 | loss = 5.163349 
iteration = 45 | loss = 5.213147 
iteration = 50 | loss = 4.698313 
iteration = 0 | loss = 4.859884 
iteration = 5 | loss = 5.148131 
iteration = 10 | loss = 5.079643 
iteration = 15 | loss = 4.306022 
iteration = 20 | loss = 4.994052 
iteration = 25 | loss = 5.015417 
iteration = 30 | loss = 5.035493 
iteration = 35 | loss = 4.819095 
iteration = 40 | loss = 5.259730 
iteration = 45 | loss = 4.973438 
iteration = 50 | loss = 5.176332 
 Epoch: [100] Loss: 4.8737  R1_I2A: 0.5143 R1_A2I: 0.3775 
                 
iteration = 0 | loss = 5.243513 
iteration = 5 | loss = 4.646817 
iteration = 10 | loss = 4.940173 
iteration = 15 | loss = 5.294378 
iteration = 20 | loss = 5.027868 
iteration = 25 | loss = 4.490016 
iteration = 30 | loss = 5.749840 
iteration = 35 | loss = 5.188744 
iteration = 40 | loss = 5.323785 
iteration = 45 | loss = 5.234741 
iteration = 50 | loss = 4.933301 
iteration = 0 | loss = 4.924943 
iteration = 5 | loss = 5.494328 
iteration = 10 | loss = 5.165723 
iteration = 15 | loss = 5.817851 
iteration = 20 | loss = 5.263283 
iteration = 25 | loss = 5.021206 
iteration = 30 | loss = 5.077608 
iteration = 35 | loss = 4.964930 
iteration = 40 | loss = 5.195131 
iteration = 45 | loss = 6.055797 
iteration = 50 | loss = 5.762896 
iteration = 0 | loss = 5.464368 
iteration = 5 | loss = 4.844049 
iteration = 10 | loss = 5.043763 
iteration = 15 | loss = 5.098834 
iteration = 20 | loss = 5.436686 
iteration = 25 | loss = 4.703137 
iteration = 30 | loss = 5.040359 
iteration = 35 | loss = 5.454331 
iteration = 40 | loss = 4.925085 
iteration = 45 | loss = 5.539059 
iteration = 50 | loss = 5.390537 
iteration = 0 | loss = 5.408097 
iteration = 5 | loss = 5.560031 
iteration = 10 | loss = 4.922067 
iteration = 15 | loss = 5.311692 
iteration = 20 | loss = 5.145665 
iteration = 25 | loss = 4.817471 
iteration = 30 | loss = 4.707273 
iteration = 35 | loss = 4.665338 
iteration = 40 | loss = 5.280782 
iteration = 45 | loss = 4.865088 
iteration = 50 | loss = 4.528877 
iteration = 0 | loss = 4.898003 
iteration = 5 | loss = 5.144979 
iteration = 10 | loss = 4.872636 
iteration = 15 | loss = 5.043634 
iteration = 20 | loss = 5.374324 
iteration = 25 | loss = 5.188867 
iteration = 30 | loss = 4.434011 
iteration = 35 | loss = 4.848913 
iteration = 40 | loss = 5.252101 
iteration = 45 | loss = 4.812856 
iteration = 50 | loss = 5.110371 
 Epoch: [105] Loss: 4.6736  R1_I2A: 0.5264 R1_A2I: 0.3784 
                 
iteration = 0 | loss = 5.194948 
iteration = 5 | loss = 4.585875 
iteration = 10 | loss = 5.224089 
iteration = 15 | loss = 4.330316 
iteration = 20 | loss = 5.919879 
iteration = 25 | loss = 5.251259 
iteration = 30 | loss = 5.241296 
iteration = 35 | loss = 5.360603 
iteration = 40 | loss = 5.189881 
iteration = 45 | loss = 4.586211 
iteration = 50 | loss = 4.475611 
iteration = 0 | loss = 5.304627 
iteration = 5 | loss = 4.878466 
iteration = 10 | loss = 5.168719 
iteration = 15 | loss = 5.111190 
iteration = 20 | loss = 5.743541 
iteration = 25 | loss = 5.380218 
iteration = 30 | loss = 5.630781 
iteration = 35 | loss = 5.122213 
iteration = 40 | loss = 5.255403 
iteration = 45 | loss = 5.260011 
iteration = 50 | loss = 5.439807 
iteration = 0 | loss = 5.106934 
iteration = 5 | loss = 4.898395 
iteration = 10 | loss = 5.444436 
iteration = 15 | loss = 4.968394 
iteration = 20 | loss = 5.134914 
iteration = 25 | loss = 4.638021 
iteration = 30 | loss = 5.261055 
iteration = 35 | loss = 4.962410 
iteration = 40 | loss = 5.627126 
iteration = 45 | loss = 5.083181 
iteration = 50 | loss = 5.325024 
iteration = 0 | loss = 4.941691 
iteration = 5 | loss = 5.022069 
iteration = 10 | loss = 5.157347 
iteration = 15 | loss = 4.534988 
iteration = 20 | loss = 5.486979 
iteration = 25 | loss = 4.922620 
iteration = 30 | loss = 5.083094 
iteration = 35 | loss = 5.329121 
iteration = 40 | loss = 5.060805 
iteration = 45 | loss = 5.202188 
iteration = 50 | loss = 5.269697 
iteration = 0 | loss = 5.700068 
iteration = 5 | loss = 4.906207 
iteration = 10 | loss = 5.112981 
iteration = 15 | loss = 5.256285 
iteration = 20 | loss = 5.177238 
iteration = 25 | loss = 4.541119 
iteration = 30 | loss = 5.252728 
iteration = 35 | loss = 4.808256 
iteration = 40 | loss = 5.275991 
iteration = 45 | loss = 5.153962 
iteration = 50 | loss = 5.163906 
 Epoch: [110] Loss: 4.7569  R1_I2A: 0.5238 R1_A2I: 0.3558 
                 
iteration = 0 | loss = 4.994973 
iteration = 5 | loss = 4.842517 
iteration = 10 | loss = 4.729446 
iteration = 15 | loss = 4.447322 
iteration = 20 | loss = 5.167633 
iteration = 25 | loss = 5.055130 
iteration = 30 | loss = 5.056675 
iteration = 35 | loss = 5.011475 
iteration = 40 | loss = 4.888646 
iteration = 45 | loss = 4.921741 
iteration = 50 | loss = 4.472636 
iteration = 0 | loss = 4.822352 
iteration = 5 | loss = 5.515858 
iteration = 10 | loss = 5.012374 
iteration = 15 | loss = 5.212830 
iteration = 20 | loss = 4.888980 
iteration = 25 | loss = 5.069157 
iteration = 30 | loss = 4.873696 
iteration = 35 | loss = 5.084332 
iteration = 40 | loss = 5.073345 
iteration = 45 | loss = 4.314714 
iteration = 50 | loss = 5.268809 
iteration = 0 | loss = 4.958405 
iteration = 5 | loss = 5.186644 
iteration = 10 | loss = 4.682377 
iteration = 15 | loss = 5.145588 
iteration = 20 | loss = 4.967893 
iteration = 25 | loss = 5.448393 
iteration = 30 | loss = 5.248142 
iteration = 35 | loss = 5.139558 
iteration = 40 | loss = 5.320892 
iteration = 45 | loss = 5.007376 
iteration = 50 | loss = 5.048189 
iteration = 0 | loss = 5.188527 
iteration = 5 | loss = 5.154496 
iteration = 10 | loss = 4.679634 
iteration = 15 | loss = 4.422036 
iteration = 20 | loss = 5.451437 
iteration = 25 | loss = 4.539690 
iteration = 30 | loss = 5.289007 
iteration = 35 | loss = 4.893659 
iteration = 40 | loss = 5.196330 
iteration = 45 | loss = 4.440549 
iteration = 50 | loss = 4.973623 
iteration = 0 | loss = 5.465723 
iteration = 5 | loss = 4.964250 
iteration = 10 | loss = 5.168731 
iteration = 15 | loss = 4.866364 
iteration = 20 | loss = 5.006271 
iteration = 25 | loss = 5.414657 
iteration = 30 | loss = 5.203465 
iteration = 35 | loss = 4.879988 
iteration = 40 | loss = 4.343103 
iteration = 45 | loss = 4.612062 
iteration = 50 | loss = 4.616388 
 Epoch: [115] Loss: 5.0260  R1_I2A: 0.5030 R1_A2I: 0.3610 
                 
iteration = 0 | loss = 4.548640 
iteration = 5 | loss = 5.307386 
iteration = 10 | loss = 5.011877 
iteration = 15 | loss = 4.271070 
iteration = 20 | loss = 5.237000 
iteration = 25 | loss = 5.454122 
iteration = 30 | loss = 5.513736 
iteration = 35 | loss = 4.881720 
iteration = 40 | loss = 4.649446 
iteration = 45 | loss = 4.787800 
iteration = 50 | loss = 4.976058 
iteration = 0 | loss = 4.607646 
iteration = 5 | loss = 4.998259 
iteration = 10 | loss = 5.024366 
iteration = 15 | loss = 5.134428 
iteration = 20 | loss = 4.680847 
iteration = 25 | loss = 4.890978 
iteration = 30 | loss = 4.313009 
iteration = 35 | loss = 4.671043 
iteration = 40 | loss = 4.405389 
iteration = 45 | loss = 4.944715 
iteration = 50 | loss = 5.031720 
iteration = 0 | loss = 3.940436 
iteration = 5 | loss = 5.013302 
iteration = 10 | loss = 5.428719 
iteration = 15 | loss = 4.648240 
iteration = 20 | loss = 5.073622 
iteration = 25 | loss = 4.838892 
iteration = 30 | loss = 4.609094 
iteration = 35 | loss = 5.068982 
iteration = 40 | loss = 4.628236 
iteration = 45 | loss = 5.188037 
iteration = 50 | loss = 4.884117 
iteration = 0 | loss = 5.029819 
iteration = 5 | loss = 4.871380 
iteration = 10 | loss = 4.593957 
iteration = 15 | loss = 5.354414 
iteration = 20 | loss = 4.869624 
iteration = 25 | loss = 4.052315 
iteration = 30 | loss = 4.948442 
iteration = 35 | loss = 5.588911 
iteration = 40 | loss = 4.591589 
iteration = 45 | loss = 4.214079 
iteration = 50 | loss = 5.238744 
iteration = 0 | loss = 5.059766 
iteration = 5 | loss = 5.155175 
iteration = 10 | loss = 5.064289 
iteration = 15 | loss = 4.909096 
iteration = 20 | loss = 4.802129 
iteration = 25 | loss = 4.402202 
iteration = 30 | loss = 5.735980 
iteration = 35 | loss = 4.791950 
iteration = 40 | loss = 4.992998 
iteration = 45 | loss = 5.045007 
iteration = 50 | loss = 4.920681 
 Epoch: [120] Loss: 4.8256  R1_I2A: 0.4900 R1_A2I: 0.3706 
                 
iteration = 0 | loss = 5.019326 
iteration = 5 | loss = 4.577121 
iteration = 10 | loss = 4.464984 
iteration = 15 | loss = 5.063874 
iteration = 20 | loss = 4.373703 
iteration = 25 | loss = 5.167411 
iteration = 30 | loss = 5.031082 
iteration = 35 | loss = 5.146664 
iteration = 40 | loss = 5.302491 
iteration = 45 | loss = 4.788938 
iteration = 50 | loss = 5.388362 

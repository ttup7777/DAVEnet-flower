64 13.0
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/train/filenames.pickle (7034)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/flowers/Oxford102/test/filenames.pickle (1155)
current #steps=0, #epochs=0
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 8.319047 
iteration = 5 | loss = 8.484934 
iteration = 10 | loss = 8.449430 
iteration = 15 | loss = 8.384501 
iteration = 20 | loss = 8.347800 
iteration = 25 | loss = 8.346871 
iteration = 30 | loss = 8.315131 
iteration = 35 | loss = 8.334382 
iteration = 40 | loss = 8.245567 
iteration = 45 | loss = 8.191465 
iteration = 50 | loss = 8.119480 
iteration = 55 | loss = 7.963331 
iteration = 60 | loss = 7.973057 
iteration = 65 | loss = 7.916368 
iteration = 70 | loss = 7.415885 
iteration = 75 | loss = 7.462116 
iteration = 80 | loss = 7.551994 
iteration = 85 | loss = 7.406858 
iteration = 90 | loss = 7.462052 
iteration = 95 | loss = 7.527351 
iteration = 100 | loss = 6.947344 
iteration = 105 | loss = 6.830482 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 6.890190 
iteration = 5 | loss = 6.798755 
iteration = 10 | loss = 6.927369 
iteration = 15 | loss = 6.688473 
iteration = 20 | loss = 6.573731 
iteration = 25 | loss = 6.783935 
iteration = 30 | loss = 6.627872 
iteration = 35 | loss = 6.576697 
iteration = 40 | loss = 6.298097 
iteration = 45 | loss = 6.484880 
iteration = 50 | loss = 6.269945 
iteration = 55 | loss = 6.468126 
iteration = 60 | loss = 6.590287 
iteration = 65 | loss = 6.550160 
iteration = 70 | loss = 6.302753 
iteration = 75 | loss = 6.552553 
iteration = 80 | loss = 6.595998 
iteration = 85 | loss = 6.156739 
iteration = 90 | loss = 6.520050 
iteration = 95 | loss = 5.619997 
iteration = 100 | loss = 6.074392 
iteration = 105 | loss = 5.868007 
iteration = 0 | loss = 5.853345 
iteration = 5 | loss = 5.504845 
iteration = 10 | loss = 5.464561 
iteration = 15 | loss = 6.119103 
iteration = 20 | loss = 6.204569 
iteration = 25 | loss = 5.869586 
iteration = 30 | loss = 5.784012 
iteration = 35 | loss = 5.438214 
iteration = 40 | loss = 5.992733 
iteration = 45 | loss = 5.948803 
iteration = 50 | loss = 5.393548 
iteration = 55 | loss = 5.516032 
iteration = 60 | loss = 5.573616 
iteration = 65 | loss = 5.492845 
iteration = 70 | loss = 5.781967 
iteration = 75 | loss = 5.540180 
iteration = 80 | loss = 5.658878 
iteration = 85 | loss = 6.081396 
iteration = 90 | loss = 5.511397 
iteration = 95 | loss = 5.476735 
iteration = 100 | loss = 5.307518 
iteration = 105 | loss = 5.259484 
iteration = 0 | loss = 4.967382 
iteration = 5 | loss = 5.433371 
iteration = 10 | loss = 5.232203 
iteration = 15 | loss = 5.123408 
iteration = 20 | loss = 5.739709 
iteration = 25 | loss = 5.049688 
iteration = 30 | loss = 5.142348 
iteration = 35 | loss = 4.999936 
iteration = 40 | loss = 5.684926 
iteration = 45 | loss = 5.311744 
iteration = 50 | loss = 5.055348 
iteration = 55 | loss = 5.423048 
iteration = 60 | loss = 5.379323 
iteration = 65 | loss = 5.020585 
iteration = 70 | loss = 5.254200 
iteration = 75 | loss = 5.325877 
iteration = 80 | loss = 5.327886 
iteration = 85 | loss = 5.005048 
iteration = 90 | loss = 5.683298 
iteration = 95 | loss = 5.589437 
iteration = 100 | loss = 5.446207 
iteration = 105 | loss = 5.586546 
iteration = 0 | loss = 4.885852 
iteration = 5 | loss = 5.189216 
iteration = 10 | loss = 4.739217 
iteration = 15 | loss = 5.188941 
iteration = 20 | loss = 5.646890 
iteration = 25 | loss = 4.600838 
iteration = 30 | loss = 5.484362 
iteration = 35 | loss = 4.475890 
iteration = 40 | loss = 5.059317 
iteration = 45 | loss = 5.210635 
iteration = 50 | loss = 5.192165 
iteration = 55 | loss = 5.106934 
iteration = 60 | loss = 5.250863 
iteration = 65 | loss = 4.770596 
iteration = 70 | loss = 4.748446 
iteration = 75 | loss = 5.051146 
iteration = 80 | loss = 4.824538 
iteration = 85 | loss = 5.277213 
iteration = 90 | loss = 4.548959 
iteration = 95 | loss = 4.488566 
iteration = 100 | loss = 4.796672 
iteration = 105 | loss = 4.452942 
 Epoch: [5] Loss: 4.8532  R1_I2A: 0.4900 R1_A2I: 0.3431 
                 
iteration = 0 | loss = 4.273861 
iteration = 5 | loss = 4.283867 
iteration = 10 | loss = 4.720098 
iteration = 15 | loss = 4.835120 
iteration = 20 | loss = 4.868697 
iteration = 25 | loss = 4.913265 
iteration = 30 | loss = 4.838310 
iteration = 35 | loss = 4.931596 
iteration = 40 | loss = 4.917472 
iteration = 45 | loss = 4.405474 
iteration = 50 | loss = 4.524914 
iteration = 55 | loss = 4.356822 
iteration = 60 | loss = 5.149151 
iteration = 65 | loss = 4.587008 
iteration = 70 | loss = 4.880655 
iteration = 75 | loss = 5.200875 
iteration = 80 | loss = 4.339736 
iteration = 85 | loss = 4.810889 
iteration = 90 | loss = 4.503776 
iteration = 95 | loss = 5.287253 
iteration = 100 | loss = 5.318556 
iteration = 105 | loss = 5.010530 
iteration = 0 | loss = 4.179402 
iteration = 5 | loss = 4.697206 
iteration = 10 | loss = 5.014509 
iteration = 15 | loss = 4.736619 
iteration = 20 | loss = 5.037803 
iteration = 25 | loss = 4.583742 
iteration = 30 | loss = 5.186895 
iteration = 35 | loss = 4.485295 
iteration = 40 | loss = 4.373733 
iteration = 45 | loss = 4.869597 
iteration = 50 | loss = 4.577795 
iteration = 55 | loss = 4.419836 
iteration = 60 | loss = 4.782674 
iteration = 65 | loss = 4.174724 
iteration = 70 | loss = 4.723970 
iteration = 75 | loss = 4.546365 
iteration = 80 | loss = 4.881225 
iteration = 85 | loss = 3.947443 
iteration = 90 | loss = 4.304513 
iteration = 95 | loss = 4.764306 
iteration = 100 | loss = 3.886075 
iteration = 105 | loss = 4.933375 
iteration = 0 | loss = 4.642230 
iteration = 5 | loss = 5.337342 
iteration = 10 | loss = 4.736316 
iteration = 15 | loss = 4.340465 
iteration = 20 | loss = 4.385903 
iteration = 25 | loss = 5.121695 
iteration = 30 | loss = 4.590482 
iteration = 35 | loss = 4.537484 
iteration = 40 | loss = 4.581953 
iteration = 45 | loss = 4.509513 
iteration = 50 | loss = 4.108790 
iteration = 55 | loss = 4.654185 
iteration = 60 | loss = 4.548460 
iteration = 65 | loss = 4.347150 
iteration = 70 | loss = 4.878876 
iteration = 75 | loss = 4.668065 
iteration = 80 | loss = 4.571774 
iteration = 85 | loss = 4.713431 
iteration = 90 | loss = 4.126187 
iteration = 95 | loss = 4.501272 
iteration = 100 | loss = 4.675523 
iteration = 105 | loss = 3.926048 
iteration = 0 | loss = 4.264446 
iteration = 5 | loss = 3.497362 
iteration = 10 | loss = 4.182737 
iteration = 15 | loss = 4.375335 
iteration = 20 | loss = 4.137808 
iteration = 25 | loss = 4.040679 
iteration = 30 | loss = 4.425833 
iteration = 35 | loss = 4.228781 
iteration = 40 | loss = 4.240335 
iteration = 45 | loss = 4.352736 
iteration = 50 | loss = 4.549086 
iteration = 55 | loss = 3.810577 
iteration = 60 | loss = 4.204796 
iteration = 65 | loss = 4.225831 
iteration = 70 | loss = 3.931020 
iteration = 75 | loss = 4.146824 
iteration = 80 | loss = 3.727638 
iteration = 85 | loss = 3.360301 
iteration = 90 | loss = 4.906149 
iteration = 95 | loss = 4.167677 
iteration = 100 | loss = 3.964787 
iteration = 105 | loss = 4.139840 
iteration = 0 | loss = 4.032971 
iteration = 5 | loss = 4.144398 
iteration = 10 | loss = 3.889127 
iteration = 15 | loss = 4.243093 
iteration = 20 | loss = 4.433854 
iteration = 25 | loss = 4.463889 
iteration = 30 | loss = 4.393503 
iteration = 35 | loss = 3.781219 
iteration = 40 | loss = 3.724171 
iteration = 45 | loss = 4.115669 
iteration = 50 | loss = 4.787276 
iteration = 55 | loss = 4.608697 
iteration = 60 | loss = 4.292532 
iteration = 65 | loss = 4.193994 
iteration = 70 | loss = 4.183294 
iteration = 75 | loss = 4.388087 
iteration = 80 | loss = 3.921986 
iteration = 85 | loss = 4.750179 
iteration = 90 | loss = 3.969281 
iteration = 95 | loss = 4.757775 
iteration = 100 | loss = 4.010288 
iteration = 105 | loss = 4.004337 
 Epoch: [10] Loss: 3.9470  R1_I2A: 0.5429 R1_A2I: 0.3765 
                 
iteration = 0 | loss = 4.025158 
iteration = 5 | loss = 3.814095 
iteration = 10 | loss = 3.798397 
iteration = 15 | loss = 3.603435 
iteration = 20 | loss = 3.777679 
iteration = 25 | loss = 3.711161 
iteration = 30 | loss = 4.116999 
iteration = 35 | loss = 4.049790 
iteration = 40 | loss = 3.720803 
iteration = 45 | loss = 4.332932 
iteration = 50 | loss = 3.999582 
iteration = 55 | loss = 3.097505 
iteration = 60 | loss = 4.008810 
iteration = 65 | loss = 3.991683 
iteration = 70 | loss = 4.187392 
iteration = 75 | loss = 4.028199 
iteration = 80 | loss = 4.028454 
iteration = 85 | loss = 4.244314 
iteration = 90 | loss = 4.253178 
iteration = 95 | loss = 3.964229 
iteration = 100 | loss = 3.863416 
iteration = 105 | loss = 4.033467 
iteration = 0 | loss = 3.996973 
iteration = 5 | loss = 3.580172 
iteration = 10 | loss = 3.665655 
iteration = 15 | loss = 4.277069 
iteration = 20 | loss = 4.291199 
iteration = 25 | loss = 4.116733 
iteration = 30 | loss = 3.930014 
iteration = 35 | loss = 3.803732 
iteration = 40 | loss = 3.832932 
iteration = 45 | loss = 4.284266 
iteration = 50 | loss = 3.662871 
iteration = 55 | loss = 3.935602 
iteration = 60 | loss = 3.450057 
iteration = 65 | loss = 3.776694 
iteration = 70 | loss = 3.279951 
iteration = 75 | loss = 3.898536 
iteration = 80 | loss = 3.941147 
iteration = 85 | loss = 3.933231 
iteration = 90 | loss = 4.230442 
iteration = 95 | loss = 3.727678 
iteration = 100 | loss = 3.661345 
iteration = 105 | loss = 4.442151 
iteration = 0 | loss = 3.871768 
iteration = 5 | loss = 3.835632 
iteration = 10 | loss = 3.292580 
iteration = 15 | loss = 4.114301 
iteration = 20 | loss = 3.861696 
iteration = 25 | loss = 4.015157 
iteration = 30 | loss = 3.317018 
iteration = 35 | loss = 3.721209 
iteration = 40 | loss = 4.227885 
iteration = 45 | loss = 4.179225 
iteration = 50 | loss = 4.365630 
iteration = 55 | loss = 3.552569 
iteration = 60 | loss = 4.191661 
iteration = 65 | loss = 4.239256 
iteration = 70 | loss = 3.771699 
iteration = 75 | loss = 3.321319 
iteration = 80 | loss = 3.262266 
iteration = 85 | loss = 3.356813 
iteration = 90 | loss = 4.098536 
iteration = 95 | loss = 4.253636 
iteration = 100 | loss = 4.194993 
iteration = 105 | loss = 3.893397 
iteration = 0 | loss = 3.898833 
iteration = 5 | loss = 4.363762 
iteration = 10 | loss = 3.685846 
iteration = 15 | loss = 3.276850 
iteration = 20 | loss = 4.033462 
iteration = 25 | loss = 3.752367 
iteration = 30 | loss = 3.848823 
iteration = 35 | loss = 3.684795 
iteration = 40 | loss = 3.563723 
iteration = 45 | loss = 3.848846 
iteration = 50 | loss = 3.775216 
iteration = 55 | loss = 3.859472 
iteration = 60 | loss = 3.888268 
iteration = 65 | loss = 4.127266 
iteration = 70 | loss = 4.090023 
iteration = 75 | loss = 3.846939 
iteration = 80 | loss = 3.526488 
iteration = 85 | loss = 3.299949 
iteration = 90 | loss = 3.968573 
iteration = 95 | loss = 3.178041 
iteration = 100 | loss = 4.068439 
iteration = 105 | loss = 3.526775 
iteration = 0 | loss = 3.617418 
iteration = 5 | loss = 3.869661 
iteration = 10 | loss = 3.426910 
iteration = 15 | loss = 3.803840 
iteration = 20 | loss = 3.890755 
iteration = 25 | loss = 4.349113 
iteration = 30 | loss = 4.507494 
iteration = 35 | loss = 4.135958 
iteration = 40 | loss = 3.657974 
iteration = 45 | loss = 4.353370 
iteration = 50 | loss = 3.733780 
iteration = 55 | loss = 3.439579 
iteration = 60 | loss = 3.605871 
iteration = 65 | loss = 3.529257 
iteration = 70 | loss = 3.545947 
iteration = 75 | loss = 3.316208 
iteration = 80 | loss = 3.361964 
iteration = 85 | loss = 4.031117 
iteration = 90 | loss = 3.975999 
iteration = 95 | loss = 3.679680 
iteration = 100 | loss = 3.335872 
iteration = 105 | loss = 3.611001 
 Epoch: [15] Loss: 3.5091  R1_I2A: 0.5688 R1_A2I: 0.4378 
                 
iteration = 0 | loss = 3.524704 
iteration = 5 | loss = 3.452074 
iteration = 10 | loss = 3.471566 
iteration = 15 | loss = 3.638475 
iteration = 20 | loss = 3.388311 
iteration = 25 | loss = 3.421429 
iteration = 30 | loss = 3.830203 
iteration = 35 | loss = 3.495454 
iteration = 40 | loss = 3.794448 
iteration = 45 | loss = 3.521544 
iteration = 50 | loss = 3.519867 
iteration = 55 | loss = 3.485611 
iteration = 60 | loss = 3.105706 
iteration = 65 | loss = 3.824836 
iteration = 70 | loss = 3.259829 
iteration = 75 | loss = 3.243396 
iteration = 80 | loss = 3.778574 
iteration = 85 | loss = 2.909637 
iteration = 90 | loss = 4.469284 
iteration = 95 | loss = 3.549070 
iteration = 100 | loss = 3.926887 
iteration = 105 | loss = 3.202696 
iteration = 0 | loss = 3.267040 
iteration = 5 | loss = 3.455966 
iteration = 10 | loss = 3.785310 
iteration = 15 | loss = 3.174254 
iteration = 20 | loss = 3.422421 
iteration = 25 | loss = 3.564055 
iteration = 30 | loss = 3.653466 
iteration = 35 | loss = 3.609983 
iteration = 40 | loss = 3.692147 
iteration = 45 | loss = 3.069032 
iteration = 50 | loss = 3.389510 
iteration = 55 | loss = 3.420900 
iteration = 60 | loss = 3.218982 
iteration = 65 | loss = 3.656864 
iteration = 70 | loss = 3.562764 
iteration = 75 | loss = 3.585829 
iteration = 80 | loss = 3.200112 
iteration = 85 | loss = 3.786912 
iteration = 90 | loss = 3.606825 
iteration = 95 | loss = 3.464296 
iteration = 100 | loss = 3.583615 
iteration = 105 | loss = 3.447825 
iteration = 0 | loss = 3.210271 
iteration = 5 | loss = 3.745591 
iteration = 10 | loss = 3.747683 
iteration = 15 | loss = 3.437349 
iteration = 20 | loss = 3.542818 
iteration = 25 | loss = 3.789199 
iteration = 30 | loss = 3.705709 
iteration = 35 | loss = 3.493712 
iteration = 40 | loss = 2.819623 
iteration = 45 | loss = 3.330056 
iteration = 50 | loss = 3.296969 
iteration = 55 | loss = 3.688075 
iteration = 60 | loss = 3.110838 
iteration = 65 | loss = 3.304298 
iteration = 70 | loss = 3.290860 
iteration = 75 | loss = 3.065952 
iteration = 80 | loss = 3.448886 
iteration = 85 | loss = 3.588024 
iteration = 90 | loss = 3.324178 
iteration = 95 | loss = 3.473616 
iteration = 100 | loss = 3.578205 
iteration = 105 | loss = 3.753660 
iteration = 0 | loss = 3.385957 
iteration = 5 | loss = 3.541032 
iteration = 10 | loss = 3.257816 
iteration = 15 | loss = 3.141614 
iteration = 20 | loss = 3.479883 
iteration = 25 | loss = 3.828003 
iteration = 30 | loss = 3.672818 
iteration = 35 | loss = 3.370920 
iteration = 40 | loss = 3.900809 
iteration = 45 | loss = 3.509524 
iteration = 50 | loss = 3.993945 
iteration = 55 | loss = 3.328717 
iteration = 60 | loss = 3.330652 
iteration = 65 | loss = 3.296970 
iteration = 70 | loss = 3.913289 
iteration = 75 | loss = 3.510254 
iteration = 80 | loss = 3.369898 
iteration = 85 | loss = 3.388595 
iteration = 90 | loss = 3.323016 
iteration = 95 | loss = 3.602435 
iteration = 100 | loss = 3.384306 
iteration = 105 | loss = 2.986164 
iteration = 0 | loss = 3.337090 
iteration = 5 | loss = 2.790944 
iteration = 10 | loss = 3.363738 
iteration = 15 | loss = 2.926281 
iteration = 20 | loss = 3.335052 
iteration = 25 | loss = 2.854496 
iteration = 30 | loss = 3.092313 
iteration = 35 | loss = 3.088465 
iteration = 40 | loss = 3.223419 
iteration = 45 | loss = 4.268486 
iteration = 50 | loss = 3.587714 
iteration = 55 | loss = 3.509446 
iteration = 60 | loss = 3.354981 
iteration = 65 | loss = 3.213194 
iteration = 70 | loss = 3.064958 
iteration = 75 | loss = 3.158807 
iteration = 80 | loss = 3.602470 
iteration = 85 | loss = 3.020390 
iteration = 90 | loss = 2.701031 
iteration = 95 | loss = 3.179896 
iteration = 100 | loss = 3.174807 
iteration = 105 | loss = 3.443436 
 Epoch: [20] Loss: 3.8941  R1_I2A: 0.5541 R1_A2I: 0.4624 
                 
iteration = 0 | loss = 2.861083 
iteration = 5 | loss = 3.830908 
iteration = 10 | loss = 3.320437 
iteration = 15 | loss = 3.870378 
iteration = 20 | loss = 3.375476 
iteration = 25 | loss = 3.062141 
iteration = 30 | loss = 3.355245 
iteration = 35 | loss = 3.706601 
iteration = 40 | loss = 3.396893 
iteration = 45 | loss = 3.808323 
iteration = 50 | loss = 3.529312 
iteration = 55 | loss = 3.387609 
iteration = 60 | loss = 3.266756 
iteration = 65 | loss = 3.683346 
iteration = 70 | loss = 3.291911 
iteration = 75 | loss = 2.914462 
iteration = 80 | loss = 4.000600 
iteration = 85 | loss = 3.421773 
iteration = 90 | loss = 3.522509 
iteration = 95 | loss = 3.379930 
iteration = 100 | loss = 3.544165 
iteration = 105 | loss = 3.748855 
iteration = 0 | loss = 2.968096 
iteration = 5 | loss = 3.012950 
iteration = 10 | loss = 3.622635 
iteration = 15 | loss = 3.248674 
iteration = 20 | loss = 2.787968 
iteration = 25 | loss = 3.335410 
iteration = 30 | loss = 3.141869 
iteration = 35 | loss = 3.083308 
iteration = 40 | loss = 3.015279 
iteration = 45 | loss = 3.643466 
iteration = 50 | loss = 3.637750 
iteration = 55 | loss = 3.447268 
iteration = 60 | loss = 3.198164 
iteration = 65 | loss = 3.177623 
iteration = 70 | loss = 3.743207 
iteration = 75 | loss = 2.832091 
iteration = 80 | loss = 2.921729 
iteration = 85 | loss = 3.057799 
iteration = 90 | loss = 2.966838 
iteration = 95 | loss = 3.348589 
iteration = 100 | loss = 3.609299 
iteration = 105 | loss = 3.205718 
iteration = 0 | loss = 3.532490 
iteration = 5 | loss = 3.369913 
iteration = 10 | loss = 2.890918 
iteration = 15 | loss = 3.168632 
iteration = 20 | loss = 3.193959 
iteration = 25 | loss = 3.274152 
iteration = 30 | loss = 3.277058 
iteration = 35 | loss = 3.379008 
iteration = 40 | loss = 3.339045 
iteration = 45 | loss = 3.481836 
iteration = 50 | loss = 3.287432 
iteration = 55 | loss = 3.200877 
iteration = 60 | loss = 2.930180 
iteration = 65 | loss = 2.563096 
iteration = 70 | loss = 3.420330 
iteration = 75 | loss = 3.307522 
iteration = 80 | loss = 3.250625 
iteration = 85 | loss = 3.510913 
iteration = 90 | loss = 3.785516 
iteration = 95 | loss = 3.058720 
iteration = 100 | loss = 3.472740 
iteration = 105 | loss = 2.892966 
iteration = 0 | loss = 3.035606 
iteration = 5 | loss = 3.571051 
iteration = 10 | loss = 3.265109 
iteration = 15 | loss = 3.202838 
iteration = 20 | loss = 3.135790 
iteration = 25 | loss = 3.431741 
iteration = 30 | loss = 2.987134 
iteration = 35 | loss = 3.357057 
iteration = 40 | loss = 2.908502 
iteration = 45 | loss = 3.788070 
iteration = 50 | loss = 3.581587 
iteration = 55 | loss = 3.256041 
iteration = 60 | loss = 2.895680 
iteration = 65 | loss = 2.981746 
iteration = 70 | loss = 3.217517 
iteration = 75 | loss = 3.167591 
iteration = 80 | loss = 3.047050 
iteration = 85 | loss = 2.940464 
iteration = 90 | loss = 3.035068 
iteration = 95 | loss = 3.400688 
iteration = 100 | loss = 3.194704 
iteration = 105 | loss = 2.533153 
iteration = 0 | loss = 3.738450 
iteration = 5 | loss = 3.151956 
iteration = 10 | loss = 3.041945 
iteration = 15 | loss = 3.124385 
iteration = 20 | loss = 3.398479 
iteration = 25 | loss = 3.139526 
iteration = 30 | loss = 3.390781 
iteration = 35 | loss = 3.179557 
iteration = 40 | loss = 3.695322 
iteration = 45 | loss = 3.224837 
iteration = 50 | loss = 2.685619 
iteration = 55 | loss = 3.575861 
iteration = 60 | loss = 2.921023 
iteration = 65 | loss = 3.475089 
iteration = 70 | loss = 3.085112 
iteration = 75 | loss = 2.984528 
iteration = 80 | loss = 3.063022 
iteration = 85 | loss = 3.400524 
iteration = 90 | loss = 3.027378 
iteration = 95 | loss = 2.576284 
iteration = 100 | loss = 2.875098 
iteration = 105 | loss = 3.579645 
 Epoch: [25] Loss: 3.0115  R1_I2A: 0.5671 R1_A2I: 0.4655 
                 
 Epoch: [25] Loss: 3.0115  R1_I2A: 0.5712 mAP_I2A: 0.5041  R1_A2I: 0.4655 mAP_A2I: 0.4059 
                     
iteration = 0 | loss = 2.923791 
iteration = 5 | loss = 3.271321 
iteration = 10 | loss = 3.495394 
iteration = 15 | loss = 3.042553 
iteration = 20 | loss = 2.570874 
iteration = 25 | loss = 3.536290 
iteration = 30 | loss = 3.564050 
iteration = 35 | loss = 3.184558 
iteration = 40 | loss = 2.332378 
iteration = 45 | loss = 3.395514 
iteration = 50 | loss = 3.115301 
iteration = 55 | loss = 2.991188 
iteration = 60 | loss = 3.108983 
iteration = 65 | loss = 3.299845 
iteration = 70 | loss = 3.265665 
iteration = 75 | loss = 3.315753 
iteration = 80 | loss = 3.421840 
iteration = 85 | loss = 3.174694 
iteration = 90 | loss = 2.922902 
iteration = 95 | loss = 3.559806 
iteration = 100 | loss = 2.801232 
iteration = 105 | loss = 2.726704 
iteration = 0 | loss = 2.782988 
iteration = 5 | loss = 2.999353 
iteration = 10 | loss = 3.091000 
iteration = 15 | loss = 2.906217 
iteration = 20 | loss = 3.093150 
iteration = 25 | loss = 2.934698 
iteration = 30 | loss = 2.859150 
iteration = 35 | loss = 3.229549 
iteration = 40 | loss = 2.794509 
iteration = 45 | loss = 2.595258 
iteration = 50 | loss = 2.922694 
iteration = 55 | loss = 3.349868 
iteration = 60 | loss = 3.218233 
iteration = 65 | loss = 2.343160 
iteration = 70 | loss = 2.706129 
iteration = 75 | loss = 3.353255 
iteration = 80 | loss = 3.266265 
iteration = 85 | loss = 2.671184 
iteration = 90 | loss = 3.646923 
iteration = 95 | loss = 2.968377 
iteration = 100 | loss = 2.516425 
iteration = 105 | loss = 3.540307 
iteration = 0 | loss = 3.098956 
iteration = 5 | loss = 3.595159 
iteration = 10 | loss = 2.640761 
iteration = 15 | loss = 3.048178 
iteration = 20 | loss = 3.542897 
iteration = 25 | loss = 2.716743 
iteration = 30 | loss = 3.106251 
iteration = 35 | loss = 3.946966 
iteration = 40 | loss = 3.392546 
iteration = 45 | loss = 3.285224 
iteration = 50 | loss = 3.312968 
iteration = 55 | loss = 2.966951 
iteration = 60 | loss = 2.943385 
iteration = 65 | loss = 2.887860 
iteration = 70 | loss = 2.908801 
iteration = 75 | loss = 2.926999 
iteration = 80 | loss = 2.867605 
iteration = 85 | loss = 3.113384 
iteration = 90 | loss = 2.681010 
iteration = 95 | loss = 2.998457 
iteration = 100 | loss = 3.143065 
iteration = 105 | loss = 3.680050 
iteration = 0 | loss = 2.827048 
iteration = 5 | loss = 3.181947 
iteration = 10 | loss = 2.588427 
iteration = 15 | loss = 2.827125 
iteration = 20 | loss = 2.773199 
iteration = 25 | loss = 2.784345 
iteration = 30 | loss = 2.592082 
iteration = 35 | loss = 3.136587 
iteration = 40 | loss = 2.864971 
iteration = 45 | loss = 3.322531 
iteration = 50 | loss = 2.805625 
iteration = 55 | loss = 3.116264 
iteration = 60 | loss = 3.113403 
iteration = 65 | loss = 2.991034 
iteration = 70 | loss = 3.045092 
iteration = 75 | loss = 2.760828 
iteration = 80 | loss = 2.405236 
iteration = 85 | loss = 3.375948 
iteration = 90 | loss = 2.663256 
iteration = 95 | loss = 3.316061 
iteration = 100 | loss = 2.511521 
iteration = 105 | loss = 2.862897 
iteration = 0 | loss = 2.624764 
iteration = 5 | loss = 3.071923 
iteration = 10 | loss = 2.827957 
iteration = 15 | loss = 2.764321 
iteration = 20 | loss = 2.974802 
iteration = 25 | loss = 2.718849 
iteration = 30 | loss = 2.583458 
iteration = 35 | loss = 3.298398 
iteration = 40 | loss = 2.561629 
iteration = 45 | loss = 2.606442 
iteration = 50 | loss = 2.618284 
iteration = 55 | loss = 3.396028 
iteration = 60 | loss = 3.157135 
iteration = 65 | loss = 3.118548 
iteration = 70 | loss = 3.013673 
iteration = 75 | loss = 2.654176 
iteration = 80 | loss = 2.621674 
iteration = 85 | loss = 3.232357 
iteration = 90 | loss = 2.665817 
iteration = 95 | loss = 2.912063 
iteration = 100 | loss = 2.937261 
iteration = 105 | loss = 2.732045 
 Epoch: [30] Loss: 3.2572  R1_I2A: 0.5515 R1_A2I: 0.4462 
                 
iteration = 0 | loss = 2.480948 
iteration = 5 | loss = 2.963161 
iteration = 10 | loss = 2.516679 
iteration = 15 | loss = 2.938052 
iteration = 20 | loss = 3.227942 
iteration = 25 | loss = 2.602899 
iteration = 30 | loss = 2.800894 
iteration = 35 | loss = 3.058535 
iteration = 40 | loss = 2.976484 
iteration = 45 | loss = 2.773329 
iteration = 50 | loss = 2.882244 
iteration = 55 | loss = 3.109213 
iteration = 60 | loss = 3.231456 
iteration = 65 | loss = 2.970865 
iteration = 70 | loss = 2.624725 
iteration = 75 | loss = 3.403453 
iteration = 80 | loss = 3.083628 
iteration = 85 | loss = 3.142050 
iteration = 90 | loss = 3.214297 
iteration = 95 | loss = 2.678029 
iteration = 100 | loss = 3.167802 
iteration = 105 | loss = 2.826408 
iteration = 0 | loss = 3.395452 
iteration = 5 | loss = 3.118698 
iteration = 10 | loss = 2.647872 
iteration = 15 | loss = 2.970323 
iteration = 20 | loss = 2.862624 
iteration = 25 | loss = 3.098623 
iteration = 30 | loss = 3.014373 
iteration = 35 | loss = 2.843872 
iteration = 40 | loss = 3.088695 
iteration = 45 | loss = 2.957826 
iteration = 50 | loss = 2.517144 
iteration = 55 | loss = 2.507416 
iteration = 60 | loss = 2.910523 
iteration = 65 | loss = 2.395533 
iteration = 70 | loss = 2.526474 
iteration = 75 | loss = 2.821577 
iteration = 80 | loss = 2.688534 
iteration = 85 | loss = 3.025330 
iteration = 90 | loss = 3.344986 
iteration = 95 | loss = 3.043029 
iteration = 100 | loss = 2.696378 
iteration = 105 | loss = 3.410423 
iteration = 0 | loss = 2.999215 
iteration = 5 | loss = 3.051146 
iteration = 10 | loss = 2.764930 
iteration = 15 | loss = 3.165963 
iteration = 20 | loss = 2.389632 
iteration = 25 | loss = 2.483260 
iteration = 30 | loss = 2.933243 
iteration = 35 | loss = 2.462882 
iteration = 40 | loss = 2.758629 
iteration = 45 | loss = 2.801170 
iteration = 50 | loss = 2.866870 
iteration = 55 | loss = 2.925465 
iteration = 60 | loss = 2.292758 
iteration = 65 | loss = 2.840244 
iteration = 70 | loss = 3.402264 
iteration = 75 | loss = 3.223122 
iteration = 80 | loss = 2.765729 
iteration = 85 | loss = 2.735532 
iteration = 90 | loss = 2.813195 
iteration = 95 | loss = 2.815623 
iteration = 100 | loss = 3.025518 
iteration = 105 | loss = 2.791071 
iteration = 0 | loss = 2.744682 
iteration = 5 | loss = 2.568454 
iteration = 10 | loss = 3.270847 
iteration = 15 | loss = 3.072707 
iteration = 20 | loss = 2.948731 
iteration = 25 | loss = 2.833717 
iteration = 30 | loss = 2.359679 
iteration = 35 | loss = 3.068424 
iteration = 40 | loss = 2.925454 
iteration = 45 | loss = 2.715989 
iteration = 50 | loss = 2.827008 
iteration = 55 | loss = 2.244513 
iteration = 60 | loss = 2.700301 
iteration = 65 | loss = 2.685987 
iteration = 70 | loss = 2.237838 
iteration = 75 | loss = 2.248094 
iteration = 80 | loss = 3.040322 
iteration = 85 | loss = 2.523131 
iteration = 90 | loss = 2.894486 
iteration = 95 | loss = 2.977444 
iteration = 100 | loss = 2.704327 
iteration = 105 | loss = 3.074642 
iteration = 0 | loss = 2.874779 
iteration = 5 | loss = 2.543351 
iteration = 10 | loss = 2.888595 
iteration = 15 | loss = 2.853662 
iteration = 20 | loss = 3.196301 
iteration = 25 | loss = 2.481288 
iteration = 30 | loss = 2.904841 
iteration = 35 | loss = 2.728491 
iteration = 40 | loss = 2.497979 
iteration = 45 | loss = 2.769726 
iteration = 50 | loss = 2.891817 
iteration = 55 | loss = 2.857013 
iteration = 60 | loss = 2.758312 
iteration = 65 | loss = 3.086862 
iteration = 70 | loss = 3.156551 
iteration = 75 | loss = 2.850800 
iteration = 80 | loss = 2.465366 
iteration = 85 | loss = 2.389936 
iteration = 90 | loss = 2.896554 
iteration = 95 | loss = 3.947849 
iteration = 100 | loss = 2.723913 
iteration = 105 | loss = 2.897344 
 Epoch: [35] Loss: 2.5917  R1_I2A: 0.5758 R1_A2I: 0.4610 
                 
 Epoch: [35] Loss: 2.5917  R1_I2A: 0.5835 mAP_I2A: 0.5133  R1_A2I: 0.4610 mAP_A2I: 0.4019 
                     
iteration = 0 | loss = 2.894716 
iteration = 5 | loss = 2.944608 
iteration = 10 | loss = 2.623611 
iteration = 15 | loss = 2.658098 
iteration = 20 | loss = 2.620818 
iteration = 25 | loss = 2.902033 
iteration = 30 | loss = 2.696714 
iteration = 35 | loss = 2.837256 
iteration = 40 | loss = 2.598697 
iteration = 45 | loss = 2.634102 
iteration = 50 | loss = 2.306062 
iteration = 55 | loss = 2.392595 
iteration = 60 | loss = 2.551719 
iteration = 65 | loss = 2.625350 
iteration = 70 | loss = 2.933190 
iteration = 75 | loss = 2.747456 
iteration = 80 | loss = 2.804317 
iteration = 85 | loss = 2.379714 
iteration = 90 | loss = 2.803188 
iteration = 95 | loss = 2.965742 
iteration = 100 | loss = 2.665141 
iteration = 105 | loss = 2.616575 
iteration = 0 | loss = 2.533323 
iteration = 5 | loss = 2.503879 
iteration = 10 | loss = 2.849150 
iteration = 15 | loss = 2.885476 
iteration = 20 | loss = 2.322042 
iteration = 25 | loss = 2.804648 
iteration = 30 | loss = 2.724448 
iteration = 35 | loss = 2.649040 
iteration = 40 | loss = 2.683356 
iteration = 45 | loss = 2.851266 
iteration = 50 | loss = 2.974373 
iteration = 55 | loss = 3.265889 
iteration = 60 | loss = 2.349460 
iteration = 65 | loss = 2.713210 
iteration = 70 | loss = 2.202927 
iteration = 75 | loss = 2.151736 
iteration = 80 | loss = 2.585193 
iteration = 85 | loss = 2.606519 
iteration = 90 | loss = 2.217951 
iteration = 95 | loss = 2.876842 
iteration = 100 | loss = 3.167086 
iteration = 105 | loss = 2.793140 
iteration = 0 | loss = 2.001396 
iteration = 5 | loss = 2.516122 
iteration = 10 | loss = 2.914774 
iteration = 15 | loss = 2.799957 
iteration = 20 | loss = 2.668610 
iteration = 25 | loss = 2.703591 
iteration = 30 | loss = 2.284400 
iteration = 35 | loss = 2.894433 
iteration = 40 | loss = 2.793994 
iteration = 45 | loss = 2.636826 
iteration = 50 | loss = 2.786758 
iteration = 55 | loss = 2.707621 
iteration = 60 | loss = 2.453900 
iteration = 65 | loss = 2.352668 
iteration = 70 | loss = 2.455637 
iteration = 75 | loss = 2.632084 
iteration = 80 | loss = 2.723481 
iteration = 85 | loss = 2.682297 
iteration = 90 | loss = 2.527400 
iteration = 95 | loss = 2.969332 
iteration = 100 | loss = 2.716335 
iteration = 105 | loss = 2.449448 
iteration = 0 | loss = 2.789699 
iteration = 5 | loss = 2.201826 
iteration = 10 | loss = 2.846877 
iteration = 15 | loss = 2.879680 
iteration = 20 | loss = 2.423413 
iteration = 25 | loss = 2.882011 
iteration = 30 | loss = 2.732036 
iteration = 35 | loss = 3.239055 
iteration = 40 | loss = 3.361202 
iteration = 45 | loss = 3.191691 
iteration = 50 | loss = 2.801590 
iteration = 55 | loss = 2.127964 
iteration = 60 | loss = 2.193104 
iteration = 65 | loss = 2.616728 
iteration = 70 | loss = 2.660935 
iteration = 75 | loss = 2.760684 
iteration = 80 | loss = 2.679341 
iteration = 85 | loss = 2.602854 
iteration = 90 | loss = 2.665035 
iteration = 95 | loss = 2.660735 
iteration = 100 | loss = 3.145255 
iteration = 105 | loss = 2.506538 
iteration = 0 | loss = 2.833920 
iteration = 5 | loss = 2.825647 
iteration = 10 | loss = 3.205692 
iteration = 15 | loss = 2.345925 
iteration = 20 | loss = 2.959072 
iteration = 25 | loss = 2.506009 
iteration = 30 | loss = 2.656933 
iteration = 35 | loss = 2.406201 
iteration = 40 | loss = 2.949304 
iteration = 45 | loss = 2.366627 
iteration = 50 | loss = 2.588578 
iteration = 55 | loss = 2.104661 
iteration = 60 | loss = 2.938116 
iteration = 65 | loss = 3.009604 
iteration = 70 | loss = 2.663627 
iteration = 75 | loss = 2.889992 
iteration = 80 | loss = 2.719642 
iteration = 85 | loss = 2.123571 
iteration = 90 | loss = 2.960331 
iteration = 95 | loss = 2.781523 
iteration = 100 | loss = 2.956311 
iteration = 105 | loss = 2.838047 
 Epoch: [40] Loss: 2.5370  R1_I2A: 0.5887 R1_A2I: 0.4634 
                 
 Epoch: [40] Loss: 2.5370  R1_I2A: 0.5920 mAP_I2A: 0.5130  R1_A2I: 0.4634 mAP_A2I: 0.4127 
                     
iteration = 0 | loss = 3.059894 
iteration = 5 | loss = 2.666893 
iteration = 10 | loss = 2.558610 
iteration = 15 | loss = 3.141832 
iteration = 20 | loss = 2.518701 
iteration = 25 | loss = 2.761008 
iteration = 30 | loss = 2.423913 
iteration = 35 | loss = 2.316496 
iteration = 40 | loss = 2.244488 
iteration = 45 | loss = 2.838476 
iteration = 50 | loss = 2.318804 
iteration = 55 | loss = 2.756368 
iteration = 60 | loss = 2.490323 
iteration = 65 | loss = 2.807512 
iteration = 70 | loss = 2.468258 
iteration = 75 | loss = 2.539723 
iteration = 80 | loss = 2.232321 
iteration = 85 | loss = 2.720721 
iteration = 90 | loss = 2.375135 
iteration = 95 | loss = 2.374260 
iteration = 100 | loss = 2.855171 
iteration = 105 | loss = 2.527871 

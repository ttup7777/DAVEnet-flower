64 13.0 False True
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/birds/train/filenames.pickle (8855)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/birds/test/filenames.pickle (2933)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/data/birds/test/filenames.pickle (2933)
current #steps=0, #epochs=0
start training...
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/SpeechLab/TianTian/xinsheng/Retrieval_v4.3/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
iteration = 0 | loss = 8.342798 
iteration = 5 | loss = 8.385292 
iteration = 10 | loss = 8.454699 
iteration = 15 | loss = 8.351443 
iteration = 20 | loss = 8.388690 
iteration = 25 | loss = 8.302981 
iteration = 30 | loss = 8.300526 
iteration = 35 | loss = 8.245197 
iteration = 40 | loss = 8.219830 
iteration = 45 | loss = 8.213302 
iteration = 50 | loss = 8.241998 
iteration = 55 | loss = 7.999248 
iteration = 60 | loss = 8.024060 
iteration = 65 | loss = 7.805539 
iteration = 70 | loss = 7.917630 
iteration = 75 | loss = 8.019628 
iteration = 80 | loss = 7.886136 
iteration = 85 | loss = 7.725690 
iteration = 90 | loss = 7.755059 
iteration = 95 | loss = 7.420184 
iteration = 100 | loss = 7.703479 
iteration = 105 | loss = 7.647902 
iteration = 110 | loss = 7.481866 
iteration = 115 | loss = 7.263435 
iteration = 120 | loss = 7.147865 
iteration = 125 | loss = 7.301841 
iteration = 130 | loss = 7.008384 
iteration = 135 | loss = 7.268203 
/home/nfs/tiantian/.local/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
iteration = 0 | loss = 7.019167 
iteration = 5 | loss = 7.027521 
iteration = 10 | loss = 7.149098 
iteration = 15 | loss = 6.738844 
iteration = 20 | loss = 6.851201 
iteration = 25 | loss = 7.193050 
iteration = 30 | loss = 7.120028 
iteration = 35 | loss = 6.883620 
iteration = 40 | loss = 7.043896 
iteration = 45 | loss = 6.246479 
iteration = 50 | loss = 6.526735 
iteration = 55 | loss = 6.979203 
iteration = 60 | loss = 7.067628 
iteration = 65 | loss = 6.559026 
iteration = 70 | loss = 7.108055 
iteration = 75 | loss = 7.098642 
iteration = 80 | loss = 6.899830 
iteration = 85 | loss = 6.616313 
iteration = 90 | loss = 7.268538 
iteration = 95 | loss = 6.486799 
iteration = 100 | loss = 6.777199 
iteration = 105 | loss = 6.798480 
iteration = 110 | loss = 6.682628 
iteration = 115 | loss = 6.950057 
iteration = 120 | loss = 6.498060 
iteration = 125 | loss = 6.898225 
iteration = 130 | loss = 6.492526 
iteration = 135 | loss = 6.211321 
iteration = 0 | loss = 6.213662 
iteration = 5 | loss = 6.470159 
iteration = 10 | loss = 5.954720 
iteration = 15 | loss = 6.660120 
iteration = 20 | loss = 5.786530 
iteration = 25 | loss = 6.506132 
iteration = 30 | loss = 6.471791 
iteration = 35 | loss = 6.287354 
iteration = 40 | loss = 6.237623 
iteration = 45 | loss = 6.431923 
iteration = 50 | loss = 6.420668 
iteration = 55 | loss = 6.321774 
iteration = 60 | loss = 5.988007 
iteration = 65 | loss = 6.484786 
iteration = 70 | loss = 6.469916 
iteration = 75 | loss = 5.791196 
iteration = 80 | loss = 5.804409 
iteration = 85 | loss = 5.925056 
iteration = 90 | loss = 5.868196 
iteration = 95 | loss = 6.138551 
iteration = 100 | loss = 5.960969 
iteration = 105 | loss = 6.276251 
iteration = 110 | loss = 6.040092 
iteration = 115 | loss = 6.420702 
iteration = 120 | loss = 6.013996 
iteration = 125 | loss = 6.000952 
iteration = 130 | loss = 5.941896 
iteration = 135 | loss = 6.100258 
iteration = 0 | loss = 6.266765 
iteration = 5 | loss = 5.861676 
iteration = 10 | loss = 6.668614 
iteration = 15 | loss = 5.371244 
iteration = 20 | loss = 5.812159 
iteration = 25 | loss = 5.613677 
iteration = 30 | loss = 5.823697 
iteration = 35 | loss = 5.714863 
iteration = 40 | loss = 5.810061 
iteration = 45 | loss = 5.557807 
iteration = 50 | loss = 5.831598 
iteration = 55 | loss = 5.463965 
iteration = 60 | loss = 5.392776 
iteration = 65 | loss = 5.627032 
iteration = 70 | loss = 5.790039 
iteration = 75 | loss = 5.497689 
iteration = 80 | loss = 6.124134 
iteration = 85 | loss = 5.573949 
iteration = 90 | loss = 5.897005 
iteration = 95 | loss = 6.192535 
iteration = 100 | loss = 6.024054 
iteration = 105 | loss = 5.449852 
iteration = 110 | loss = 5.452158 
iteration = 115 | loss = 5.292878 
iteration = 120 | loss = 5.547143 
iteration = 125 | loss = 5.873732 
iteration = 130 | loss = 5.621637 
iteration = 135 | loss = 5.307695 
iteration = 0 | loss = 6.054612 
iteration = 5 | loss = 5.729668 
iteration = 10 | loss = 5.823294 
iteration = 15 | loss = 5.085818 
iteration = 20 | loss = 5.147316 
iteration = 25 | loss = 5.724863 
iteration = 30 | loss = 5.668612 
iteration = 35 | loss = 5.332602 
iteration = 40 | loss = 5.502264 
iteration = 45 | loss = 5.356625 
iteration = 50 | loss = 5.476090 
iteration = 55 | loss = 5.241193 
iteration = 60 | loss = 5.187791 
iteration = 65 | loss = 5.209823 
iteration = 70 | loss = 5.199323 
iteration = 75 | loss = 5.463757 
iteration = 80 | loss = 5.449650 
iteration = 85 | loss = 5.503356 
iteration = 90 | loss = 4.934436 
iteration = 95 | loss = 5.987521 
iteration = 100 | loss = 5.607491 
iteration = 105 | loss = 5.444553 
iteration = 110 | loss = 5.803588 
iteration = 115 | loss = 5.144049 
iteration = 120 | loss = 5.882322 
iteration = 125 | loss = 5.341378 
iteration = 130 | loss = 5.513422 
iteration = 135 | loss = 5.490464 
 Epoch: [5] Loss: 5.5886  R1_I2A: 0.2980 R1_A2I: 0.2060 
                 
iteration = 0 | loss = 5.016274 
iteration = 5 | loss = 5.773463 
iteration = 10 | loss = 5.305683 
iteration = 15 | loss = 5.172282 
iteration = 20 | loss = 5.211023 
iteration = 25 | loss = 5.043109 
iteration = 30 | loss = 5.267038 
iteration = 35 | loss = 4.858265 
iteration = 40 | loss = 5.266469 
iteration = 45 | loss = 5.392566 
iteration = 50 | loss = 5.705455 
iteration = 55 | loss = 5.457344 
iteration = 60 | loss = 5.488949 
iteration = 65 | loss = 4.939881 
iteration = 70 | loss = 5.255362 
iteration = 75 | loss = 4.963526 
iteration = 80 | loss = 4.658449 
iteration = 85 | loss = 4.952902 
iteration = 90 | loss = 5.374476 
iteration = 95 | loss = 5.089525 
iteration = 100 | loss = 4.584264 
iteration = 105 | loss = 4.930450 
iteration = 110 | loss = 5.640708 
iteration = 115 | loss = 5.314457 
iteration = 120 | loss = 5.081807 
iteration = 125 | loss = 5.217813 
iteration = 130 | loss = 5.896011 
iteration = 135 | loss = 5.100097 
iteration = 0 | loss = 4.924692 
iteration = 5 | loss = 5.407766 
iteration = 10 | loss = 5.863427 
iteration = 15 | loss = 5.125024 
iteration = 20 | loss = 4.607090 
iteration = 25 | loss = 4.933316 
iteration = 30 | loss = 5.387855 
iteration = 35 | loss = 5.183451 
iteration = 40 | loss = 5.570116 
iteration = 45 | loss = 4.778289 
iteration = 50 | loss = 4.437564 
iteration = 55 | loss = 5.219703 
iteration = 60 | loss = 5.224195 
iteration = 65 | loss = 4.579517 
iteration = 70 | loss = 5.164708 
iteration = 75 | loss = 5.140979 
iteration = 80 | loss = 4.714803 
iteration = 85 | loss = 5.169217 
iteration = 90 | loss = 5.500232 
iteration = 95 | loss = 5.011816 
iteration = 100 | loss = 4.668611 
iteration = 105 | loss = 5.550827 
iteration = 110 | loss = 5.282888 
iteration = 115 | loss = 4.977670 
iteration = 120 | loss = 5.167317 
iteration = 125 | loss = 5.272120 
iteration = 130 | loss = 5.344859 
iteration = 135 | loss = 4.948236 
iteration = 0 | loss = 5.273162 
iteration = 5 | loss = 4.772715 
iteration = 10 | loss = 4.903518 
iteration = 15 | loss = 4.786415 
iteration = 20 | loss = 4.984873 
iteration = 25 | loss = 4.975768 
iteration = 30 | loss = 5.566469 
iteration = 35 | loss = 5.380062 
iteration = 40 | loss = 5.112865 
iteration = 45 | loss = 5.121242 
iteration = 50 | loss = 5.201341 
iteration = 55 | loss = 5.668723 
iteration = 60 | loss = 4.860016 
iteration = 65 | loss = 5.296099 
iteration = 70 | loss = 6.427949 
iteration = 75 | loss = 4.241447 
iteration = 80 | loss = 4.930548 
iteration = 85 | loss = 5.246189 
iteration = 90 | loss = 4.719480 
iteration = 95 | loss = 4.454340 
iteration = 100 | loss = 5.793111 
iteration = 105 | loss = 4.620848 
iteration = 110 | loss = 4.904408 
iteration = 115 | loss = 5.227395 
iteration = 120 | loss = 5.751190 
iteration = 125 | loss = 4.942470 
iteration = 130 | loss = 5.048097 
iteration = 135 | loss = 5.032341 
iteration = 0 | loss = 5.017092 
iteration = 5 | loss = 4.551224 
iteration = 10 | loss = 5.008812 
iteration = 15 | loss = 4.523582 
iteration = 20 | loss = 4.867651 
iteration = 25 | loss = 4.483349 
iteration = 30 | loss = 4.766716 
iteration = 35 | loss = 5.344234 
iteration = 40 | loss = 4.621312 
iteration = 45 | loss = 4.563171 
iteration = 50 | loss = 4.498882 
iteration = 55 | loss = 4.384356 
iteration = 60 | loss = 4.857894 
iteration = 65 | loss = 4.548595 
iteration = 70 | loss = 5.126370 
iteration = 75 | loss = 4.640124 
iteration = 80 | loss = 5.283454 
iteration = 85 | loss = 5.291141 
iteration = 90 | loss = 4.628417 
iteration = 95 | loss = 4.240396 
iteration = 100 | loss = 4.612865 
iteration = 105 | loss = 4.998409 
iteration = 110 | loss = 4.899029 
iteration = 115 | loss = 4.836918 
iteration = 120 | loss = 4.423931 
iteration = 125 | loss = 4.525671 
iteration = 130 | loss = 5.353555 
iteration = 135 | loss = 4.751925 
iteration = 0 | loss = 4.259746 
iteration = 5 | loss = 4.668753 
iteration = 10 | loss = 4.625457 
iteration = 15 | loss = 4.891680 
iteration = 20 | loss = 4.434021 
iteration = 25 | loss = 4.530319 
iteration = 30 | loss = 4.796067 
iteration = 35 | loss = 4.746596 
iteration = 40 | loss = 5.039684 
iteration = 45 | loss = 5.135324 
iteration = 50 | loss = 4.665868 
iteration = 55 | loss = 5.774980 
iteration = 60 | loss = 4.355727 
iteration = 65 | loss = 4.299239 
iteration = 70 | loss = 5.072671 
iteration = 75 | loss = 5.048962 
iteration = 80 | loss = 4.419866 
iteration = 85 | loss = 4.965854 
iteration = 90 | loss = 4.932378 
iteration = 95 | loss = 4.335556 
iteration = 100 | loss = 4.285370 
iteration = 105 | loss = 4.861103 
iteration = 110 | loss = 4.672090 
iteration = 115 | loss = 5.401242 
iteration = 120 | loss = 4.727593 
iteration = 125 | loss = 5.208645 
iteration = 130 | loss = 4.298721 
iteration = 135 | loss = 4.785830 
 Epoch: [10] Loss: 4.9155  R1_I2A: 0.3563 R1_A2I: 0.2534 
                 
iteration = 0 | loss = 4.735750 
iteration = 5 | loss = 4.666721 
iteration = 10 | loss = 4.862160 
iteration = 15 | loss = 5.422775 
iteration = 20 | loss = 4.597598 
iteration = 25 | loss = 4.452075 
iteration = 30 | loss = 4.697323 
iteration = 35 | loss = 4.766774 
iteration = 40 | loss = 4.758105 
iteration = 45 | loss = 5.157392 
iteration = 50 | loss = 4.431350 
iteration = 55 | loss = 4.745445 
iteration = 60 | loss = 4.956936 
iteration = 65 | loss = 4.177484 
iteration = 70 | loss = 4.310654 
iteration = 75 | loss = 5.278172 
iteration = 80 | loss = 4.759254 
iteration = 85 | loss = 4.422660 
iteration = 90 | loss = 4.724747 
iteration = 95 | loss = 4.394100 
iteration = 100 | loss = 5.272025 
iteration = 105 | loss = 5.221992 
iteration = 110 | loss = 4.696287 
iteration = 115 | loss = 4.311892 
iteration = 120 | loss = 5.005844 
iteration = 125 | loss = 4.286229 
iteration = 130 | loss = 4.793880 
iteration = 135 | loss = 4.424462 
iteration = 0 | loss = 4.878826 
iteration = 5 | loss = 5.071780 
iteration = 10 | loss = 4.815965 
iteration = 15 | loss = 5.096674 
iteration = 20 | loss = 4.525667 
iteration = 25 | loss = 4.756293 
iteration = 30 | loss = 4.688706 
iteration = 35 | loss = 4.774346 
iteration = 40 | loss = 5.037827 
iteration = 45 | loss = 4.768005 
iteration = 50 | loss = 4.970264 
iteration = 55 | loss = 4.638807 
iteration = 60 | loss = 4.896267 
iteration = 65 | loss = 5.159999 
iteration = 70 | loss = 4.508856 
iteration = 75 | loss = 4.567592 
iteration = 80 | loss = 4.746914 
iteration = 85 | loss = 5.039482 
iteration = 90 | loss = 4.636764 
iteration = 95 | loss = 4.447680 
iteration = 100 | loss = 4.680584 
iteration = 105 | loss = 4.643342 
iteration = 110 | loss = 4.449917 
iteration = 115 | loss = 4.562562 
iteration = 120 | loss = 4.468714 
iteration = 125 | loss = 4.505869 
iteration = 130 | loss = 4.996606 
iteration = 135 | loss = 4.377032 
iteration = 0 | loss = 4.660991 
iteration = 5 | loss = 5.263705 
iteration = 10 | loss = 4.990790 
iteration = 15 | loss = 4.928386 
iteration = 20 | loss = 4.342396 
iteration = 25 | loss = 4.483730 
iteration = 30 | loss = 4.354345 
iteration = 35 | loss = 4.961411 
iteration = 40 | loss = 4.499865 
iteration = 45 | loss = 4.777805 
iteration = 50 | loss = 5.009611 
iteration = 55 | loss = 4.599614 
iteration = 60 | loss = 4.676519 
iteration = 65 | loss = 4.186914 
iteration = 70 | loss = 5.140683 
iteration = 75 | loss = 4.507569 
iteration = 80 | loss = 4.534053 
iteration = 85 | loss = 4.909043 
iteration = 90 | loss = 4.651681 
iteration = 95 | loss = 4.480520 
iteration = 100 | loss = 4.566972 
iteration = 105 | loss = 4.709344 
iteration = 110 | loss = 4.448015 
iteration = 115 | loss = 4.564207 
iteration = 120 | loss = 4.634983 
iteration = 125 | loss = 4.622324 
iteration = 130 | loss = 4.758250 
iteration = 135 | loss = 4.727029 
iteration = 0 | loss = 4.528780 
iteration = 5 | loss = 3.864090 
iteration = 10 | loss = 4.239033 
iteration = 15 | loss = 4.264613 
iteration = 20 | loss = 5.187609 
iteration = 25 | loss = 3.853637 
iteration = 30 | loss = 5.111208 
iteration = 35 | loss = 4.654929 
iteration = 40 | loss = 4.076576 
iteration = 45 | loss = 4.112380 
iteration = 50 | loss = 4.610116 
iteration = 55 | loss = 4.204399 
iteration = 60 | loss = 4.503565 
iteration = 65 | loss = 4.770195 
iteration = 70 | loss = 4.234657 
iteration = 75 | loss = 5.261623 
iteration = 80 | loss = 4.262567 
iteration = 85 | loss = 3.857649 
iteration = 90 | loss = 4.845659 
iteration = 95 | loss = 4.277701 
iteration = 100 | loss = 4.780596 
iteration = 105 | loss = 4.816786 
iteration = 110 | loss = 4.868552 
iteration = 115 | loss = 4.163845 
iteration = 120 | loss = 4.607550 
iteration = 125 | loss = 4.867049 
iteration = 130 | loss = 4.305107 
iteration = 135 | loss = 4.756177 
iteration = 0 | loss = 4.060972 
iteration = 5 | loss = 4.404325 
iteration = 10 | loss = 4.867942 
iteration = 15 | loss = 5.063433 
iteration = 20 | loss = 4.621024 
iteration = 25 | loss = 4.770630 
iteration = 30 | loss = 4.114796 
iteration = 35 | loss = 4.445941 
iteration = 40 | loss = 4.302896 
iteration = 45 | loss = 4.233020 
iteration = 50 | loss = 4.511938 
iteration = 55 | loss = 4.105529 
iteration = 60 | loss = 4.124854 
iteration = 65 | loss = 3.999109 
iteration = 70 | loss = 4.624608 
iteration = 75 | loss = 4.228751 
iteration = 80 | loss = 4.074389 
iteration = 85 | loss = 4.732268 
iteration = 90 | loss = 4.495193 
iteration = 95 | loss = 4.871573 
iteration = 100 | loss = 3.979237 
iteration = 105 | loss = 4.745906 
iteration = 110 | loss = 5.239786 
iteration = 115 | loss = 4.082848 
iteration = 120 | loss = 4.483792 
iteration = 125 | loss = 4.456689 
iteration = 130 | loss = 4.237967 
iteration = 135 | loss = 4.350632 
 Epoch: [15] Loss: 4.1879  R1_I2A: 0.3904 R1_A2I: 0.2740 
                 
iteration = 0 | loss = 3.749224 
iteration = 5 | loss = 4.419562 
iteration = 10 | loss = 4.022585 
iteration = 15 | loss = 4.251750 
iteration = 20 | loss = 3.437434 
iteration = 25 | loss = 5.038216 
iteration = 30 | loss = 4.928458 
iteration = 35 | loss = 4.063543 
iteration = 40 | loss = 4.311299 
iteration = 45 | loss = 4.397544 
iteration = 50 | loss = 4.662257 
iteration = 55 | loss = 4.017494 
iteration = 60 | loss = 4.830894 
iteration = 65 | loss = 4.326978 
iteration = 70 | loss = 4.120611 
iteration = 75 | loss = 4.300593 
iteration = 80 | loss = 4.479937 
iteration = 85 | loss = 4.387556 
iteration = 90 | loss = 4.296672 
iteration = 95 | loss = 4.648716 
iteration = 100 | loss = 4.213945 
iteration = 105 | loss = 4.559792 
iteration = 110 | loss = 4.806982 
iteration = 115 | loss = 4.602179 
iteration = 120 | loss = 4.715811 
iteration = 125 | loss = 4.240740 
iteration = 130 | loss = 4.674066 
iteration = 135 | loss = 4.928211 
iteration = 0 | loss = 4.418522 
iteration = 5 | loss = 4.606019 
iteration = 10 | loss = 4.558678 
iteration = 15 | loss = 3.748136 
iteration = 20 | loss = 4.459891 
iteration = 25 | loss = 4.170008 
iteration = 30 | loss = 3.823637 
iteration = 35 | loss = 4.849906 
iteration = 40 | loss = 5.013301 
iteration = 45 | loss = 4.281205 
iteration = 50 | loss = 4.364621 
iteration = 55 | loss = 4.468898 
iteration = 60 | loss = 4.670529 
iteration = 65 | loss = 4.430905 
iteration = 70 | loss = 3.973256 
iteration = 75 | loss = 4.565209 
iteration = 80 | loss = 4.471099 
iteration = 85 | loss = 4.170870 
iteration = 90 | loss = 4.039052 
iteration = 95 | loss = 4.264685 
iteration = 100 | loss = 4.404462 
iteration = 105 | loss = 4.396699 
iteration = 110 | loss = 3.996784 
iteration = 115 | loss = 3.843783 
iteration = 120 | loss = 4.300661 
iteration = 125 | loss = 4.738410 
iteration = 130 | loss = 3.875147 
iteration = 135 | loss = 4.355285 
iteration = 0 | loss = 4.634948 
iteration = 5 | loss = 3.763365 
iteration = 10 | loss = 4.374751 
iteration = 15 | loss = 4.094300 
iteration = 20 | loss = 3.977457 
iteration = 25 | loss = 4.070033 
iteration = 30 | loss = 4.533596 
iteration = 35 | loss = 4.026833 
iteration = 40 | loss = 3.811369 
iteration = 45 | loss = 3.823225 
iteration = 50 | loss = 4.414444 
iteration = 55 | loss = 3.931542 
iteration = 60 | loss = 3.826853 
iteration = 65 | loss = 4.333825 
iteration = 70 | loss = 4.140225 
iteration = 75 | loss = 4.170162 
iteration = 80 | loss = 3.911271 
iteration = 85 | loss = 4.117908 
iteration = 90 | loss = 4.607147 
iteration = 95 | loss = 4.787907 
iteration = 100 | loss = 4.875115 
iteration = 105 | loss = 4.673881 
iteration = 110 | loss = 4.298075 
iteration = 115 | loss = 4.667788 
iteration = 120 | loss = 4.090627 
iteration = 125 | loss = 4.411373 
iteration = 130 | loss = 4.404422 
iteration = 135 | loss = 4.233811 
iteration = 0 | loss = 4.355251 
iteration = 5 | loss = 4.441094 
iteration = 10 | loss = 4.011985 
iteration = 15 | loss = 4.394504 
iteration = 20 | loss = 4.527214 
iteration = 25 | loss = 3.998241 
iteration = 30 | loss = 4.344977 
iteration = 35 | loss = 4.207245 
iteration = 40 | loss = 4.568624 
iteration = 45 | loss = 4.537283 
iteration = 50 | loss = 4.766256 
iteration = 55 | loss = 4.048160 
iteration = 60 | loss = 4.144249 
iteration = 65 | loss = 4.429397 
iteration = 70 | loss = 4.575665 
iteration = 75 | loss = 4.933280 
iteration = 80 | loss = 4.705032 
iteration = 85 | loss = 3.711802 
iteration = 90 | loss = 4.840079 
iteration = 95 | loss = 4.096047 
iteration = 100 | loss = 4.502342 
iteration = 105 | loss = 4.614348 
iteration = 110 | loss = 4.249955 
iteration = 115 | loss = 3.844344 
iteration = 120 | loss = 3.866426 
iteration = 125 | loss = 3.322505 
iteration = 130 | loss = 4.088321 
iteration = 135 | loss = 4.057184 
iteration = 0 | loss = 4.022063 
iteration = 5 | loss = 4.583952 
iteration = 10 | loss = 4.504728 
iteration = 15 | loss = 3.749014 
iteration = 20 | loss = 3.409341 
iteration = 25 | loss = 4.114894 
iteration = 30 | loss = 4.169853 
iteration = 35 | loss = 4.203029 
iteration = 40 | loss = 4.339345 
iteration = 45 | loss = 4.233968 
iteration = 50 | loss = 4.031887 
iteration = 55 | loss = 4.849873 
iteration = 60 | loss = 4.545835 
iteration = 65 | loss = 3.961948 
iteration = 70 | loss = 4.559429 
iteration = 75 | loss = 4.431950 
iteration = 80 | loss = 4.065351 
iteration = 85 | loss = 3.893478 
iteration = 90 | loss = 4.065084 
iteration = 95 | loss = 4.101998 
iteration = 100 | loss = 4.373764 
iteration = 105 | loss = 4.257049 
iteration = 110 | loss = 4.924996 
iteration = 115 | loss = 3.913856 
iteration = 120 | loss = 4.395576 
iteration = 125 | loss = 4.065459 
iteration = 130 | loss = 4.063720 
iteration = 135 | loss = 4.288821 
 Epoch: [20] Loss: 4.1769  R1_I2A: 0.4040 R1_A2I: 0.2833 
                 
iteration = 0 | loss = 4.182139 
iteration = 5 | loss = 3.630829 
iteration = 10 | loss = 4.680360 
iteration = 15 | loss = 3.762757 
iteration = 20 | loss = 3.622364 
iteration = 25 | loss = 4.328950 
iteration = 30 | loss = 4.056882 
iteration = 35 | loss = 4.075677 
iteration = 40 | loss = 4.250254 
iteration = 45 | loss = 4.301237 
iteration = 50 | loss = 3.988758 
iteration = 55 | loss = 4.405106 
iteration = 60 | loss = 4.068817 
iteration = 65 | loss = 3.752632 
iteration = 70 | loss = 4.010341 
iteration = 75 | loss = 4.087201 
iteration = 80 | loss = 4.368689 
iteration = 85 | loss = 4.743449 
iteration = 90 | loss = 4.247810 
iteration = 95 | loss = 4.649337 
iteration = 100 | loss = 4.142029 
iteration = 105 | loss = 3.765983 
iteration = 110 | loss = 4.161604 
iteration = 115 | loss = 4.092418 
iteration = 120 | loss = 4.699236 
iteration = 125 | loss = 4.560393 
iteration = 130 | loss = 4.859371 
iteration = 135 | loss = 3.880992 
iteration = 0 | loss = 4.053329 
iteration = 5 | loss = 4.216308 
iteration = 10 | loss = 4.638263 
iteration = 15 | loss = 4.224337 
iteration = 20 | loss = 4.319550 
iteration = 25 | loss = 4.072345 
iteration = 30 | loss = 3.937782 
iteration = 35 | loss = 4.017502 
iteration = 40 | loss = 4.220835 
iteration = 45 | loss = 3.833794 
iteration = 50 | loss = 4.095018 
iteration = 55 | loss = 4.342561 
iteration = 60 | loss = 3.986270 
iteration = 65 | loss = 3.695656 
iteration = 70 | loss = 4.233502 
iteration = 75 | loss = 3.938496 
iteration = 80 | loss = 4.114207 
iteration = 85 | loss = 4.119478 
iteration = 90 | loss = 4.028950 
iteration = 95 | loss = 3.873403 
iteration = 100 | loss = 3.804564 
iteration = 105 | loss = 3.984900 
iteration = 110 | loss = 4.288716 
iteration = 115 | loss = 4.137459 
iteration = 120 | loss = 4.184749 
iteration = 125 | loss = 4.217561 
iteration = 130 | loss = 3.903265 
iteration = 135 | loss = 4.348880 
iteration = 0 | loss = 3.878520 
iteration = 5 | loss = 3.717762 
iteration = 10 | loss = 3.865577 
iteration = 15 | loss = 3.889227 
iteration = 20 | loss = 4.355925 
iteration = 25 | loss = 4.610379 
iteration = 30 | loss = 3.512330 
iteration = 35 | loss = 4.031700 
iteration = 40 | loss = 4.133017 
iteration = 45 | loss = 4.433736 
iteration = 50 | loss = 3.967286 
iteration = 55 | loss = 4.367260 
iteration = 60 | loss = 4.397106 
iteration = 65 | loss = 3.976652 
iteration = 70 | loss = 4.323370 
iteration = 75 | loss = 4.485327 
iteration = 80 | loss = 4.163631 
iteration = 85 | loss = 4.001641 
iteration = 90 | loss = 4.589704 
iteration = 95 | loss = 4.492748 
iteration = 100 | loss = 3.681799 
iteration = 105 | loss = 3.794947 
iteration = 110 | loss = 4.196736 
iteration = 115 | loss = 4.119399 
iteration = 120 | loss = 3.763619 
iteration = 125 | loss = 3.913378 
iteration = 130 | loss = 4.111475 
iteration = 135 | loss = 3.919894 
iteration = 0 | loss = 4.069112 
iteration = 5 | loss = 3.934068 
iteration = 10 | loss = 3.750184 
iteration = 15 | loss = 4.511322 
iteration = 20 | loss = 4.287620 
iteration = 25 | loss = 3.986801 
iteration = 30 | loss = 4.292222 
iteration = 35 | loss = 4.894645 
iteration = 40 | loss = 4.086231 
iteration = 45 | loss = 3.686151 
iteration = 50 | loss = 4.097545 
iteration = 55 | loss = 4.508389 
iteration = 60 | loss = 4.041191 
iteration = 65 | loss = 4.283736 
iteration = 70 | loss = 4.435634 
iteration = 75 | loss = 4.269767 
iteration = 80 | loss = 3.956012 
iteration = 85 | loss = 3.781712 
iteration = 90 | loss = 3.834159 
iteration = 95 | loss = 3.867320 
iteration = 100 | loss = 4.285751 
iteration = 105 | loss = 4.278316 
iteration = 110 | loss = 4.498602 
iteration = 115 | loss = 3.893580 
iteration = 120 | loss = 3.462466 
iteration = 125 | loss = 3.632479 
iteration = 130 | loss = 3.954655 
iteration = 135 | loss = 3.770518 
iteration = 0 | loss = 3.732499 
iteration = 5 | loss = 3.709496 
iteration = 10 | loss = 3.735101 
iteration = 15 | loss = 4.406342 
iteration = 20 | loss = 4.090385 
iteration = 25 | loss = 4.462998 
iteration = 30 | loss = 3.971022 
iteration = 35 | loss = 4.188566 
iteration = 40 | loss = 4.260613 
iteration = 45 | loss = 4.002528 
iteration = 50 | loss = 4.170289 
iteration = 55 | loss = 4.279715 
iteration = 60 | loss = 4.073333 
iteration = 65 | loss = 3.921820 
iteration = 70 | loss = 3.609687 
iteration = 75 | loss = 3.737684 
iteration = 80 | loss = 3.762663 
iteration = 85 | loss = 3.922801 
iteration = 90 | loss = 4.033434 
iteration = 95 | loss = 4.268182 
iteration = 100 | loss = 3.732597 
iteration = 105 | loss = 4.126790 
iteration = 110 | loss = 3.523118 
iteration = 115 | loss = 3.961344 
iteration = 120 | loss = 3.852664 
iteration = 125 | loss = 3.564093 
iteration = 130 | loss = 4.213355 
iteration = 135 | loss = 4.465819 
 Epoch: [25] Loss: 4.2091  R1_I2A: 0.4091 R1_A2I: 0.3019 
                 
 Epoch: [25] Loss: 4.2091  R1_I2A: 0.4070 mAP_I2A: 0.3448  R1_A2I: 0.3019 mAP_A2I: 0.2428 
                     
iteration = 0 | loss = 3.594640 
iteration = 5 | loss = 4.399480 
iteration = 10 | loss = 3.887348 
iteration = 15 | loss = 3.469021 
iteration = 20 | loss = 3.768241 
iteration = 25 | loss = 3.810038 
iteration = 30 | loss = 3.722265 
iteration = 35 | loss = 3.995276 
iteration = 40 | loss = 4.252970 
iteration = 45 | loss = 3.652856 
iteration = 50 | loss = 3.972303 
iteration = 55 | loss = 3.613789 
iteration = 60 | loss = 4.121833 
iteration = 65 | loss = 4.157784 
iteration = 70 | loss = 3.404703 
iteration = 75 | loss = 4.029445 
iteration = 80 | loss = 3.880264 
iteration = 85 | loss = 3.989577 
iteration = 90 | loss = 4.048946 
iteration = 95 | loss = 4.593165 
iteration = 100 | loss = 4.461128 
iteration = 105 | loss = 4.440317 
iteration = 110 | loss = 4.144492 
iteration = 115 | loss = 3.470455 
iteration = 120 | loss = 4.144793 
iteration = 125 | loss = 4.041005 
iteration = 130 | loss = 3.853564 
iteration = 135 | loss = 3.978518 
iteration = 0 | loss = 4.017682 
iteration = 5 | loss = 4.433836 
iteration = 10 | loss = 3.954659 
iteration = 15 | loss = 4.045974 
iteration = 20 | loss = 4.090331 
iteration = 25 | loss = 3.814199 
iteration = 30 | loss = 4.244100 
iteration = 35 | loss = 3.989625 
iteration = 40 | loss = 4.124893 
iteration = 45 | loss = 4.275590 
iteration = 50 | loss = 3.549687 
iteration = 55 | loss = 3.198695 
iteration = 60 | loss = 4.199084 
iteration = 65 | loss = 3.164906 
iteration = 70 | loss = 4.140556 
iteration = 75 | loss = 3.644510 
iteration = 80 | loss = 3.727110 
iteration = 85 | loss = 4.116913 
iteration = 90 | loss = 3.928169 
iteration = 95 | loss = 3.186363 
iteration = 100 | loss = 3.840022 
iteration = 105 | loss = 3.738747 
iteration = 110 | loss = 4.656138 
iteration = 115 | loss = 3.811917 
iteration = 120 | loss = 3.980133 
iteration = 125 | loss = 4.153932 
iteration = 130 | loss = 3.902773 
iteration = 135 | loss = 4.290590 
iteration = 0 | loss = 4.242299 
iteration = 5 | loss = 3.892641 
iteration = 10 | loss = 3.746433 
iteration = 15 | loss = 3.873516 
iteration = 20 | loss = 4.047056 
iteration = 25 | loss = 3.756574 
iteration = 30 | loss = 4.348282 
iteration = 35 | loss = 3.788605 
iteration = 40 | loss = 4.050927 
iteration = 45 | loss = 3.635549 
iteration = 50 | loss = 3.424736 
iteration = 55 | loss = 3.787728 
iteration = 60 | loss = 4.422579 
iteration = 65 | loss = 4.010599 
iteration = 70 | loss = 4.023849 
iteration = 75 | loss = 3.872309 
iteration = 80 | loss = 3.672372 
iteration = 85 | loss = 4.177588 
iteration = 90 | loss = 3.816482 
iteration = 95 | loss = 3.545943 
iteration = 100 | loss = 3.716397 
iteration = 105 | loss = 3.742424 
iteration = 110 | loss = 4.313853 
iteration = 115 | loss = 3.687804 
iteration = 120 | loss = 3.974952 
iteration = 125 | loss = 3.854136 
iteration = 130 | loss = 3.652747 
iteration = 135 | loss = 4.136445 
iteration = 0 | loss = 4.099579 
iteration = 5 | loss = 3.823229 
iteration = 10 | loss = 4.123119 
iteration = 15 | loss = 3.596868 
iteration = 20 | loss = 3.975614 
iteration = 25 | loss = 3.804118 
iteration = 30 | loss = 3.665596 
iteration = 35 | loss = 3.804031 
iteration = 40 | loss = 3.712288 
iteration = 45 | loss = 3.618907 
iteration = 50 | loss = 3.789854 
iteration = 55 | loss = 3.919553 
iteration = 60 | loss = 4.311772 
iteration = 65 | loss = 3.697531 
iteration = 70 | loss = 3.689105 
iteration = 75 | loss = 3.851401 
iteration = 80 | loss = 3.372113 
iteration = 85 | loss = 3.653938 
iteration = 90 | loss = 3.617697 
iteration = 95 | loss = 3.648634 
iteration = 100 | loss = 3.510546 
iteration = 105 | loss = 4.038918 
iteration = 110 | loss = 3.953718 
iteration = 115 | loss = 3.947677 
iteration = 120 | loss = 3.820755 
iteration = 125 | loss = 3.844972 
iteration = 130 | loss = 4.015832 
iteration = 135 | loss = 4.235086 
iteration = 0 | loss = 3.531980 
iteration = 5 | loss = 4.285906 
iteration = 10 | loss = 4.163857 
iteration = 15 | loss = 3.707716 
iteration = 20 | loss = 3.856539 
iteration = 25 | loss = 3.702531 
iteration = 30 | loss = 3.724279 
iteration = 35 | loss = 3.861565 
iteration = 40 | loss = 3.583371 
iteration = 45 | loss = 4.160465 
iteration = 50 | loss = 3.711205 
iteration = 55 | loss = 3.992223 
iteration = 60 | loss = 3.947164 
iteration = 65 | loss = 3.697128 
iteration = 70 | loss = 3.276690 
iteration = 75 | loss = 3.965722 
iteration = 80 | loss = 3.634469 
iteration = 85 | loss = 3.691648 
iteration = 90 | loss = 3.871189 
iteration = 95 | loss = 3.829926 
iteration = 100 | loss = 3.302904 
iteration = 105 | loss = 4.000898 
iteration = 110 | loss = 4.257097 
iteration = 115 | loss = 4.108874 
iteration = 120 | loss = 3.451451 
iteration = 125 | loss = 3.964916 
iteration = 130 | loss = 3.976229 
iteration = 135 | loss = 3.754120 
 Epoch: [30] Loss: 3.9190  R1_I2A: 0.4293 R1_A2I: 0.3000 
                 
 Epoch: [30] Loss: 3.9190  R1_I2A: 0.4297 mAP_I2A: 0.3552  R1_A2I: 0.3000 mAP_A2I: 0.2449 
                     
iteration = 0 | loss = 4.014002 
iteration = 5 | loss = 4.254343 
iteration = 10 | loss = 4.430007 
iteration = 15 | loss = 4.651085 
iteration = 20 | loss = 3.753218 
iteration = 25 | loss = 3.734003 
iteration = 30 | loss = 4.417310 
iteration = 35 | loss = 4.336896 
iteration = 40 | loss = 3.244015 
iteration = 45 | loss = 3.971853 
iteration = 50 | loss = 3.676594 
iteration = 55 | loss = 3.607365 
iteration = 60 | loss = 3.746104 
iteration = 65 | loss = 4.005653 
iteration = 70 | loss = 3.820575 
iteration = 75 | loss = 3.867254 
iteration = 80 | loss = 4.236889 
iteration = 85 | loss = 3.627430 
iteration = 90 | loss = 4.719519 
iteration = 95 | loss = 4.352104 
iteration = 100 | loss = 4.108308 
iteration = 105 | loss = 3.653229 
iteration = 110 | loss = 3.904983 
iteration = 115 | loss = 4.065394 
iteration = 120 | loss = 3.605589 
iteration = 125 | loss = 3.444893 
iteration = 130 | loss = 4.088482 
iteration = 135 | loss = 4.551288 
iteration = 0 | loss = 3.557433 
iteration = 5 | loss = 3.907278 
iteration = 10 | loss = 3.655006 
iteration = 15 | loss = 3.624942 
iteration = 20 | loss = 3.732608 
iteration = 25 | loss = 3.605645 
iteration = 30 | loss = 4.232042 
iteration = 35 | loss = 3.869379 
iteration = 40 | loss = 3.644368 
iteration = 45 | loss = 3.211393 
iteration = 50 | loss = 3.847870 
iteration = 55 | loss = 3.656415 
iteration = 60 | loss = 3.942726 
iteration = 65 | loss = 3.944801 
iteration = 70 | loss = 3.753337 
iteration = 75 | loss = 3.577726 
iteration = 80 | loss = 4.048053 
iteration = 85 | loss = 3.997250 
iteration = 90 | loss = 3.476888 
iteration = 95 | loss = 4.372004 
iteration = 100 | loss = 4.291252 
iteration = 105 | loss = 3.775525 
iteration = 110 | loss = 3.533328 
iteration = 115 | loss = 3.959027 
iteration = 120 | loss = 3.758358 
iteration = 125 | loss = 3.884939 
iteration = 130 | loss = 3.763994 
iteration = 135 | loss = 4.932355 
iteration = 0 | loss = 3.777030 
iteration = 5 | loss = 4.062873 
iteration = 10 | loss = 4.048858 
iteration = 15 | loss = 4.064574 
iteration = 20 | loss = 3.710096 
iteration = 25 | loss = 3.279162 
iteration = 30 | loss = 3.866889 
iteration = 35 | loss = 3.667580 
iteration = 40 | loss = 3.974251 
iteration = 45 | loss = 3.811487 
iteration = 50 | loss = 3.222528 
iteration = 55 | loss = 3.432144 
iteration = 60 | loss = 3.748164 
iteration = 65 | loss = 3.463022 
iteration = 70 | loss = 3.643878 
iteration = 75 | loss = 3.506675 
iteration = 80 | loss = 4.250773 
iteration = 85 | loss = 4.422938 
iteration = 90 | loss = 3.687601 
iteration = 95 | loss = 3.521049 
iteration = 100 | loss = 3.735030 
iteration = 105 | loss = 3.711992 
iteration = 110 | loss = 4.140801 
iteration = 115 | loss = 3.725430 
iteration = 120 | loss = 4.023640 
iteration = 125 | loss = 4.152173 
iteration = 130 | loss = 4.207800 
iteration = 135 | loss = 4.330082 
iteration = 0 | loss = 4.354928 
iteration = 5 | loss = 3.871402 
iteration = 10 | loss = 3.816250 
iteration = 15 | loss = 3.848274 
iteration = 20 | loss = 3.921886 
iteration = 25 | loss = 3.386698 
iteration = 30 | loss = 3.482765 
iteration = 35 | loss = 4.226523 
iteration = 40 | loss = 3.391911 
iteration = 45 | loss = 3.730336 
iteration = 50 | loss = 3.437863 
iteration = 55 | loss = 3.167823 
iteration = 60 | loss = 3.640788 
iteration = 65 | loss = 4.034549 
iteration = 70 | loss = 3.760042 
iteration = 75 | loss = 3.776073 
iteration = 80 | loss = 3.933901 
iteration = 85 | loss = 3.806637 
iteration = 90 | loss = 4.034903 
iteration = 95 | loss = 3.956756 
iteration = 100 | loss = 3.382524 
iteration = 105 | loss = 3.470334 
iteration = 110 | loss = 3.867444 
iteration = 115 | loss = 4.083849 
iteration = 120 | loss = 3.737607 
iteration = 125 | loss = 3.506792 
iteration = 130 | loss = 3.805380 
iteration = 135 | loss = 3.630021 
iteration = 0 | loss = 3.751028 
iteration = 5 | loss = 4.072517 
iteration = 10 | loss = 3.846377 
iteration = 15 | loss = 3.292032 
iteration = 20 | loss = 4.012432 
iteration = 25 | loss = 3.956262 
iteration = 30 | loss = 3.937969 
iteration = 35 | loss = 4.034082 
iteration = 40 | loss = 3.856613 
iteration = 45 | loss = 3.700061 
iteration = 50 | loss = 3.241647 
iteration = 55 | loss = 3.588748 
iteration = 60 | loss = 3.758734 
iteration = 65 | loss = 3.773134 
iteration = 70 | loss = 3.463870 
iteration = 75 | loss = 3.691933 
iteration = 80 | loss = 3.594540 
iteration = 85 | loss = 3.436115 
iteration = 90 | loss = 3.883282 
iteration = 95 | loss = 3.193339 
iteration = 100 | loss = 3.770269 
iteration = 105 | loss = 4.242621 
iteration = 110 | loss = 3.740573 
iteration = 115 | loss = 3.770216 
iteration = 120 | loss = 3.893466 
iteration = 125 | loss = 3.804653 
iteration = 130 | loss = 3.670281 
iteration = 135 | loss = 3.776757 
 Epoch: [35] Loss: 4.1326  R1_I2A: 0.4344 R1_A2I: 0.3044 
                 
 Epoch: [35] Loss: 4.1326  R1_I2A: 0.4327 mAP_I2A: 0.3523  R1_A2I: 0.3044 mAP_A2I: 0.2477 
                     
iteration = 0 | loss = 3.654846 
iteration = 5 | loss = 3.875375 
iteration = 10 | loss = 3.691022 
iteration = 15 | loss = 3.416305 
iteration = 20 | loss = 3.537760 
iteration = 25 | loss = 3.349802 
iteration = 30 | loss = 3.312403 
iteration = 35 | loss = 4.301626 
iteration = 40 | loss = 3.631872 
iteration = 45 | loss = 3.544512 
iteration = 50 | loss = 3.971745 
iteration = 55 | loss = 4.029737 
iteration = 60 | loss = 3.158429 
iteration = 65 | loss = 3.936120 
iteration = 70 | loss = 3.849753 
iteration = 75 | loss = 3.021935 
iteration = 80 | loss = 4.474968 
iteration = 85 | loss = 3.198918 
iteration = 90 | loss = 3.603057 
iteration = 95 | loss = 3.972835 
iteration = 100 | loss = 3.901430 
iteration = 105 | loss = 3.364751 
iteration = 110 | loss = 3.800227 
iteration = 115 | loss = 3.979069 
iteration = 120 | loss = 3.858002 
iteration = 125 | loss = 3.760556 
iteration = 130 | loss = 3.834521 
iteration = 135 | loss = 3.835969 
iteration = 0 | loss = 4.288976 
iteration = 5 | loss = 3.437221 
iteration = 10 | loss = 3.549795 
iteration = 15 | loss = 3.364815 
iteration = 20 | loss = 3.498489 
iteration = 25 | loss = 3.931612 
iteration = 30 | loss = 3.545557 
iteration = 35 | loss = 3.862197 
iteration = 40 | loss = 3.956223 
iteration = 45 | loss = 3.419669 
iteration = 50 | loss = 3.542247 
iteration = 55 | loss = 3.651068 
iteration = 60 | loss = 3.637010 
iteration = 65 | loss = 3.355310 
iteration = 70 | loss = 4.082773 
iteration = 75 | loss = 3.152656 
iteration = 80 | loss = 4.070638 
iteration = 85 | loss = 3.249383 
iteration = 90 | loss = 4.186648 
iteration = 95 | loss = 3.572767 
iteration = 100 | loss = 3.635300 
iteration = 105 | loss = 3.801553 
iteration = 110 | loss = 3.463581 
iteration = 115 | loss = 4.091039 
iteration = 120 | loss = 3.354984 
iteration = 125 | loss = 3.161747 
iteration = 130 | loss = 3.725624 
iteration = 135 | loss = 3.670774 
iteration = 0 | loss = 3.783225 
iteration = 5 | loss = 3.454973 
iteration = 10 | loss = 4.002023 
iteration = 15 | loss = 3.425338 
iteration = 20 | loss = 3.886951 
iteration = 25 | loss = 3.946964 
iteration = 30 | loss = 4.094972 
iteration = 35 | loss = 3.969450 
iteration = 40 | loss = 3.824191 
iteration = 45 | loss = 3.568579 
iteration = 50 | loss = 3.628458 
iteration = 55 | loss = 3.424871 
iteration = 60 | loss = 3.837356 
iteration = 65 | loss = 3.401627 
iteration = 70 | loss = 3.529719 
iteration = 75 | loss = 4.210419 
iteration = 80 | loss = 3.540176 
iteration = 85 | loss = 3.253024 
iteration = 90 | loss = 3.306406 
iteration = 95 | loss = 3.294202 
iteration = 100 | loss = 3.914462 
iteration = 105 | loss = 3.840629 
iteration = 110 | loss = 3.743513 
iteration = 115 | loss = 3.672156 
iteration = 120 | loss = 3.043446 
iteration = 125 | loss = 3.476448 
iteration = 130 | loss = 3.779437 
iteration = 135 | loss = 3.529894 
iteration = 0 | loss = 4.307249 
iteration = 5 | loss = 3.265078 
iteration = 10 | loss = 3.557985 
iteration = 15 | loss = 4.084611 
iteration = 20 | loss = 3.377709 
iteration = 25 | loss = 3.500965 
iteration = 30 | loss = 3.560933 
iteration = 35 | loss = 3.345999 
iteration = 40 | loss = 4.075428 
iteration = 45 | loss = 4.002117 
iteration = 50 | loss = 3.535334 
iteration = 55 | loss = 3.656185 
iteration = 60 | loss = 3.285602 
iteration = 65 | loss = 3.925498 
iteration = 70 | loss = 3.401639 
iteration = 75 | loss = 3.754120 
iteration = 80 | loss = 3.322129 
iteration = 85 | loss = 3.998404 
iteration = 90 | loss = 3.675223 
iteration = 95 | loss = 3.671256 
iteration = 100 | loss = 3.843306 
iteration = 105 | loss = 3.764873 
iteration = 110 | loss = 3.329141 
iteration = 115 | loss = 3.239784 
iteration = 120 | loss = 3.599016 
iteration = 125 | loss = 3.522748 
iteration = 130 | loss = 3.499945 
iteration = 135 | loss = 3.548522 
iteration = 0 | loss = 3.732181 
iteration = 5 | loss = 3.403436 
iteration = 10 | loss = 4.115363 
iteration = 15 | loss = 3.687242 
iteration = 20 | loss = 3.334528 
iteration = 25 | loss = 3.349780 
iteration = 30 | loss = 3.577696 
iteration = 35 | loss = 3.540581 
iteration = 40 | loss = 3.611232 
iteration = 45 | loss = 3.825046 
iteration = 50 | loss = 3.590043 
iteration = 55 | loss = 3.624225 
iteration = 60 | loss = 3.933421 
iteration = 65 | loss = 3.710238 
iteration = 70 | loss = 3.709372 
iteration = 75 | loss = 3.920641 
iteration = 80 | loss = 4.084769 
iteration = 85 | loss = 3.893133 
iteration = 90 | loss = 3.655931 
iteration = 95 | loss = 3.806242 
iteration = 100 | loss = 3.746142 
iteration = 105 | loss = 4.061177 
iteration = 110 | loss = 3.488993 
iteration = 115 | loss = 3.935018 
iteration = 120 | loss = 3.507331 
iteration = 125 | loss = 3.633839 
iteration = 130 | loss = 3.683242 
iteration = 135 | loss = 3.829308 
 Epoch: [40] Loss: 3.6662  R1_I2A: 0.4470 R1_A2I: 0.3062 
                 
 Epoch: [40] Loss: 3.6662  R1_I2A: 0.4464 mAP_I2A: 0.3676  R1_A2I: 0.3062 mAP_A2I: 0.2490 
                     
iteration = 0 | loss = 3.889220 
iteration = 5 | loss = 3.526385 
iteration = 10 | loss = 3.225710 
iteration = 15 | loss = 3.436048 
iteration = 20 | loss = 3.766608 
iteration = 25 | loss = 3.503288 
iteration = 30 | loss = 3.923440 
iteration = 35 | loss = 3.403016 
iteration = 40 | loss = 3.499296 
iteration = 45 | loss = 3.372236 
iteration = 50 | loss = 3.254836 
iteration = 55 | loss = 3.559932 
iteration = 60 | loss = 3.784822 
iteration = 65 | loss = 3.398542 
iteration = 70 | loss = 3.399709 
iteration = 75 | loss = 4.012048 
iteration = 80 | loss = 3.931556 
iteration = 85 | loss = 4.006643 
iteration = 90 | loss = 4.062670 
iteration = 95 | loss = 3.629710 
iteration = 100 | loss = 3.673735 
iteration = 105 | loss = 4.102584 
iteration = 110 | loss = 3.793478 
iteration = 115 | loss = 3.983365 
iteration = 120 | loss = 3.352166 
iteration = 125 | loss = 3.519588 
iteration = 130 | loss = 3.606292 
iteration = 135 | loss = 3.775646 

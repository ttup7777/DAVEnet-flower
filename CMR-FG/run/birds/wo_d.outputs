Namespace(RNN_dropout=0.0, WORKERS=8, audio_model='Davenet', batch_size=128, cfg_file='Confg/birds_train_batch_wo_d.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds', exp_dir='', gpu_id=0, image_model='VGG16', img_size=256, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=80, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_d.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/birds/wo_d', simtype='MISA', smooth_gamm3=10.0, start_epoch=40, tasks='extraction', topk=3, weight_decay=0.0001)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/train/filenames.pickle (8855)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/test/filenames.pickle (2933)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/test/filenames.pickle (2933)
loaded parameters from epoch 40
current #steps=0, #epochs=40
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:78: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:80: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
iteration = 0 | loss = 7.319579 
iteration = 5 | loss = 7.461772 
iteration = 10 | loss = 7.725338 
iteration = 15 | loss = 7.650709 
iteration = 20 | loss = 7.771207 
iteration = 25 | loss = 8.286635 
iteration = 30 | loss = 8.577441 
iteration = 35 | loss = 8.400095 
iteration = 40 | loss = 7.466043 
iteration = 45 | loss = 7.805362 
iteration = 50 | loss = 7.974336 
iteration = 55 | loss = 7.936427 
iteration = 60 | loss = 7.975761 
iteration = 65 | loss = 7.894525 
/scratch/xinsheng/software/anaconda/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/scratch/xinsheng/software/anaconda/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
iteration = 0 | loss = 8.124117 
iteration = 5 | loss = 7.448071 
iteration = 10 | loss = 7.443347 
iteration = 15 | loss = 8.057325 
iteration = 20 | loss = 7.948997 
iteration = 25 | loss = 7.441947 
iteration = 30 | loss = 7.333525 
iteration = 35 | loss = 8.093437 
iteration = 40 | loss = 7.365637 
iteration = 45 | loss = 7.927198 
iteration = 50 | loss = 7.107320 
iteration = 55 | loss = 7.844594 
iteration = 60 | loss = 7.761453 
iteration = 65 | loss = 7.312955 
iteration = 0 | loss = 7.447823 
iteration = 5 | loss = 7.231647 
iteration = 10 | loss = 7.093657 
iteration = 15 | loss = 7.833962 
iteration = 20 | loss = 8.237585 
iteration = 25 | loss = 8.003373 
iteration = 30 | loss = 7.267087 
iteration = 35 | loss = 7.787556 
iteration = 40 | loss = 7.658059 
iteration = 45 | loss = 8.063614 
iteration = 50 | loss = 8.758145 
iteration = 55 | loss = 7.630562 
iteration = 60 | loss = 7.186385 
iteration = 65 | loss = 7.806381 
iteration = 0 | loss = 7.822549 
iteration = 5 | loss = 7.158485 
iteration = 10 | loss = 7.209891 
iteration = 15 | loss = 7.669001 
iteration = 20 | loss = 6.945191 
iteration = 25 | loss = 7.225446 
iteration = 30 | loss = 8.649587 
iteration = 35 | loss = 7.641262 
iteration = 40 | loss = 7.658755 
iteration = 45 | loss = 7.725044 
iteration = 50 | loss = 7.459044 
iteration = 55 | loss = 7.232641 
iteration = 60 | loss = 7.586658 
iteration = 65 | loss = 7.850407 
iteration = 0 | loss = 7.249594 
iteration = 5 | loss = 8.047012 
iteration = 10 | loss = 7.821006 
iteration = 15 | loss = 8.476545 
iteration = 20 | loss = 7.178372 
iteration = 25 | loss = 7.614182 
iteration = 30 | loss = 7.147406 
iteration = 35 | loss = 7.642811 
iteration = 40 | loss = 7.949662 
iteration = 45 | loss = 6.723757 
iteration = 50 | loss = 7.839757 
iteration = 55 | loss = 7.175642 
iteration = 60 | loss = 7.926721 
iteration = 65 | loss = 7.733593 
 Epoch: [45] Loss: 7.5409  R1_I2A: 0.4466 R1_A2I: 0.3437 
                 
 Epoch: [45] Loss: 7.5409  R1_I2A: 0.4636 mAP_I2A: 0.3925  R1_A2I: 0.3278 mAP_A2I: 0.2692 
                     
iteration = 0 | loss = 7.429847 
iteration = 5 | loss = 8.613438 
iteration = 10 | loss = 7.327635 
iteration = 15 | loss = 7.815370 
iteration = 20 | loss = 7.388836 
iteration = 25 | loss = 7.689368 
iteration = 30 | loss = 7.014343 
iteration = 35 | loss = 7.507136 
iteration = 40 | loss = 7.347427 
iteration = 45 | loss = 7.579333 
iteration = 50 | loss = 7.723615 
iteration = 55 | loss = 7.683282 
iteration = 60 | loss = 7.554946 
iteration = 65 | loss = 7.871970 
iteration = 0 | loss = 6.745294 
iteration = 5 | loss = 7.888153 
iteration = 10 | loss = 7.087559 
iteration = 15 | loss = 7.415656 
iteration = 20 | loss = 7.598283 
iteration = 25 | loss = 7.260134 
iteration = 30 | loss = 8.274435 
iteration = 35 | loss = 7.509917 
iteration = 40 | loss = 7.568799 
iteration = 45 | loss = 7.389085 
iteration = 50 | loss = 7.774619 
iteration = 55 | loss = 7.089274 
iteration = 60 | loss = 7.138427 
iteration = 65 | loss = 7.119007 
iteration = 0 | loss = 7.240157 
iteration = 5 | loss = 7.257223 
iteration = 10 | loss = 7.836211 
iteration = 15 | loss = 7.034192 
iteration = 20 | loss = 8.151628 
iteration = 25 | loss = 7.377247 
iteration = 30 | loss = 8.243225 
iteration = 35 | loss = 7.346964 
iteration = 40 | loss = 7.791238 
iteration = 45 | loss = 6.782827 
iteration = 50 | loss = 6.975651 
iteration = 55 | loss = 7.685829 
iteration = 60 | loss = 7.468076 
iteration = 65 | loss = 6.834266 
iteration = 0 | loss = 7.421923 
iteration = 5 | loss = 7.068067 
iteration = 10 | loss = 7.105646 
iteration = 15 | loss = 7.886786 
iteration = 20 | loss = 8.604450 
iteration = 25 | loss = 7.231930 
iteration = 30 | loss = 7.885751 
iteration = 35 | loss = 7.943635 
iteration = 40 | loss = 7.361610 
iteration = 45 | loss = 7.301526 
iteration = 50 | loss = 7.326412 
iteration = 55 | loss = 7.620812 
iteration = 60 | loss = 7.731678 
iteration = 65 | loss = 7.501725 
iteration = 0 | loss = 7.223271 
iteration = 5 | loss = 8.240786 
iteration = 10 | loss = 7.730167 
iteration = 15 | loss = 7.224710 
iteration = 20 | loss = 7.521526 
iteration = 25 | loss = 7.240933 
iteration = 30 | loss = 7.425690 
iteration = 35 | loss = 7.886845 
iteration = 40 | loss = 7.096831 
iteration = 45 | loss = 7.590731 
iteration = 50 | loss = 7.667475 
iteration = 55 | loss = 7.171618 
iteration = 60 | loss = 7.761619 
iteration = 65 | loss = 7.058167 
 Epoch: [50] Loss: 7.6316  R1_I2A: 0.4555 R1_A2I: 0.3519 
                 
 Epoch: [50] Loss: 7.6316  R1_I2A: 0.4687 mAP_I2A: 0.3978  R1_A2I: 0.3346 mAP_A2I: 0.2751 
                     
iteration = 0 | loss = 7.584323 
iteration = 5 | loss = 7.847261 
iteration = 10 | loss = 7.390038 
iteration = 15 | loss = 7.268714 
iteration = 20 | loss = 7.015466 
iteration = 25 | loss = 7.340354 
iteration = 30 | loss = 7.174231 
iteration = 35 | loss = 7.626971 
iteration = 40 | loss = 6.722897 
iteration = 45 | loss = 7.133232 
iteration = 50 | loss = 7.626578 
iteration = 55 | loss = 7.477646 
iteration = 60 | loss = 7.242391 
iteration = 65 | loss = 6.823726 
iteration = 0 | loss = 7.779427 
iteration = 5 | loss = 6.758684 
iteration = 10 | loss = 6.683938 
iteration = 15 | loss = 7.516893 
iteration = 20 | loss = 7.060769 
iteration = 25 | loss = 7.191289 
iteration = 30 | loss = 7.357094 
iteration = 35 | loss = 8.025131 
iteration = 40 | loss = 7.401109 
iteration = 45 | loss = 6.855756 
iteration = 50 | loss = 7.080219 
iteration = 55 | loss = 6.792612 
iteration = 60 | loss = 7.916942 
iteration = 65 | loss = 7.113398 
iteration = 0 | loss = 6.661795 
iteration = 5 | loss = 7.358759 
iteration = 10 | loss = 7.357813 
iteration = 15 | loss = 7.495979 
iteration = 20 | loss = 6.767713 
iteration = 25 | loss = 7.241008 
iteration = 30 | loss = 7.365311 
iteration = 35 | loss = 7.404766 
iteration = 40 | loss = 7.390828 
iteration = 45 | loss = 8.013257 
iteration = 50 | loss = 7.525476 
iteration = 55 | loss = 7.219878 
iteration = 60 | loss = 7.721042 
iteration = 65 | loss = 6.976817 
iteration = 0 | loss = 7.259274 
iteration = 5 | loss = 7.560589 
iteration = 10 | loss = 7.664749 
iteration = 15 | loss = 7.092189 
iteration = 20 | loss = 7.051491 
iteration = 25 | loss = 8.089404 
iteration = 30 | loss = 7.158979 
iteration = 35 | loss = 6.942852 
iteration = 40 | loss = 7.167797 
iteration = 45 | loss = 6.757329 
iteration = 50 | loss = 7.374758 
iteration = 55 | loss = 6.912100 
iteration = 60 | loss = 7.345155 
iteration = 65 | loss = 8.007278 
iteration = 0 | loss = 7.838573 
iteration = 5 | loss = 7.792261 
iteration = 10 | loss = 6.758201 
iteration = 15 | loss = 7.365941 
iteration = 20 | loss = 7.808854 
iteration = 25 | loss = 7.877748 
iteration = 30 | loss = 7.228266 
iteration = 35 | loss = 7.324323 
iteration = 40 | loss = 6.982477 
iteration = 45 | loss = 6.195875 
iteration = 50 | loss = 7.521362 
iteration = 55 | loss = 6.854076 
iteration = 60 | loss = 7.163056 
iteration = 65 | loss = 7.300547 
 Epoch: [55] Loss: 7.3267  R1_I2A: 0.4511 R1_A2I: 0.3573 
                 
 Epoch: [55] Loss: 7.3267  R1_I2A: 0.4787 mAP_I2A: 0.4018  R1_A2I: 0.3372 mAP_A2I: 0.2766 
                     
iteration = 0 | loss = 7.124703 
iteration = 5 | loss = 7.385036 
iteration = 10 | loss = 7.517215 
iteration = 15 | loss = 7.069298 
iteration = 20 | loss = 7.224047 
iteration = 25 | loss = 7.202923 
iteration = 30 | loss = 7.399487 
iteration = 35 | loss = 7.130017 
iteration = 40 | loss = 6.731254 
iteration = 45 | loss = 7.114946 
iteration = 50 | loss = 7.332211 
iteration = 55 | loss = 6.728390 
iteration = 60 | loss = 7.199153 
iteration = 65 | loss = 6.977079 
iteration = 0 | loss = 6.993268 
iteration = 5 | loss = 6.625515 
iteration = 10 | loss = 7.404109 
iteration = 15 | loss = 6.737782 
iteration = 20 | loss = 7.561824 
iteration = 25 | loss = 6.991638 
iteration = 30 | loss = 7.539524 
iteration = 35 | loss = 7.693475 
iteration = 40 | loss = 6.590064 
iteration = 45 | loss = 6.796160 
iteration = 50 | loss = 6.654048 
iteration = 55 | loss = 7.061483 
iteration = 60 | loss = 6.962004 
iteration = 65 | loss = 6.866699 
iteration = 0 | loss = 7.784140 
iteration = 5 | loss = 6.434882 
iteration = 10 | loss = 7.250903 
iteration = 15 | loss = 7.432593 
iteration = 20 | loss = 7.196676 
iteration = 25 | loss = 6.990374 
iteration = 30 | loss = 7.659481 
iteration = 35 | loss = 6.543866 
iteration = 40 | loss = 7.568907 
iteration = 45 | loss = 7.480742 
iteration = 50 | loss = 7.445217 
iteration = 55 | loss = 7.248837 
iteration = 60 | loss = 7.046703 
iteration = 65 | loss = 6.875351 
iteration = 0 | loss = 7.482707 
iteration = 5 | loss = 7.883251 
iteration = 10 | loss = 7.089231 
iteration = 15 | loss = 7.428380 
iteration = 20 | loss = 6.268690 
iteration = 25 | loss = 6.597059 
iteration = 30 | loss = 7.059700 
iteration = 35 | loss = 7.626314 
iteration = 40 | loss = 7.329436 
iteration = 45 | loss = 6.774842 
iteration = 50 | loss = 6.985637 
iteration = 55 | loss = 7.423198 
iteration = 60 | loss = 7.121040 
iteration = 65 | loss = 7.484693 
iteration = 0 | loss = 6.371467 
iteration = 5 | loss = 6.882119 
iteration = 10 | loss = 6.624370 
iteration = 15 | loss = 7.193342 
iteration = 20 | loss = 7.103292 
iteration = 25 | loss = 7.180754 
iteration = 30 | loss = 7.322636 
iteration = 35 | loss = 7.656862 
iteration = 40 | loss = 7.754409 
iteration = 45 | loss = 7.018393 
iteration = 50 | loss = 7.241199 
iteration = 55 | loss = 6.782891 
iteration = 60 | loss = 7.495557 
iteration = 65 | loss = 6.877520 
 Epoch: [60] Loss: 7.3835  R1_I2A: 0.4531 R1_A2I: 0.3444 
                 
iteration = 0 | loss = 6.271937 
iteration = 5 | loss = 7.927344 
iteration = 10 | loss = 7.264400 
iteration = 15 | loss = 7.201081 
iteration = 20 | loss = 7.351910 
iteration = 25 | loss = 7.640885 
iteration = 30 | loss = 6.410120 
iteration = 35 | loss = 6.764927 
iteration = 40 | loss = 7.356971 
iteration = 45 | loss = 7.282605 
iteration = 50 | loss = 6.882357 
iteration = 55 | loss = 6.686916 
iteration = 60 | loss = 7.649163 
iteration = 65 | loss = 6.576763 
iteration = 0 | loss = 6.642349 
iteration = 5 | loss = 6.587358 
iteration = 10 | loss = 7.223816 
iteration = 15 | loss = 7.387475 
iteration = 20 | loss = 6.278901 
iteration = 25 | loss = 6.874144 
iteration = 30 | loss = 6.566982 
iteration = 35 | loss = 7.480597 
iteration = 40 | loss = 7.463554 
iteration = 45 | loss = 7.130958 
iteration = 50 | loss = 7.075706 
iteration = 55 | loss = 7.480414 
iteration = 60 | loss = 6.869185 
iteration = 65 | loss = 7.160819 
iteration = 0 | loss = 6.507461 
iteration = 5 | loss = 7.758704 
iteration = 10 | loss = 7.628407 
iteration = 15 | loss = 7.325627 
iteration = 20 | loss = 6.981024 
iteration = 25 | loss = 6.652512 
iteration = 30 | loss = 7.456131 
iteration = 35 | loss = 7.031890 
iteration = 40 | loss = 6.836961 
iteration = 45 | loss = 7.463666 
iteration = 50 | loss = 7.106406 
iteration = 55 | loss = 6.926019 
iteration = 60 | loss = 6.764688 
iteration = 65 | loss = 6.603276 
iteration = 0 | loss = 8.448177 
iteration = 5 | loss = 7.297773 
iteration = 10 | loss = 7.148293 
iteration = 15 | loss = 7.078923 
iteration = 20 | loss = 6.698431 
iteration = 25 | loss = 6.560741 
iteration = 30 | loss = 7.006825 
iteration = 35 | loss = 7.493533 
iteration = 40 | loss = 7.335574 
iteration = 45 | loss = 6.723135 
iteration = 50 | loss = 7.689521 
iteration = 55 | loss = 7.280752 
iteration = 60 | loss = 7.440889 
iteration = 65 | loss = 6.884025 
iteration = 0 | loss = 7.017715 
iteration = 5 | loss = 6.817661 
iteration = 10 | loss = 7.292883 
iteration = 15 | loss = 7.085472 
iteration = 20 | loss = 6.817436 
iteration = 25 | loss = 7.137035 
iteration = 30 | loss = 7.794974 
iteration = 35 | loss = 6.686836 
iteration = 40 | loss = 6.698014 
iteration = 45 | loss = 6.967793 
iteration = 50 | loss = 7.173285 
iteration = 55 | loss = 6.695974 
iteration = 60 | loss = 6.988835 
iteration = 65 | loss = 7.161719 
 Epoch: [65] Loss: 7.0774  R1_I2A: 0.4538 R1_A2I: 0.3536 
                 
iteration = 0 | loss = 7.634603 
iteration = 5 | loss = 7.480268 
iteration = 10 | loss = 6.983292 
iteration = 15 | loss = 6.932656 
iteration = 20 | loss = 6.272472 
iteration = 25 | loss = 6.538383 
iteration = 30 | loss = 7.603059 
iteration = 35 | loss = 7.319135 
iteration = 40 | loss = 6.928475 
iteration = 45 | loss = 7.864130 
iteration = 50 | loss = 6.863169 
iteration = 55 | loss = 7.300936 
iteration = 60 | loss = 6.291267 
iteration = 65 | loss = 7.246412 
iteration = 0 | loss = 6.561102 
iteration = 5 | loss = 6.983770 
iteration = 10 | loss = 7.612228 
iteration = 15 | loss = 7.253924 
iteration = 20 | loss = 6.897460 
iteration = 25 | loss = 6.296225 
iteration = 30 | loss = 6.916678 
iteration = 35 | loss = 6.952567 
iteration = 40 | loss = 7.145457 
iteration = 45 | loss = 6.071829 
iteration = 50 | loss = 7.021318 
iteration = 55 | loss = 7.679882 
iteration = 60 | loss = 7.072795 
iteration = 65 | loss = 6.906666 
iteration = 0 | loss = 7.022648 
iteration = 5 | loss = 6.994408 
iteration = 10 | loss = 6.617500 
iteration = 15 | loss = 6.897194 
iteration = 20 | loss = 7.296483 
iteration = 25 | loss = 7.361510 
iteration = 30 | loss = 7.551720 
iteration = 35 | loss = 7.102366 
iteration = 40 | loss = 6.605179 
iteration = 45 | loss = 6.820580 
iteration = 50 | loss = 6.682662 
iteration = 55 | loss = 7.139564 
iteration = 60 | loss = 7.246154 
iteration = 65 | loss = 7.345119 
iteration = 0 | loss = 7.277364 
iteration = 5 | loss = 7.128385 
iteration = 10 | loss = 6.618984 
iteration = 15 | loss = 6.485645 
iteration = 20 | loss = 7.285578 
iteration = 25 | loss = 6.772137 
iteration = 30 | loss = 7.256715 
iteration = 35 | loss = 7.076856 
iteration = 40 | loss = 7.278084 
iteration = 45 | loss = 7.208665 
iteration = 50 | loss = 6.980376 
iteration = 55 | loss = 6.496405 
iteration = 60 | loss = 6.767287 
iteration = 65 | loss = 7.144714 
iteration = 0 | loss = 6.947495 
iteration = 5 | loss = 7.285027 
iteration = 10 | loss = 6.219116 
iteration = 15 | loss = 7.327994 
iteration = 20 | loss = 7.375251 
iteration = 25 | loss = 7.206497 
iteration = 30 | loss = 7.366568 
iteration = 35 | loss = 6.209364 
iteration = 40 | loss = 6.480747 
iteration = 45 | loss = 7.101623 
iteration = 50 | loss = 6.589602 
iteration = 55 | loss = 7.085507 
iteration = 60 | loss = 6.905782 
iteration = 65 | loss = 6.898200 
 Epoch: [70] Loss: 7.1886  R1_I2A: 0.4558 R1_A2I: 0.3519 
                 
iteration = 0 | loss = 6.571379 
iteration = 5 | loss = 6.572339 
iteration = 10 | loss = 6.676853 
iteration = 15 | loss = 7.059554 
iteration = 20 | loss = 7.070502 
iteration = 25 | loss = 6.815793 
iteration = 30 | loss = 6.997300 
iteration = 35 | loss = 6.520491 
iteration = 40 | loss = 6.633029 
iteration = 45 | loss = 6.744383 
iteration = 50 | loss = 7.295723 
iteration = 55 | loss = 6.701417 
iteration = 60 | loss = 6.565379 
iteration = 65 | loss = 6.782092 
iteration = 0 | loss = 6.828306 
iteration = 5 | loss = 7.197352 
iteration = 10 | loss = 6.594599 
iteration = 15 | loss = 7.234369 
iteration = 20 | loss = 7.662597 
iteration = 25 | loss = 6.279289 
iteration = 30 | loss = 6.645432 
iteration = 35 | loss = 6.956477 
iteration = 40 | loss = 7.132112 
iteration = 45 | loss = 6.663300 
iteration = 50 | loss = 7.084478 
iteration = 55 | loss = 7.376820 
iteration = 60 | loss = 7.024147 
iteration = 65 | loss = 7.134457 
iteration = 0 | loss = 6.679916 
iteration = 5 | loss = 6.477016 
iteration = 10 | loss = 7.031228 
iteration = 15 | loss = 6.521506 
iteration = 20 | loss = 6.782164 
iteration = 25 | loss = 6.357705 
iteration = 30 | loss = 7.161061 
iteration = 35 | loss = 7.170011 
iteration = 40 | loss = 6.639568 
iteration = 45 | loss = 6.735985 
iteration = 50 | loss = 6.455235 
iteration = 55 | loss = 6.881862 
iteration = 60 | loss = 7.073653 
iteration = 65 | loss = 7.578750 
iteration = 0 | loss = 6.763166 
iteration = 5 | loss = 6.604999 
iteration = 10 | loss = 6.594763 
iteration = 15 | loss = 6.897165 
iteration = 20 | loss = 6.416858 
iteration = 25 | loss = 6.431401 
iteration = 30 | loss = 7.134820 
iteration = 35 | loss = 6.785233 
iteration = 40 | loss = 6.525695 
iteration = 45 | loss = 6.930763 
iteration = 50 | loss = 6.937651 
iteration = 55 | loss = 6.533525 
iteration = 60 | loss = 7.199316 
iteration = 65 | loss = 6.682394 
iteration = 0 | loss = 6.609016 
iteration = 5 | loss = 6.778088 
iteration = 10 | loss = 7.097527 
iteration = 15 | loss = 7.160091 
iteration = 20 | loss = 8.000879 
iteration = 25 | loss = 6.933333 
iteration = 30 | loss = 6.632730 
iteration = 35 | loss = 6.737238 
iteration = 40 | loss = 7.058722 
iteration = 45 | loss = 7.227284 
iteration = 50 | loss = 6.814644 
iteration = 55 | loss = 6.862401 
iteration = 60 | loss = 6.447405 
iteration = 65 | loss = 7.012914 
 Epoch: [75] Loss: 6.7222  R1_I2A: 0.4668 R1_A2I: 0.3532 
                 
 Epoch: [75] Loss: 6.7222  R1_I2A: 0.4803 mAP_I2A: 0.4063  R1_A2I: 0.3382 mAP_A2I: 0.2792 
                     
iteration = 0 | loss = 6.930280 
iteration = 5 | loss = 6.445340 
iteration = 10 | loss = 6.120580 
iteration = 15 | loss = 6.726154 
iteration = 20 | loss = 6.666307 
iteration = 25 | loss = 7.093592 
iteration = 30 | loss = 6.432992 
iteration = 35 | loss = 6.749665 
iteration = 40 | loss = 6.710055 
iteration = 45 | loss = 6.793162 
iteration = 50 | loss = 7.089561 
iteration = 55 | loss = 7.465869 
iteration = 60 | loss = 6.993243 
iteration = 65 | loss = 6.397485 
iteration = 0 | loss = 6.335404 
iteration = 5 | loss = 6.852544 
iteration = 10 | loss = 6.557508 
iteration = 15 | loss = 7.425208 
iteration = 20 | loss = 6.636833 
iteration = 25 | loss = 6.414147 
iteration = 30 | loss = 6.600432 
iteration = 35 | loss = 6.437256 
iteration = 40 | loss = 7.281713 
iteration = 45 | loss = 6.883090 
iteration = 50 | loss = 6.830401 
iteration = 55 | loss = 7.041173 
iteration = 60 | loss = 7.398958 
iteration = 65 | loss = 6.739343 
iteration = 0 | loss = 6.722807 
iteration = 5 | loss = 7.380308 
iteration = 10 | loss = 7.339392 
iteration = 15 | loss = 6.804304 
iteration = 20 | loss = 6.891339 
iteration = 25 | loss = 7.226365 
iteration = 30 | loss = 6.824656 
iteration = 35 | loss = 6.797110 
iteration = 40 | loss = 6.908408 
iteration = 45 | loss = 6.610698 
iteration = 50 | loss = 7.048733 
iteration = 55 | loss = 6.900105 
iteration = 60 | loss = 6.874761 
iteration = 65 | loss = 6.963777 
iteration = 0 | loss = 6.970499 
iteration = 5 | loss = 7.170718 
iteration = 10 | loss = 6.417901 
iteration = 15 | loss = 6.579987 
iteration = 20 | loss = 6.177102 
iteration = 25 | loss = 7.289988 
iteration = 30 | loss = 6.385993 
iteration = 35 | loss = 6.864389 
iteration = 40 | loss = 6.779144 
iteration = 45 | loss = 6.526540 
iteration = 50 | loss = 6.685235 
iteration = 55 | loss = 7.488168 
iteration = 60 | loss = 6.228069 
iteration = 65 | loss = 6.530297 
iteration = 0 | loss = 6.040154 
iteration = 5 | loss = 7.426681 
iteration = 10 | loss = 6.787764 
iteration = 15 | loss = 6.685497 
iteration = 20 | loss = 6.903302 
iteration = 25 | loss = 6.731385 
iteration = 30 | loss = 6.463840 
iteration = 35 | loss = 6.717072 
iteration = 40 | loss = 7.276655 
iteration = 45 | loss = 6.423146 
iteration = 50 | loss = 7.117143 
iteration = 55 | loss = 6.972354 
iteration = 60 | loss = 6.376064 
iteration = 65 | loss = 6.929681 
 Epoch: [80] Loss: 6.0248  R1_I2A: 0.4586 R1_A2I: 0.3536 
                 
iteration = 0 | loss = 6.408185 
iteration = 5 | loss = 6.787546 
iteration = 10 | loss = 6.325611 
iteration = 15 | loss = 7.113102 
iteration = 20 | loss = 6.934648 
iteration = 25 | loss = 6.674796 
iteration = 30 | loss = 6.811074 
iteration = 35 | loss = 6.590321 
iteration = 40 | loss = 6.229439 
iteration = 45 | loss = 6.690080 
iteration = 50 | loss = 6.512810 
iteration = 55 | loss = 6.383997 
iteration = 60 | loss = 6.710917 
iteration = 65 | loss = 7.018705 

Namespace(RNN_dropout=0.0, WORKERS=8, audio_model='Davenet', batch_size=128, cfg_file='Confg/birds_train_batch_wo_c.yml', data_path='/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds', exp_dir='', gpu_id=0, image_model='VGG16', img_size=256, lr=0.0001, lr_decay=50, manualSeed=200, margin=1.0, momentum=0.9, n_epochs=60, n_heads=1, n_print_steps=2, optim='adam', pretrained_image_model=False, result_file='wo_c.text', resume=True, rnn_type='LSTM', save_root='outputs/01_Baseline/birds/wo_c', simtype='MISA', smooth_gamm3=10.0, start_epoch=20, tasks='extraction', topk=3, weight_decay=0.0001)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/train/filenames.pickle (8855)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/test/filenames.pickle (2933)
Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg
Load filenames from: /tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/data/birds/test/filenames.pickle (2933)
loaded parameters from epoch 20
current #steps=0, #epochs=20
start training...
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/utils/config.py:235: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:89: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/AudioModels.py:91: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:78: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/ImageModels.py:80: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.
  nn.init.orthogonal(self.hidden.weight.data)
/tudelft.net/staff-bulk/ewi/insy/MMC/xinsheng/code/Interspeech2020/FGSL_V10.1/models/classification.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.L1.weight.data)
iteration = 0 | loss = 5.706887 
iteration = 5 | loss = 5.775058 
iteration = 10 | loss = 6.124691 
iteration = 15 | loss = 5.924005 
iteration = 20 | loss = 5.874171 
iteration = 25 | loss = 6.024722 
iteration = 30 | loss = 6.493760 
iteration = 35 | loss = 6.295937 
iteration = 40 | loss = 5.754321 
iteration = 45 | loss = 5.980575 
iteration = 50 | loss = 5.921486 
iteration = 55 | loss = 6.072332 
iteration = 60 | loss = 5.991484 
iteration = 65 | loss = 5.970113 
/scratch/xinsheng/software/anaconda/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/scratch/xinsheng/software/anaconda/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
iteration = 0 | loss = 6.041265 
iteration = 5 | loss = 5.738099 
iteration = 10 | loss = 5.742445 
iteration = 15 | loss = 6.118104 
iteration = 20 | loss = 5.980102 
iteration = 25 | loss = 5.765385 
iteration = 30 | loss = 5.728751 
iteration = 35 | loss = 5.883815 
iteration = 40 | loss = 5.519058 
iteration = 45 | loss = 5.916782 
iteration = 50 | loss = 5.540419 
iteration = 55 | loss = 5.612151 
iteration = 60 | loss = 5.903569 
iteration = 65 | loss = 5.559412 
iteration = 0 | loss = 5.840641 
iteration = 5 | loss = 5.643759 
iteration = 10 | loss = 5.358636 
iteration = 15 | loss = 5.867154 
iteration = 20 | loss = 6.121496 
iteration = 25 | loss = 6.194846 
iteration = 30 | loss = 5.726333 
iteration = 35 | loss = 5.805292 
iteration = 40 | loss = 5.871861 
iteration = 45 | loss = 6.033731 
iteration = 50 | loss = 6.443697 
iteration = 55 | loss = 5.837080 
iteration = 60 | loss = 5.420612 
iteration = 65 | loss = 5.939761 
iteration = 0 | loss = 5.950352 
iteration = 5 | loss = 5.534111 
iteration = 10 | loss = 5.626495 
iteration = 15 | loss = 5.714420 
iteration = 20 | loss = 5.517529 
iteration = 25 | loss = 5.659440 
iteration = 30 | loss = 6.311107 
iteration = 35 | loss = 5.921585 
iteration = 40 | loss = 5.976233 
iteration = 45 | loss = 6.025402 
iteration = 50 | loss = 5.581398 
iteration = 55 | loss = 5.437731 
iteration = 60 | loss = 5.429574 
iteration = 65 | loss = 5.844232 
iteration = 0 | loss = 5.538985 
iteration = 5 | loss = 5.918532 
iteration = 10 | loss = 5.828356 
iteration = 15 | loss = 6.366919 
iteration = 20 | loss = 5.426964 
iteration = 25 | loss = 5.743833 
iteration = 30 | loss = 5.470620 
iteration = 35 | loss = 5.728293 
iteration = 40 | loss = 6.102897 
iteration = 45 | loss = 5.206084 
iteration = 50 | loss = 5.745722 
iteration = 55 | loss = 5.402330 
iteration = 60 | loss = 5.909999 
iteration = 65 | loss = 5.853209 
 Epoch: [25] Loss: 5.6629  R1_I2A: 0.4122 R1_A2I: 0.3096 
                 
iteration = 0 | loss = 5.750485 
iteration = 5 | loss = 5.789348 
iteration = 10 | loss = 5.565741 
iteration = 15 | loss = 5.304506 
iteration = 20 | loss = 5.494008 
iteration = 25 | loss = 5.352723 
iteration = 30 | loss = 5.393780 
iteration = 35 | loss = 5.045913 
iteration = 40 | loss = 5.349321 
iteration = 45 | loss = 5.846274 
iteration = 50 | loss = 5.917527 
iteration = 55 | loss = 5.911561 
iteration = 60 | loss = 5.862902 
iteration = 65 | loss = 5.727078 
iteration = 0 | loss = 5.902501 
iteration = 5 | loss = 5.777153 
iteration = 10 | loss = 5.555973 
iteration = 15 | loss = 5.325251 
iteration = 20 | loss = 5.274661 
iteration = 25 | loss = 5.395465 
iteration = 30 | loss = 5.729153 
iteration = 35 | loss = 5.855267 
iteration = 40 | loss = 5.660336 
iteration = 45 | loss = 5.433577 
iteration = 50 | loss = 5.212782 
iteration = 55 | loss = 5.828318 
iteration = 60 | loss = 5.413549 
iteration = 65 | loss = 5.407043 
iteration = 0 | loss = 5.589828 
iteration = 5 | loss = 5.431086 
iteration = 10 | loss = 5.247873 
iteration = 15 | loss = 5.805566 
iteration = 20 | loss = 5.370657 
iteration = 25 | loss = 5.501197 
iteration = 30 | loss = 5.217505 
iteration = 35 | loss = 5.733756 
iteration = 40 | loss = 5.541660 
iteration = 45 | loss = 5.455235 
iteration = 50 | loss = 5.750304 
iteration = 55 | loss = 5.805864 
iteration = 60 | loss = 5.619861 
iteration = 65 | loss = 5.398995 
iteration = 0 | loss = 5.479150 
iteration = 5 | loss = 4.926309 
iteration = 10 | loss = 5.457511 
iteration = 15 | loss = 5.516244 
iteration = 20 | loss = 5.820802 
iteration = 25 | loss = 5.645501 
iteration = 30 | loss = 5.657813 
iteration = 35 | loss = 5.906058 
iteration = 40 | loss = 5.571506 
iteration = 45 | loss = 5.791504 
iteration = 50 | loss = 5.598809 
iteration = 55 | loss = 5.769928 
iteration = 60 | loss = 5.748123 
iteration = 65 | loss = 5.182053 
iteration = 0 | loss = 5.622044 
iteration = 5 | loss = 5.140153 
iteration = 10 | loss = 5.787822 
iteration = 15 | loss = 5.916241 
iteration = 20 | loss = 5.377319 
iteration = 25 | loss = 5.568284 
iteration = 30 | loss = 5.430068 
iteration = 35 | loss = 5.824989 
iteration = 40 | loss = 5.339052 
iteration = 45 | loss = 5.274838 
iteration = 50 | loss = 5.715291 
iteration = 55 | loss = 5.182485 
iteration = 60 | loss = 5.273552 
iteration = 65 | loss = 5.791065 
 Epoch: [30] Loss: 5.3761  R1_I2A: 0.4180 R1_A2I: 0.3249 
                 
iteration = 0 | loss = 5.954304 
iteration = 5 | loss = 5.631440 
iteration = 10 | loss = 5.753188 
iteration = 15 | loss = 5.492765 
iteration = 20 | loss = 5.610201 
iteration = 25 | loss = 5.493031 
iteration = 30 | loss = 5.429062 
iteration = 35 | loss = 5.417777 
iteration = 40 | loss = 5.546407 
iteration = 45 | loss = 5.473699 
iteration = 50 | loss = 5.300541 
iteration = 55 | loss = 6.117378 
iteration = 60 | loss = 5.751171 
iteration = 65 | loss = 5.302360 
iteration = 0 | loss = 5.253924 
iteration = 5 | loss = 5.264336 
iteration = 10 | loss = 5.181911 
iteration = 15 | loss = 5.583155 
iteration = 20 | loss = 5.229464 
iteration = 25 | loss = 5.579097 
iteration = 30 | loss = 5.533222 
iteration = 35 | loss = 5.674684 
iteration = 40 | loss = 5.353487 
iteration = 45 | loss = 5.317092 
iteration = 50 | loss = 5.399696 
iteration = 55 | loss = 5.796579 
iteration = 60 | loss = 5.228786 
iteration = 65 | loss = 5.320767 
iteration = 0 | loss = 5.409527 
iteration = 5 | loss = 4.969554 
iteration = 10 | loss = 5.456191 
iteration = 15 | loss = 5.231191 
iteration = 20 | loss = 4.907207 
iteration = 25 | loss = 5.665466 
iteration = 30 | loss = 5.622628 
iteration = 35 | loss = 5.438853 
iteration = 40 | loss = 5.702806 
iteration = 45 | loss = 5.418671 
iteration = 50 | loss = 5.619347 
iteration = 55 | loss = 4.976177 
iteration = 60 | loss = 4.938400 
iteration = 65 | loss = 5.726944 
iteration = 0 | loss = 5.476347 
iteration = 5 | loss = 5.512329 
iteration = 10 | loss = 5.259550 
iteration = 15 | loss = 5.453627 
iteration = 20 | loss = 5.589235 
iteration = 25 | loss = 5.388290 
iteration = 30 | loss = 4.908637 
iteration = 35 | loss = 5.606772 
iteration = 40 | loss = 5.539849 
iteration = 45 | loss = 5.487641 
iteration = 50 | loss = 5.640339 
iteration = 55 | loss = 5.096685 
iteration = 60 | loss = 5.415951 
iteration = 65 | loss = 5.170842 
iteration = 0 | loss = 5.257324 
iteration = 5 | loss = 5.203198 
iteration = 10 | loss = 5.465377 
iteration = 15 | loss = 4.946734 
iteration = 20 | loss = 5.189082 
iteration = 25 | loss = 5.718385 
iteration = 30 | loss = 5.312831 
iteration = 35 | loss = 5.525279 
iteration = 40 | loss = 5.309246 
iteration = 45 | loss = 5.470363 
iteration = 50 | loss = 5.282295 
iteration = 55 | loss = 4.991043 
iteration = 60 | loss = 5.578615 
iteration = 65 | loss = 5.146832 
 Epoch: [35] Loss: 5.2645  R1_I2A: 0.4170 R1_A2I: 0.3229 
                 
iteration = 0 | loss = 5.402505 
iteration = 5 | loss = 5.139776 
iteration = 10 | loss = 5.192905 
iteration = 15 | loss = 5.050130 
iteration = 20 | loss = 5.505765 
iteration = 25 | loss = 5.457087 
iteration = 30 | loss = 4.924382 
iteration = 35 | loss = 5.263544 
iteration = 40 | loss = 5.207443 
iteration = 45 | loss = 5.712508 
iteration = 50 | loss = 5.648414 
iteration = 55 | loss = 5.748467 
iteration = 60 | loss = 5.508628 
iteration = 65 | loss = 5.085607 
iteration = 0 | loss = 5.290347 
iteration = 5 | loss = 5.342447 
iteration = 10 | loss = 5.854023 
iteration = 15 | loss = 5.179221 
iteration = 20 | loss = 5.333767 
iteration = 25 | loss = 4.957246 
iteration = 30 | loss = 5.359194 
iteration = 35 | loss = 5.415713 
iteration = 40 | loss = 5.143511 
iteration = 45 | loss = 5.029750 
iteration = 50 | loss = 5.477852 
iteration = 55 | loss = 4.922839 
iteration = 60 | loss = 5.063280 
iteration = 65 | loss = 5.695319 
iteration = 0 | loss = 5.384019 
iteration = 5 | loss = 5.266088 
iteration = 10 | loss = 5.345083 
iteration = 15 | loss = 5.313911 
iteration = 20 | loss = 5.188029 
iteration = 25 | loss = 5.210073 
iteration = 30 | loss = 4.662333 
iteration = 35 | loss = 5.322830 
iteration = 40 | loss = 5.266907 
iteration = 45 | loss = 5.041325 
iteration = 50 | loss = 5.429428 
iteration = 55 | loss = 5.125571 
iteration = 60 | loss = 5.291036 
iteration = 65 | loss = 4.994875 
iteration = 0 | loss = 5.138800 
iteration = 5 | loss = 5.173320 
iteration = 10 | loss = 4.962531 
iteration = 15 | loss = 5.249761 
iteration = 20 | loss = 5.524727 
iteration = 25 | loss = 4.804835 
iteration = 30 | loss = 5.396241 
iteration = 35 | loss = 5.535869 
iteration = 40 | loss = 5.396251 
iteration = 45 | loss = 5.245227 
iteration = 50 | loss = 5.247905 
iteration = 55 | loss = 5.516949 
iteration = 60 | loss = 5.299328 
iteration = 65 | loss = 5.518424 
iteration = 0 | loss = 5.408746 
iteration = 5 | loss = 5.071355 
iteration = 10 | loss = 5.460967 
iteration = 15 | loss = 5.406924 
iteration = 20 | loss = 5.262584 
iteration = 25 | loss = 5.135155 
iteration = 30 | loss = 5.180437 
iteration = 35 | loss = 5.203627 
iteration = 40 | loss = 5.670497 
iteration = 45 | loss = 5.206845 
iteration = 50 | loss = 4.997616 
iteration = 55 | loss = 5.175029 
iteration = 60 | loss = 5.211669 
iteration = 65 | loss = 5.715312 
 Epoch: [40] Loss: 5.1320  R1_I2A: 0.4293 R1_A2I: 0.3334 
                 
 Epoch: [40] Loss: 5.1320  R1_I2A: 0.4601 mAP_I2A: 0.3817  R1_A2I: 0.3206 mAP_A2I: 0.2620 
                     
iteration = 0 | loss = 5.118197 
iteration = 5 | loss = 5.347718 
iteration = 10 | loss = 5.399416 
iteration = 15 | loss = 5.205021 
iteration = 20 | loss = 5.397981 
iteration = 25 | loss = 5.573215 
iteration = 30 | loss = 5.746154 
iteration = 35 | loss = 5.217731 
iteration = 40 | loss = 5.417948 
iteration = 45 | loss = 5.355639 
iteration = 50 | loss = 5.367361 
iteration = 55 | loss = 5.334719 
iteration = 60 | loss = 5.437499 
iteration = 65 | loss = 5.323552 
iteration = 0 | loss = 5.637113 
iteration = 5 | loss = 5.054719 
iteration = 10 | loss = 5.450311 
iteration = 15 | loss = 5.447301 
iteration = 20 | loss = 5.675999 
iteration = 25 | loss = 5.587311 
iteration = 30 | loss = 5.462622 
iteration = 35 | loss = 5.393148 
iteration = 40 | loss = 5.177981 
iteration = 45 | loss = 5.159832 
iteration = 50 | loss = 5.475626 
iteration = 55 | loss = 5.225184 
iteration = 60 | loss = 5.471865 
iteration = 65 | loss = 5.639679 
iteration = 0 | loss = 5.237548 
iteration = 5 | loss = 5.113839 
iteration = 10 | loss = 5.468043 
iteration = 15 | loss = 5.656876 
iteration = 20 | loss = 5.350469 
iteration = 25 | loss = 5.415087 
iteration = 30 | loss = 5.086146 
iteration = 35 | loss = 5.397409 
iteration = 40 | loss = 5.290915 
iteration = 45 | loss = 5.622321 
iteration = 50 | loss = 5.956889 
iteration = 55 | loss = 5.427586 
iteration = 60 | loss = 5.184294 
iteration = 65 | loss = 5.566382 
iteration = 0 | loss = 5.499413 
iteration = 5 | loss = 5.356587 
iteration = 10 | loss = 5.259202 
iteration = 15 | loss = 5.194152 
iteration = 20 | loss = 5.088532 
iteration = 25 | loss = 5.379694 
iteration = 30 | loss = 4.918660 
iteration = 35 | loss = 5.196139 
iteration = 40 | loss = 5.430856 
iteration = 45 | loss = 5.320228 
iteration = 50 | loss = 5.273962 
iteration = 55 | loss = 5.647799 
iteration = 60 | loss = 5.337534 
iteration = 65 | loss = 5.271335 
iteration = 0 | loss = 5.342836 
iteration = 5 | loss = 5.467885 
iteration = 10 | loss = 5.208446 
iteration = 15 | loss = 5.252635 
iteration = 20 | loss = 5.145919 
iteration = 25 | loss = 5.050522 
iteration = 30 | loss = 5.258609 
iteration = 35 | loss = 5.112092 
iteration = 40 | loss = 5.475112 
iteration = 45 | loss = 4.971216 
iteration = 50 | loss = 4.844941 
iteration = 55 | loss = 5.079378 
iteration = 60 | loss = 5.360335 
iteration = 65 | loss = 5.061299 
 Epoch: [45] Loss: 5.1164  R1_I2A: 0.4470 R1_A2I: 0.3433 
                 
 Epoch: [45] Loss: 5.1164  R1_I2A: 0.4732 mAP_I2A: 0.3862  R1_A2I: 0.3271 mAP_A2I: 0.2661 
                     
iteration = 0 | loss = 4.856548 
iteration = 5 | loss = 5.129562 
iteration = 10 | loss = 5.018451 
iteration = 15 | loss = 4.917511 
iteration = 20 | loss = 5.415418 
iteration = 25 | loss = 5.196598 
iteration = 30 | loss = 5.521062 
iteration = 35 | loss = 5.149748 
iteration = 40 | loss = 5.069140 
iteration = 45 | loss = 5.191799 
iteration = 50 | loss = 4.942772 
iteration = 55 | loss = 5.080355 
iteration = 60 | loss = 5.148839 
iteration = 65 | loss = 5.052485 
iteration = 0 | loss = 5.093019 
iteration = 5 | loss = 5.015016 
iteration = 10 | loss = 5.154134 
iteration = 15 | loss = 5.096768 
iteration = 20 | loss = 5.431571 
iteration = 25 | loss = 5.194496 
iteration = 30 | loss = 5.117384 
iteration = 35 | loss = 5.272973 
iteration = 40 | loss = 4.972188 
iteration = 45 | loss = 5.151993 
iteration = 50 | loss = 5.421924 
iteration = 55 | loss = 5.189043 
iteration = 60 | loss = 5.042979 
iteration = 65 | loss = 4.988777 
iteration = 0 | loss = 4.980789 
iteration = 5 | loss = 5.256203 
iteration = 10 | loss = 5.018446 
iteration = 15 | loss = 5.082282 
iteration = 20 | loss = 5.382053 
iteration = 25 | loss = 4.601330 
iteration = 30 | loss = 5.302204 
iteration = 35 | loss = 5.102015 
iteration = 40 | loss = 5.145755 
iteration = 45 | loss = 5.206941 
iteration = 50 | loss = 5.188393 
iteration = 55 | loss = 5.101882 
iteration = 60 | loss = 4.802465 
iteration = 65 | loss = 5.795070 
iteration = 0 | loss = 4.901164 
iteration = 5 | loss = 5.406656 
iteration = 10 | loss = 5.269287 
iteration = 15 | loss = 5.061377 
iteration = 20 | loss = 5.213705 
iteration = 25 | loss = 5.405180 
iteration = 30 | loss = 5.225805 
iteration = 35 | loss = 5.180461 
iteration = 40 | loss = 5.057916 
iteration = 45 | loss = 4.943328 
iteration = 50 | loss = 5.107376 
iteration = 55 | loss = 5.071748 
iteration = 60 | loss = 4.999911 
iteration = 65 | loss = 5.031634 
iteration = 0 | loss = 5.033865 
iteration = 5 | loss = 4.870029 
iteration = 10 | loss = 5.125040 
iteration = 15 | loss = 5.356678 
iteration = 20 | loss = 5.269658 
iteration = 25 | loss = 5.177995 
iteration = 30 | loss = 5.312498 
iteration = 35 | loss = 5.011151 
iteration = 40 | loss = 5.026247 
iteration = 45 | loss = 5.161015 
iteration = 50 | loss = 5.120311 
iteration = 55 | loss = 5.078255 
iteration = 60 | loss = 4.850389 
iteration = 65 | loss = 5.187821 
 Epoch: [50] Loss: 5.1173  R1_I2A: 0.4715 R1_A2I: 0.3433 
                 
 Epoch: [50] Loss: 5.1173  R1_I2A: 0.4809 mAP_I2A: 0.4029  R1_A2I: 0.3349 mAP_A2I: 0.2730 
                     
iteration = 0 | loss = 4.960318 
iteration = 5 | loss = 4.864250 
iteration = 10 | loss = 4.865707 
iteration = 15 | loss = 5.030201 
iteration = 20 | loss = 5.231643 
iteration = 25 | loss = 4.876894 
iteration = 30 | loss = 5.045676 
iteration = 35 | loss = 4.933275 
iteration = 40 | loss = 5.048283 
iteration = 45 | loss = 4.840332 
iteration = 50 | loss = 5.334807 
iteration = 55 | loss = 5.120654 
iteration = 60 | loss = 5.121456 
iteration = 65 | loss = 5.027153 
iteration = 0 | loss = 4.818365 
iteration = 5 | loss = 5.233733 
iteration = 10 | loss = 4.824669 
iteration = 15 | loss = 5.090753 
iteration = 20 | loss = 5.341422 
iteration = 25 | loss = 4.675010 
iteration = 30 | loss = 4.792748 
iteration = 35 | loss = 5.037421 
iteration = 40 | loss = 5.002023 
iteration = 45 | loss = 4.888225 
iteration = 50 | loss = 4.974036 
iteration = 55 | loss = 5.247736 
iteration = 60 | loss = 5.059045 
iteration = 65 | loss = 5.257989 
iteration = 0 | loss = 4.853707 
iteration = 5 | loss = 4.660731 
iteration = 10 | loss = 5.240356 
iteration = 15 | loss = 4.750901 
iteration = 20 | loss = 4.997370 
iteration = 25 | loss = 4.602848 
iteration = 30 | loss = 5.235525 
iteration = 35 | loss = 5.167124 
iteration = 40 | loss = 4.866440 
iteration = 45 | loss = 4.771186 
iteration = 50 | loss = 4.741523 
iteration = 55 | loss = 5.016392 
iteration = 60 | loss = 5.086366 
iteration = 65 | loss = 5.404022 
iteration = 0 | loss = 4.878992 
iteration = 5 | loss = 4.913272 
iteration = 10 | loss = 4.881859 
iteration = 15 | loss = 4.928075 
iteration = 20 | loss = 4.737376 
iteration = 25 | loss = 4.824973 
iteration = 30 | loss = 5.204604 
iteration = 35 | loss = 5.056557 
iteration = 40 | loss = 4.901939 
iteration = 45 | loss = 4.973190 
iteration = 50 | loss = 4.852643 
iteration = 55 | loss = 4.892799 
iteration = 60 | loss = 5.391706 
iteration = 65 | loss = 4.905610 
iteration = 0 | loss = 4.782448 
iteration = 5 | loss = 5.002011 
iteration = 10 | loss = 5.085097 
iteration = 15 | loss = 5.259116 
iteration = 20 | loss = 5.670349 
slurmstepd: error: *** STEP 5049488.0 ON ewi2 CANCELLED AT 2020-03-03T18:15:15 DUE TO TIME LIMIT ***
